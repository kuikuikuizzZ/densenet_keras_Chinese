{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CUDA_VISIBLE_DEVICES=1\n",
    "#coding:utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from densenet.densenet_lib import Densenet_keras\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd())+'densenet/')\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# import keys_union\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import difflib\n",
    "import re\n",
    "import random\n",
    "import cv2\n",
    "import densenet.keys as keys\n",
    "import densenet.keys_keras as keys_keras\n",
    "import densenet.densenet_lib as densenet_lib\n",
    "import numpy as np\n",
    "import densenet.keys_keras as keys_keras\n",
    "import densenet.model as model\n",
    "from densenet.model import densenet_cnn_model,densenet_rnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'densenet.model' from '/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/model.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(densenet_lib)\n",
    "imp.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/trans_model/model_75layers_labeled_ch_len25_v1.pb'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_tf = densenet_lib.Densenet_tf_multi_gpus(pb_model_path=model_path,characters=characters,fixed_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/trans_model/model_75layers_labeled_ch_len25_v1.pb'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_tf_1 = densenet_lib.Densenet_tf(pb_model_path=model_path,characters=characters,fixed_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/75layers_labeled_ch_len25_v1-3.060-0.505.h5'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_keras = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                             model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './densenet/models/weights_densenet.h5'\n",
    "characters = keys.alphabet[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "densenet_keras_5990 = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                                  model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './train/models/freezen_5layers_dataset_v1-0.672-0.894.h5'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "densenet_keras_2 = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                                model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet_keras_5990.load_weights('./densenet/models/weights_densenet_with_name.h5')\n",
    "densenet_keras_5990.basemodel = basemodel5\n",
    "# densenet_keras_2.load_weights('./train/models/random_len20-06-0.400-0.926.h5')\n",
    "\n",
    "# imgs_path = glob('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/train/*.png')\n",
    "imgs_path = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_path = random.choice(imgs_path)\n",
    "# print(img_path)\n",
    "# img = Image.open(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "blank = np.ones((img.shape[0],50,3),dtype=np.uint8)*255\n",
    "img = np.concatenate((img,blank),axis=1)\n",
    "print(img.shape)\n",
    "model = densenet_keras_5990\n",
    "# img = cv2.resize(img,(800,32))\n",
    "%time result = model.recognize(img)\n",
    "# print(model.basemodel.summary())\n",
    "plt.imshow(img)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two model predict\n",
    "\n",
    "# densenet_keras.load_weights('./train/models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "# densenet_keras_2.load_weights('./train/models/freezen_5layers_dataset_v1-0.672-0.894.h5')\n",
    "    \n",
    "# imgs_path = glob('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/train/*.png')\n",
    "imgs_path = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/临时切割图/*png')\n",
    "img_path = random.choice(imgs_path)\n",
    "# print(img_path)\n",
    "# img = Image.open(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "blank = np.ones((img.shape[0],20,3),dtype=np.uint8)*255\n",
    "img = np.concatenate((blank,img,blank),axis=1)\n",
    "model1 = densenet_keras\n",
    "model2 = densenet_keras_2\n",
    "# img = cv2.resize(img,(800,32))\n",
    "%time y_pred1 = model1.predict(img)\n",
    "%time y_pred2 = model2.predict(img)\n",
    "y_pred1 = y_pred1[:, :, :]\n",
    "y_pred2 = y_pred2[:, :, :]\n",
    "\n",
    "result = model1.decode((y_pred1+y_pred2)/2,with_confidence=True)\n",
    "result2 = model2.recognize_with_confidence(img)\n",
    "result3 = densenet_keras.recognize_with_confidence(img)\n",
    "# print(model.basemodel.summary())\n",
    "plt.imshow(img)\n",
    "print(result)\n",
    "print(result2,'model2')\n",
    "print(result3,'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(u'./train/images/test_images20181122/*png')\n",
    "img_paths = glob(u'/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*5\n",
    "img_paths = random.sample(img_paths,512)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "result_list=[]\n",
    "start = time.time()\n",
    "print(len(img_list))\n",
    "%time result_list = densenet_tf.recognize_on_batch(img_list,with_confidence=True,fixed_size=True)\n",
    "# %time result_list_1 =  densenet_tf.recognize_on_batch(img_list,with_confidence=True,fixed_size=True)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'2,1000':'3.2,4.1','2,300':'1.1,1.37',\n",
    " '1 1000':'3.5,4.5s','1,300':'1.16,1.44s',\n",
    " '4,1000':'2.9,4.4','4,300':'0.98,1.58'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*10\n",
    "img_paths = random.sample(img_paths,512)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "result_list = []\n",
    "start = time.time()\n",
    "for img in img_list:\n",
    "    result = densenet_keras.recognize_with_confidence(img)\n",
    "    result_list.append(result)\n",
    "print(time.time()-start)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用标注的样本测试模型的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./train/create_dataset/total_medicine_v1.txt','w') as f:\n",
    "#     for item in total_medicine:\n",
    "#         f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "save_dir = './test_data/labeled_data/'\n",
    "img_paths = glob(save_dir+'*png')\n",
    "\n",
    "# densenet_tf.load_weights('./train/models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "\n",
    "model = densenet_tf\n",
    "error_list = []\n",
    "# load json 文件\n",
    "with open(save_dir+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    label=json.load(json_file)\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"全角转半角\"\"\"\n",
    "    rstring = \"\"\n",
    "    for uchar in ustring:\n",
    "        inside_code=ord(uchar)\n",
    "        if inside_code == 12288:                              #全角空格直接转换            \n",
    "            inside_code = 32 \n",
    "        elif (inside_code >= 65281 and inside_code <= 65374): #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "\n",
    "        rstring += chr(inside_code)\n",
    "    return rstring\n",
    "sum = 0\n",
    "start = time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单次识别速度慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for img_path in img_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    img_name = os.path.split(img_path)[-1]\n",
    "#     result,confidence = model.recognize_with_confidence(img)\n",
    "    if label[img_name] == result:\n",
    "        sum +=1\n",
    "    else:\n",
    "        error_list.append((result,label[img_name]))\n",
    "print(sum/len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613156795501709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "imgs = [cv2.imread(img_path) for img_path in img_paths]\n",
    "img_names = [os.path.split(img_path)[-1] for img_path in img_paths]\n",
    "ground_true = [strQ2B(label[img_name]) for img_name in img_names]\n",
    "result = model.recognize_on_batch(imgs,with_confidence=True,fixed_size=True)\n",
    "# sum([res[0]==ground for res,ground in zip(result,label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8281444582814446\n"
     ]
    }
   ],
   "source": [
    "result = [strQ2B(res[0]) for res in result]\n",
    "\n",
    "true_sum = [res==ground for res,ground in zip(result,ground_true)].count(True)\n",
    "print(true_sum/len(imgs))\n",
    "error_list = [(res,ground)for res,ground in zip(result,ground_true) if res != ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('甲神经阳滞麻(宫旁)', '甲神经阻滞麻醉(宫旁)'),\n",
       " ('甲透析器(Revac1èear300)', '甲透析器(Revaclear300)'),\n",
       " ('★乙型肝炎核心抗体测定Anti-HE', '★乙型肝炎核心抗体测定(Anti-H'),\n",
       " ('★糖类抗原测定(化学发光法', '★糖类抗原测定(化学发光法)'),\n",
       " ('★血清促甲状腺激素测定(仁学发)', '★血清促甲状腺激素测定(仁学发'),\n",
       " ('★抗组织细胞抗体测定/', '★抗组织细胞抗体测定'),\n",
       " ('★抗心磷脂抗体测定(ACA)', '★抗心磷脂抗体测定((ACA)'),\n",
       " ('★骨钙素N端中分子片段测定(N-MD', '★骨钙素N端中分子片段测定(N-MI'),\n",
       " ('★抗双链DNA测定((抗dsDNA)', '★抗双链DNA测定(抗dsDNA)'),\n",
       " ('★总补体测定(CH50)(仪器法)', '★总补体测定(CH5O)(仪器法)'),\n",
       " ('★抗环瓜氨酸肽抗体(抗CCP抗体)', '★抗环瓜氨酸肽抗体(抗ccP抗体)'),\n",
       " ('★抗链球菌溶血素0测定(AS0)(免', '★抗链球菌溶血素0测定(ASO)(免'),\n",
       " ('*高压液相分析(HPLC)(指便用通用', '高压液相分析(HPLC)(指使用通用'),\n",
       " ('甲血浆D-聚体测定(急诊/D-Dimer)', '甲血浆D-二聚体测定(急诊/D-Dimer)'),\n",
       " ('甲C一反应蛋白测定(CRP)(急诊)', '甲C-反应蛋白测定(CRP)(急诊)'),\n",
       " ('甲人工鼻(泰科3s2/5877)', '甲人工鼻(泰科352/5877)'),\n",
       " ('甲血清碳酸氢盐(HC03)测定', '甲血清碳酸氢盐(HCO3)测定'),\n",
       " ('丙干式片(14:17)', '丙干式片(14*17)'),\n",
       " ('甲三通(进I)', '甲三通(进口)'),\n",
       " ('(甲)百特0.9%-氯化钠注射液000m', '(甲)百特0.9%-氯化钠注射液1000ml'),\n",
       " ('(甲)百特0.9%-氯化钠注射液500m6o.', '(甲)百特0.9%-氯化钠注射液500ml5.6100'),\n",
       " ('(甲)百特0.9%-氯化钠注射液250ml-51300', '(甲)百特0.9%-氯化钠注射液250ml5.1300'),\n",
       " ('★丙型肝炎抗体测定(Anti-HCV)', '★丙型肝炎抗体测定(Anti-HCV)('),\n",
       " ('★乙型肝炎核心抗体测定(Anti-HI', '★乙型肝炎核心抗体测定(Anti-HB'),\n",
       " ('★血型单特异性抗体鉴定(凝胶柱', '★血型单特异抗体鉴定(凝胶柱'),\n",
       " ('★乙型肝炎表面抗原测定((HBsAg)(', '★乙型肝炎表面抗原测定(HBsAg)'),\n",
       " ('★乙型肝炎e抗体测定(Anti-HBe)(', '★乙型肝炎e抗体测定(Anti-HBe)'),\n",
       " ('★血清载脂蛋白AⅠ测定', '★血清载脂蛋白AI测定'),\n",
       " ('(甲)大冢-氯化钾注射液1.5500', '(甲)大冢-氯化钾注射液1g1.2500'),\n",
       " ('(甲)辰欣-葡萄糖氯化钠注射液00ml3.856', '(甲)辰欣-葡萄糖氯化钠注射液500ml3.8500'),\n",
       " ('(甲)枸橼酸舒芬太尼注射液50μ50*r766', '(甲)枸橼酸舒芬太尼注射液50μg50.1700'),\n",
       " ('★血清Y-谷氨酰基转移酶测定', '★血清γ-谷氨酰基转移酶测定'),\n",
       " ('★乙型肝炎表面抗原测定(HBsAg)(', '★乙型肝炎表面抗原测定(HBsAg)'),\n",
       " ('降钙素原检测(化学发光法)', '降钙素原测定(化学发光法)'),\n",
       " ('★血清碳酸氢盐(HC03)测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('★血清IⅣ型胶原测定', '★血清Ⅳ型胶原测定'),\n",
       " ('★人Ⅲ型前胶原肽(PIⅢP)测定', '★人Ⅲ型前胶原肽(PⅢP)测定'),\n",
       " ('血清肌酸激酶―MB同工酶质量测定', '血清肌酸激酶-MB同工酶质量测定'),\n",
       " ('、★血清白蛋白测定(化学法)', '★血清白蛋白测定(化学法)'),\n",
       " ('★乙型肝炎表面抗体测定(Anti-HB', '★乙型肝炎表面抗体测定(Anti-H'),\n",
       " ('甲血清a-L-岩藻糖苷酶测定', '甲a-L-岩藻糖苷酶测定'),\n",
       " ('', '甲床位费'),\n",
       " ('甲AB0血型鉴定(门诊)', '甲ABO血型鉴定(门诊)'),\n",
       " ('甲血浆抗凝血酶Ⅲ活性测定(AT—ⅢA)', '甲血浆抗凝血酶Ⅲ活性测定(AT-ⅢA)'),\n",
       " ('甲血红蛋白测定(b)', '甲血红蛋白测定(Hb)'),\n",
       " ('甲视黄醉结合蛋白测定', '甲视黄醇结合蛋白测定'),\n",
       " ('甲凝血酶原时间测定(PT)', '甲凝血酶原时间测定(RT)'),\n",
       " ('甲血清计油:酯测定', '甲血清甘油三酯测定'),\n",
       " ('甲血清载脂蛋白AI测定', '甲血清载脂蛋白AⅠ测定'),\n",
       " ('甲血清丙氨酸氨基转移酶测定', '甲血清丙氨基酸氨基转移酶测定'),\n",
       " ('甲γ-cT(血清γ-谷氨酰基转移酶测定', '甲γ-GT(血清γ-谷氨酰基转移酶测定)'),\n",
       " ('甲血清碳酸氢盐(HC03测定(急诊)', '甲血清碳酸氢盐(HCO3)测定(急诊)'),\n",
       " ('甲血清载脂蛋白B测定', '甲血清载脂蛋白Β测定'),\n",
       " ('甲血清a-L-岩藻糖*酶测定', '甲血清a-L-岩藻糖苷酶测定'),\n",
       " ('甲C—反应蛋白测定(cRP)', '甲C-反应蛋白测定(CRP)'),\n",
       " ('★血清我脂蛋测定', '★血清我脂蛋白E测定'),\n",
       " ('★血清直接胆红素测定(化学法或I', '★血清直接胆红素测定(化学法或'),\n",
       " ('★血清肌酸激酶一MB同T酶活性测', '★血清肌酸激酶一MB同工酶活性测'),\n",
       " ('★B型钠尿肽前体(PRO-BNP)测定', '★B犁钠尿肽前体(PRO-BNP)测定'),\n",
       " ('★血清天门冬氨酸氨基转移酶测定', '★血清天门冬氰酸氨基转移酶测定'),\n",
       " ('★血清γ-谷氨酰基转移酶测定', '★血清γ-谷氨酸基转移酶测定'),\n",
       " ('★血清载脂蛋白AⅠ测定', '★血清载脂蛋白AI测定'),\n",
       " ('尿N-乙酰-β-D-氨基葡萄糖苷酶测', '尿N-乙酰一β一D一氨基葡萄糖苷酶测'),\n",
       " ('★B2微球蛋白测定(免疫散射比浊', '★β2微球蛋白测定(免疫散射比浊'),\n",
       " ('甲血清β-羟基丁酸测定', '甲血清B-羟基丁酸测定'),\n",
       " ('甲细胞角蛋白19片段测定(CYFRA21-)', '甲细胞角蛋白19片段测定(CYFRA21-1)'),\n",
       " ('甲血清肌钙蛋白I测定', '用血清肌钙蛋白I测定'),\n",
       " ('甲丙型肝炎抗体TgG测定', '甲丙型肝炎抗体IgG测定'),\n",
       " ('★乙型肝炎e抗原测定(HBeAg)(化', '★乙型肝炎e抗原测定(HBeAg)(化学'),\n",
       " ('★活化部分凝血活酶时间测定(APT', '★活化部分凝血活酶时间测定(AP'),\n",
       " ('★AB0血型鉴定(玻璃珠柱法或凝胶', '★ABO血型鉴定(玻璃珠柱法或凝胶'),\n",
       " ('★乙型肝炎表面抗体测定(Ant-H', '★乙犁肝炎表面抗体测定(Anti-H'),\n",
       " ('★乙型肝炎核心抗体测定(Anti-lI', '★乙型肝炎核心抗体测定(Anti-H'),\n",
       " ('★凝血酶时间测定(TT)(仪器法)', '★凝血酶时问测定(TT)(仪器法)'),\n",
       " ('★血清尿酸测定(化学法)', '★血滴尿酸测定(化学法)'),\n",
       " ('★丙型肝炎抗体测定(Anti-HCV)((', '★丙型肝炎抗体测定(Anti-HCV)('),\n",
       " ('人免疫缺陷病毒抗体测定(Anti-HI', '人免疫缺陷病毒抗体测定(Anti-H'),\n",
       " ('★血清载脂蛋白A1测定', '★血清载脂蛋白AI测定'),\n",
       " ('Ⅱ床位费', '甲床位费'),\n",
       " ('甲注射器10m1', '甲注射器10ml'),\n",
       " ('内陪客躺椅费', '丙陪客躺椅费'),\n",
       " ('甲1特级护理', '甲特级护理'),\n",
       " ('甲阿昔洛韦乳膏3%10克*1支(3%10克*1支310克', '甲阿昔洛韦乳膏3%10克*1支(3%10克*1支)(3%10克'),\n",
       " ('!甲*飒化钠注射液0.9%100毫升*1瓶(0.9%100毫升*11', '甲*氯化钠注射液0.9%100毫升*1瓶(0.9%100毫升*1)'),\n",
       " ('甲氯化钠针(大冢)0.9%10毫升*1支(0.910升*', '甲氯化钠针(大冢)0.9%10毫升*1支(0.9%10毫升*'),\n",
       " ('乙(8mg)昂丹司琼(欧贝)针8毫克/4毫升*1支(8毫克/', '乙(8mg)昂丹司琼(欧贝)针8毫克/4毫升*1支(8毫克'),\n",
       " ('甲肌酐测定(急诊)', '用肌酐测定(急诊)'),\n",
       " ('甲C—反应蛋白测定(CRP)', '甲C一反应蛋白测定(CRP)'),\n",
       " ('甲血清载脂蛋白B测定', '申血清载脂蛋白B测定'),\n",
       " ('甲血游离脂肪酸测定', '用血游离脂肪酸测定'),\n",
       " ('甲血清肌钙蛋白Ⅰ测定', '甲血清肌钙蛋白I测定'),\n",
       " ('乙四肢血管彩色多普勒超☆', '乙四肢血管彩色多普勒超声'),\n",
       " ('乙螺旋CT增强扫描(≥个部位)', '乙螺旋CT增强扫描(≥三个部位)'),\n",
       " ('甲血清aL岩藻糖苷酶测定', '甲血清a-L-岩藻糖苷酶测定'),\n",
       " ('乙彩色多普勒超声常规检杳(个部位)', '乙彩色多普勒超声常规检查(一个部位)'),\n",
       " ('甲颅内压监护传感器置入术次手术(70%))', '甲颅内压监护传感器置入术次手术(70%)'),\n",
       " ('乙1CU单元治疗(14天以内)', '乙ICU单元治疗(14天以内)'),\n",
       " ('颅内多发血肿清除术', '甲颅内多发血肿清除术'),\n",
       " ('甲使用带吸刮功能手术解剖器加收(颅骨利脑手术', '甲使用带吸刮功能手术解剖器加收(颅骨和脑手术'),\n",
       " ('甲术中门休血同收', '甲术中自体血同收'),\n",
       " ('甲血清促口状腺激素测定', '甲血清促甲状腺激素测定'),\n",
       " ('甲血同型半胱尔酸测定', '甲血同型半胱氨酸测定'),\n",
       " ('甲呼吸机辅J呼吸', '甲呼吸机辅助呼吸'),\n",
       " ('丙组织多普勒显像(T))', '丙组织多普勒显像(TDI)'),\n",
       " ('★血清γ~谷氨酰基转移酶测定', '★血清γ-谷氨酰基转移酶测定'),\n",
       " ('★血细胞分析(三分类以t)0', '★血细胞分析(三分类以上)20.0000480.00'),\n",
       " ('★血清碳酸氢盐(HC03)测定(干化', '★血清碳酸氢盐(HCO3)测定(干化'),\n",
       " ('★血清碳酸氢盐(HC03测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('小密低密度脂蛋白(sdLDL)测定/', '小密低密度脂蛋白(sdLDL)测定'),\n",
       " ('★血清高密度脂蛋白胆固醇测定(', '★血清高密度脂蛋白胆固醇测定'),\n",
       " ('★葡萄糖测定(干化学法简易血糖', '★葡萄糖测定(干化学法简易血糖)'),\n",
       " ('★乙型胼炎表面抗原测定(HBsAg)(', '★乙型胼炎表面抗原测定(HBsAg)'),\n",
       " ('组织/细胞荧光定量脱氧核糖核酸以', '组织/细胞荧光定量脱氧核糖核酸'),\n",
       " ('★活化部分凝血活酶时间测定(APT', '★活化部分凝血活酶时间测定(AP'),\n",
       " ('★血清尿酸测定(化学法)', '★血清尿酸测定'),\n",
       " ('★血清碳酸氢盐(HC08)测定', '★血清碳酸总盐(HCO3)测定'),\n",
       " ('310701001电脑多导联心电图30000', '310701001b电脑多导联心电图30.0000'),\n",
       " ('★血清载脂蛋白B澜测定', '★血清载脂蛋白B测定'),\n",
       " ('★血浆凝血酶原时苘测定(PT)(仪', '★血浆凝血酶原时间测定(PT)(仪'),\n",
       " ('★血清碳酸氢盐(HC03)测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('甲持续血片监测', '甲持续血压监测'),\n",
       " ('丙(迈普新)胸腺法新针1.6毫克*1支(1.6毫克*1支', '丙(迈普新)胸腺法新针1.6亳克*1支(1.6毫克*1支)'),\n",
       " ('乙腺苷蛋氨酸(喜美欣)针0.5克*1瓶(0.5克*1瓶)0.', '乙腺苷蛋氨酸(喜美欣)针0.5克*1瓶(0.5克*1瓶)(0.'),\n",
       " ('乙阳洛诺司琼(吉欧停)针0T25毫克/5升*I支(025', '乙帕洛诺司琼(吉欧停)针0.25毫克/5毫升*1支(0.25毫'),\n",
       " ('甲氯化钠注射液0.9%500升*1袋(0.950毫升*1袋', '甲氯化钠注射液0.9%500毫升*1袋(0.9%500毫升*1袋'),\n",
       " ('氯化钠注射液0.9%250毫升*1瓶(0.9%250*1肝', '甲氯化钠注射液0.9%250毫升*1瓶(0.9%250毫升*1瓶'),\n",
       " ('乙复方硫酸新霉素药膜(制)10片(10片(10片)', '乙复方硫酸新霉素药膜(制)10片(10片)(10片)'),\n",
       " ('甲(5mg)地塞米松注射液5毫克*1支(5毫克*1支)(5毫', '甲(5mg)地塞米松注射液5亳克*1支(5毫克*1支)(5毫克'),\n",
       " ('甲深静脉穿刺置管术(PTCC)', '甲深静脉穿刺置管术(PICC)'),\n",
       " ('H血浆D-二聚体测定(D-Dimer)', '甲血浆D-二聚体测定(D-Dimer)'),\n",
       " ('乙复方碳酸氢钠含漱液(制)200毫升*1瓶(200毫升*瓶', '乙复方碳酸氢钠含漱液(制)200毫升*1瓶(200毫升*1瓶'),\n",
       " ('乙注射用水5毫升*1支(5毫*1支(5毫*1支)', '乙注射用水5毫升*1支(5毫升*1支)(5毫升*1支)'),\n",
       " ('乙瑞格列奈片(诺和龙)1毫克*30片(1毫克*30片)(1', '乙瑞格列奈片(诺和龙)1毫克*30片(1毫克*30片)(1毫'),\n",
       " ('乙奥沙利铂针(艾恒)50毫克*1瓶(50毫克*1瓶(50毫克', '乙奥沙利铂针(艾恒)50毫克*1瓶(50毫克*1瓶)(50毫克'),\n",
       " ('H静脉注射', '甲静脉注射'),\n",
       " ('甲氯化钠注射液0.9100毫升*1瓶(0.9%100毫升*1', '甲*氯化钠注射液0.9%100毫升*1瓶(0.9%100毫升*1)'),\n",
       " ('甲5%葡萄糖注射液5250毫升*1瓶(250毫*1瓶)', '甲5%葡萄糖注射液5%250毫升*1瓶(5%250毫升*1瓶)'),\n",
       " ('乙(艾速平)艾司奥美拉唑钠针40毫克*1瓶(0克*1)', '乙(艾速平)艾司奥美拉唑钠针40毫克*1瓶(40毫克*1}')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(check_str):\n",
    "    len_str = len(check_str)\n",
    "    cutoff = 0.7\n",
    "    if len_str <= 3:\n",
    "        cutoff = 0.5\n",
    "    elif len_str <= 5:\n",
    "        cutoff = 0.6\n",
    "    return cutoff\n",
    "with open('./train/create_dataset/name_dictionary_v1.2.txt') as f:\n",
    "    medicine = f.readlines()\n",
    "medicine = [name.split('\\n')[0] for name in medicine ]\n",
    "medicine = list(set(medicine))\n",
    "len(medicine)\n",
    "medicine = [strQ2B(name)  for name in medicine]\n",
    "\n",
    "\n",
    "def get_closest_matches(item):\n",
    "    result,label = item\n",
    "    cutoff = check_name(result)\n",
    "    match_result = difflib.get_close_matches(result, medicine,cutoff=cutoff)\n",
    "    if match_result:\n",
    "        return (match_result,label)\n",
    "    else:\n",
    "        return (result,label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.92 ms, sys: 9.65 ms, total: 16.6 ms\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool,cpu_count\n",
    "pool = Pool(cpu_count()//4)\n",
    "# % time match_results = [get_closest_matches(item) for item in error_list ]\n",
    "\n",
    "sum=true_sum\n",
    "%time match_results = pool.map(get_closest_matches,error_list)\n",
    "match_error = []\n",
    "for results,label in match_results:\n",
    "    if label == results[0]:\n",
    "        sum +=1\n",
    "    else:\n",
    "        match_error.append((results[0],label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792029887920298"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum/len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2dbf6c98784c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试验证模型冻结层的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  densenet  import densenet\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "characters = keys.alphabet[:]\n",
    "characters = characters[:] \n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "input = Input(shape=(32, None, 1), name='the_input')\n",
    "y_pred = densenet.dense_cnn(input, nclass)\n",
    "basemodel = Model(inputs=input, outputs=y_pred)\n",
    "modelPath = './densenet/models/weights_densenet_with_name.h5'\n",
    "\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    basemodel.load_weights(modelPath)\n",
    "    print('done!') \n",
    "  \n",
    "    \n",
    "# basemodel.save_weights('./models/no_use_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters = keys.alphabet_union[:]\n",
    "# characters = characters[:] \n",
    "# nclass = len(characters)\n",
    "\n",
    "basemodel2 = Model(inputs=input,outputs=basemodel.get_layer('flatten').output)\n",
    "for i,layer in enumerate(basemodel2.layers):\n",
    "    layer.set_weights = basemodel.layers[i].weights\n",
    "flatten = basemodel.get_layer('flatten').output\n",
    "y_pred = Dense(nclass, name='out', activation='softmax')(flatten)\n",
    "basemodel3 =  Model(inputs=input,outputs=y_pred)\n",
    "for i,layer in enumerate(basemodel3.layers):\n",
    "    layer.set_weights = basemodel.layers[i].weights\n",
    "# basemodel4 = Model(inputs=input,outputs=basemodel.get_layer('Time').output)\n",
    "# basemodel4.load_weights()\n",
    "# basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel4 = Model(inputs=input,outputs=basemodel.get_layer('flatten').output)\n",
    "basemodel4.load_weights('./models/pre_y_pred_weights.h5')\n",
    "for i,layer in enumerate(basemodel.layers[:-1]):\n",
    "    layer.set_weights = basemodel4.layers[i].weights\n",
    "#     print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel3.layers[-1].set_weights = basemodel.layers[-1].weights\n",
    "print(basemodel.layers[-1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel3.save_weights('./models/merge_weights_pretrain_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nclass)\n",
    "input1 = Input(shape=(32, None, 1), name='the_input')\n",
    "y_pred1 = densenet.dense_cnn(input1, nclass)\n",
    "basemodel5 = Model(inputs=input1, outputs=y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.save_weights('./densenet/models/weights_densenet_with_name.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel5.load_weights('./densenet/models/weights_densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.get_layer('pool3_0_avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(basemodel5.layers):\n",
    "    print(i,layer.name,layer) \n",
    "#     print(layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用plot_model 观测模型情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(densenet_keras.basemodel,to_file='./models/rename_model.png')\n",
    "plt.figure(figsize=(40,200))\n",
    "img = Image.open('./models/rename_model.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多GPU预测性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import  multi_gpu_model\n",
    "with tf.device('/cpu:0'):\n",
    "    base_model =densenet_cnn_model()\n",
    "    base_model.load_weights('./models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "parallel_model = multi_gpu_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.backend import ctc_decode\n",
    "\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "nClass = len(characters)\n",
    "def recognize_on_batch(img_list,basemodel):\n",
    "#         start = time.time()\n",
    "    max_w = int(max([32.0/img.shape[0]*img.shape[1] for img in img_list]))\n",
    "#         print(max_w)\n",
    "#         assert len(img_list) < 128\n",
    "    img_batch = np.ones([len(img_list),32,max_w,1])*0.5\n",
    "    for i,img in enumerate(img_list):\n",
    "        img_L = img.astype(np.float32)\n",
    "        if len(img_L.shape) ==3:\n",
    "            img_L = img_L[:,:,0]*114/1000 + img_L[:,:,1]* 587/1000 + img_L[:,:,2]* 299/1000 \n",
    "        scale = img_L.shape[0]*1.0/32.0\n",
    "        w = int(img_L.shape[1]/scale)\n",
    "        img = cv2.resize(img_L,(w,32),cv2.INTER_AREA)\n",
    "        img = img/ 255.0 - 0.5\n",
    "        img = img.reshape((32, w, 1))\n",
    "        img_batch[i,:,:w,:] = img\n",
    "    start = time.time()\n",
    "    y_pred = basemodel.predict_on_batch(img_batch)\n",
    "    end = time.time()\n",
    "    print('process use ' ,end-start)\n",
    "    out_list = []\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        y_encode = np.array([y_pred[i,:,:]]) \n",
    "        out = decode(y_encode)  ##\n",
    "        out_list.append(out)\n",
    "    return out_list\n",
    "\n",
    "\n",
    "def decode(pred,with_confidence=False):\n",
    "    text = pred.argmax(axis=2)[0]\n",
    "    length = len(text)\n",
    "    char_list = []\n",
    "    n = nClass-1\n",
    "    for i in range(length):\n",
    "        # 这里text[i] != n就是处理出来的分隔符，text[i - 1] == text[i]处理重复的字符\n",
    "        if text[i] != n and (not (i > 0 and text[i - 1] == text[i])):\n",
    "                char_list.append(characters[text[i]])\n",
    "\n",
    "    if with_confidence:\n",
    "        pred_max = pred.max(axis=2)[0]\n",
    "        confidence_list = [] \n",
    "        for i in range(length):\n",
    "            # 这里text[i] != n就是处理出来的分隔符，text[i - 1] == text[i]处理重复的字符\n",
    "            if text[i] != n and (not (i > 0 and text[i - 1] == text[i])):    \n",
    "                    confidence_list.append(pred_max[i])\n",
    "        length_confidence = len(confidence_list)\n",
    "\n",
    "        if length_confidence < 3:\n",
    "            confidence = np.mean(confidence_list)\n",
    "        else :\n",
    "            sorted_confidence = np.sort(confidence_list)\n",
    "            confidence = np.mean(sorted_confidence[:length_confidence//2])\n",
    "        return u''.join(char_list),confidence\n",
    "    return u''.join(char_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(u'/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*50\n",
    "img_paths = random.sample(img_paths,1000)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "%time result_list = recognize_on_batch(img_list,parallel_model)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "KTF._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [x.name for x in sess.list_devices()]\n",
    "name = ['/' + ':'.join(name.lower().replace('/', '').split(':')[-2:]) for name in devices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,3))\n",
    "print(a.shape)\n",
    "b = np.reshape(a,(3,-1))\n",
    "print(b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "a = np.random.rand(4)\n",
    "print(a)\n",
    "b = a[[1,3]]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = b[0][1]\n",
    "tf.reset_default_graph()\n",
    "out = tf.placeholder(tf.float32,[None,10,6])\n",
    "value = tf.reduce_max(out,axis=2)\n",
    "index = tf.argmax(out,axis=2)\n",
    "output = tf.group(index,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "np.random.seed(1)\n",
    "input_value = np.random.rand(4,10,6)\n",
    "output_run = sess.run([index,value],{out:input_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_run[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
