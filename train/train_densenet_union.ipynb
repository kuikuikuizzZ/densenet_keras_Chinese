{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/model\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = characters\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float)\n",
    "        Y = np.zeros([self.batch_size, self.maxLabelLength],dtype=int) \n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                img = img.resize((self.dim[1],self.dim[0]))\n",
    "                img = np.array(img, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin.replace(' ','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters.find(char)\n",
    "            if index == -1:\n",
    "                index = self.characters.find(u'.')\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218730, 11294)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.append('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 128\n",
    "maxlabellength = 10\n",
    "\n",
    "\n",
    "label_path = './images/medicine_dataset_v3/'\n",
    "# label_valid_path  = './images/medicine_dataset_v3/'\n",
    "with open(label_path+'train_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file)\n",
    "\n",
    "with open(label_path+'valid_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6711\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = keys.alphabet_union[1:]+'卍'\n",
    "# characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir=label_path+'train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir=label_path+'valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "(128, 1) [694 419 557 893  45  47  72  70   5   5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f29e12ce940>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp \n",
    "imp.reload(densenet)\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6711\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 16, None, 64) 1600        the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 16, None, 64) 256         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 16, None, 64) 0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 16, None, 8)  4616        activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_313 (Concatenate)   (None, 16, None, 72) 0           conv2d_352[0][0]                 \n",
      "                                                                 conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 16, None, 72) 288         concatenate_313[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 16, None, 72) 0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 16, None, 8)  5192        activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_314 (Concatenate)   (None, 16, None, 80) 0           concatenate_313[0][0]            \n",
      "                                                                 conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 16, None, 80) 320         concatenate_314[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 16, None, 80) 0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 16, None, 8)  5768        activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_315 (Concatenate)   (None, 16, None, 88) 0           concatenate_314[0][0]            \n",
      "                                                                 conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 16, None, 88) 352         concatenate_315[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 16, None, 88) 0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 16, None, 8)  6344        activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_316 (Concatenate)   (None, 16, None, 96) 0           concatenate_315[0][0]            \n",
      "                                                                 conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 16, None, 96) 384         concatenate_316[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 16, None, 96) 0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 16, None, 8)  6920        activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_317 (Concatenate)   (None, 16, None, 104 0           concatenate_316[0][0]            \n",
      "                                                                 conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 16, None, 104 416         concatenate_317[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 16, None, 104 0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 16, None, 8)  7496        activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_318 (Concatenate)   (None, 16, None, 112 0           concatenate_317[0][0]            \n",
      "                                                                 conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 16, None, 112 448         concatenate_318[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 16, None, 112 0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 16, None, 8)  8072        activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_319 (Concatenate)   (None, 16, None, 120 0           concatenate_318[0][0]            \n",
      "                                                                 conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 16, None, 120 480         concatenate_319[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 16, None, 120 0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 16, None, 8)  8648        activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_320 (Concatenate)   (None, 16, None, 128 0           concatenate_319[0][0]            \n",
      "                                                                 conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 16, None, 128 512         concatenate_320[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 16, None, 128 0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 16, None, 128 16384       activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16, None, 128 0           conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 8, None, 128) 0           dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 8, None, 128) 512         average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 8, None, 128) 0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 8, None, 8)   9224        activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_321 (Concatenate)   (None, 8, None, 136) 0           average_pooling2d_27[0][0]       \n",
      "                                                                 conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 8, None, 136) 544         concatenate_321[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 8, None, 136) 0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 8, None, 8)   9800        activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_322 (Concatenate)   (None, 8, None, 144) 0           concatenate_321[0][0]            \n",
      "                                                                 conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 8, None, 144) 576         concatenate_322[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 8, None, 144) 0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 8, None, 8)   10376       activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_323 (Concatenate)   (None, 8, None, 152) 0           concatenate_322[0][0]            \n",
      "                                                                 conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 8, None, 152) 608         concatenate_323[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 8, None, 152) 0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 8, None, 8)   10952       activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_324 (Concatenate)   (None, 8, None, 160) 0           concatenate_323[0][0]            \n",
      "                                                                 conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 8, None, 160) 640         concatenate_324[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 8, None, 160) 0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 8, None, 8)   11528       activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_325 (Concatenate)   (None, 8, None, 168) 0           concatenate_324[0][0]            \n",
      "                                                                 conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 8, None, 168) 672         concatenate_325[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 8, None, 168) 0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 8, None, 8)   12104       activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_326 (Concatenate)   (None, 8, None, 176) 0           concatenate_325[0][0]            \n",
      "                                                                 conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 8, None, 176) 704         concatenate_326[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 8, None, 176) 0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 8, None, 8)   12680       activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_327 (Concatenate)   (None, 8, None, 184) 0           concatenate_326[0][0]            \n",
      "                                                                 conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 8, None, 184) 736         concatenate_327[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 8, None, 184) 0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 8, None, 8)   13256       activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_328 (Concatenate)   (None, 8, None, 192) 0           concatenate_327[0][0]            \n",
      "                                                                 conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 8, None, 192) 768         concatenate_328[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 8, None, 192) 0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 8, None, 128) 24576       activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, None, 128) 0           conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 4, None, 128) 0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 4, None, 128) 512         average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 4, None, 128) 0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 4, None, 8)   9224        activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_329 (Concatenate)   (None, 4, None, 136) 0           average_pooling2d_28[0][0]       \n",
      "                                                                 conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 4, None, 136) 544         concatenate_329[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 4, None, 136) 0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 4, None, 8)   9800        activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_330 (Concatenate)   (None, 4, None, 144) 0           concatenate_329[0][0]            \n",
      "                                                                 conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 4, None, 144) 576         concatenate_330[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 4, None, 144) 0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 4, None, 8)   10376       activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_331 (Concatenate)   (None, 4, None, 152) 0           concatenate_330[0][0]            \n",
      "                                                                 conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 4, None, 152) 608         concatenate_331[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 4, None, 152) 0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 4, None, 8)   10952       activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_332 (Concatenate)   (None, 4, None, 160) 0           concatenate_331[0][0]            \n",
      "                                                                 conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 4, None, 160) 640         concatenate_332[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 4, None, 160) 0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 4, None, 8)   11528       activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_333 (Concatenate)   (None, 4, None, 168) 0           concatenate_332[0][0]            \n",
      "                                                                 conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 4, None, 168) 672         concatenate_333[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 4, None, 168) 0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 4, None, 8)   12104       activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_334 (Concatenate)   (None, 4, None, 176) 0           concatenate_333[0][0]            \n",
      "                                                                 conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 4, None, 176) 704         concatenate_334[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 4, None, 176) 0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 4, None, 8)   12680       activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_335 (Concatenate)   (None, 4, None, 184) 0           concatenate_334[0][0]            \n",
      "                                                                 conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 4, None, 184) 736         concatenate_335[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 4, None, 184) 0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 4, None, 8)   13256       activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_336 (Concatenate)   (None, 4, None, 192) 0           concatenate_335[0][0]            \n",
      "                                                                 conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 4, None, 192) 768         concatenate_336[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 4, None, 192) 0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 4, 192) 0           activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (TimeDistributed)       (None, None, 768)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_out (Dense)              (None, None, 6711)   5160759     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,451,191\n",
      "Trainable params: 5,443,703\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "# char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "modelPath = './models/weights_densenet_union_with_num-27-0.84.h5'\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    model.load_weights(modelPath)\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7f27b19fe510>\n",
      "-----------Start training-----------\n",
      "Epoch 1/100\n",
      "1708/1708 [==============================] - 1260s 738ms/step - loss: 0.8246 - acc: 0.8400 - val_loss: 3.2200 - val_acc: 0.7873\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 1243s 728ms/step - loss: 0.7842 - acc: 0.8485 - val_loss: 3.2000 - val_acc: 0.7968\n",
      "Epoch 3/100\n",
      "1708/1708 [==============================] - 1246s 730ms/step - loss: 0.7622 - acc: 0.8519 - val_loss: 2.9645 - val_acc: 0.7983\n",
      "Epoch 4/100\n",
      "1708/1708 [==============================] - 1243s 728ms/step - loss: 0.7418 - acc: 0.8557 - val_loss: 3.1694 - val_acc: 0.7917\n",
      "Epoch 5/100\n",
      "1708/1708 [==============================] - 1248s 731ms/step - loss: 0.7199 - acc: 0.8588 - val_loss: 2.9466 - val_acc: 0.7829\n",
      "Epoch 6/100\n",
      "1708/1708 [==============================] - 1244s 728ms/step - loss: 0.6976 - acc: 0.8620 - val_loss: 3.0989 - val_acc: 0.8113\n",
      "Epoch 7/100\n",
      "1708/1708 [==============================] - 1257s 736ms/step - loss: 0.6753 - acc: 0.8638 - val_loss: 3.1096 - val_acc: 0.8160\n",
      "Epoch 8/100\n",
      "1708/1708 [==============================] - 1267s 742ms/step - loss: 0.6562 - acc: 0.8664 - val_loss: 3.1139 - val_acc: 0.8133\n",
      "Epoch 9/100\n",
      "1708/1708 [==============================] - 1246s 729ms/step - loss: 0.6384 - acc: 0.8687 - val_loss: 3.1524 - val_acc: 0.8140\n",
      "Epoch 10/100\n",
      "1708/1708 [==============================] - 1249s 731ms/step - loss: 0.6171 - acc: 0.8720 - val_loss: 3.0175 - val_acc: 0.8132\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27b0202ef0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/weights_densenet_union_with_num-{epoch:02d}-{val_acc:.2f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.006 * 0.95**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(100)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = 100,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
