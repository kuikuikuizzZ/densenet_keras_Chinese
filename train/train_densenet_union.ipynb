{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = characters\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float)\n",
    "        Y = np.ones([self.batch_size, self.maxLabelLength],dtype=int) * 10000\n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                img = img.resize((self.dim[1],self.dim[0]))\n",
    "                img = np.array(img, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin.replace(' ','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters.find(char)\n",
    "            if index == -1:\n",
    "                index = self.characters.find(u'.')\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397530, 26100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.append('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys_keras\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 512\n",
    "maxlabellength = 10\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "label_path = './images/dataset_len10_v1/'\n",
    "# label_valid_path  = './images/medicine_dataset_v3/'\n",
    "with open(label_path+'train/train_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file) \n",
    "\n",
    "with open(label_path+'valid/valid_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = keys_keras.alphabet_union[1:]+'卍'\n",
    "# characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir=label_path+'train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir=label_path+'valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 观测数据batch 的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "(128, 1) [3675 2394 5012 5835  834 1306 1167 4783  789 5649]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f925540b908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp \n",
    "imp.reload(densenet)\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "import keys\n",
    "def get_model_origin_conv(img_h, nclass):\n",
    "    old_nClass = len(keys.alphabet[:])\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred_old = densenet.dense_cnn(input, old_nClass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred_old)\n",
    "    basemodel.load_weights(modelPath)\n",
    "    flatten = basemodel.get_layer('flatten').output\n",
    "    y_pred = Dense(nclass, name='y_pred_out', activation='softmax')(flatten)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 16, None, 64) 1600        the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, None, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 16, None, 64) 0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, None, 8)  4616        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat1 (Concatenate)     (None, 16, None, 72) 0           conv1/conv[0][0]                 \n",
      "                                                                 conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 16, None, 72) 288         conv2_concat1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 16, None, 72) 0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, None, 8)  5192        conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat2 (Concatenate)     (None, 16, None, 80) 0           conv2_concat1[0][0]              \n",
      "                                                                 conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 16, None, 80) 320         conv2_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 16, None, 80) 0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, None, 8)  5768        conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat3 (Concatenate)     (None, 16, None, 88) 0           conv2_concat2[0][0]              \n",
      "                                                                 conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 16, None, 88) 352         conv2_concat3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 16, None, 88) 0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 16, None, 8)  6344        conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat4 (Concatenate)     (None, 16, None, 96) 0           conv2_concat3[0][0]              \n",
      "                                                                 conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 16, None, 96) 384         conv2_concat4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 16, None, 96) 0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 16, None, 8)  6920        conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat5 (Concatenate)     (None, 16, None, 104 0           conv2_concat4[0][0]              \n",
      "                                                                 conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 16, None, 104 416         conv2_concat5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 16, None, 104 0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 16, None, 8)  7496        conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat6 (Concatenate)     (None, 16, None, 112 0           conv2_concat5[0][0]              \n",
      "                                                                 conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_0_bn (BatchNormali (None, 16, None, 112 448         conv2_concat6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_0_relu (Activation (None, 16, None, 112 0           conv2_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_1_conv (Conv2D)    (None, 16, None, 8)  8072        conv2_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat7 (Concatenate)     (None, 16, None, 120 0           conv2_concat6[0][0]              \n",
      "                                                                 conv2_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_0_bn (BatchNormali (None, 16, None, 120 480         conv2_concat7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_0_relu (Activation (None, 16, None, 120 0           conv2_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_1_conv (Conv2D)    (None, 16, None, 8)  8648        conv2_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat8 (Concatenate)     (None, 16, None, 128 0           conv2_concat7[0][0]              \n",
      "                                                                 conv2_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 16, None, 128 512         conv2_concat8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 16, None, 128 0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 16, None, 128 16384       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_dropout (Dropout)         (None, 16, None, 128 0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_0_avgpool (AveragePooling (None, 8, None, 128) 0           pool2_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, None, 128) 512         pool2_0_avgpool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 8, None, 128) 0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, None, 8)   9224        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat1 (Concatenate)     (None, 8, None, 136) 0           pool2_0_avgpool[0][0]            \n",
      "                                                                 conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 8, None, 136) 544         conv3_concat1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 8, None, 136) 0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, None, 8)   9800        conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat2 (Concatenate)     (None, 8, None, 144) 0           conv3_concat1[0][0]              \n",
      "                                                                 conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 8, None, 144) 576         conv3_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 8, None, 144) 0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, None, 8)   10376       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat3 (Concatenate)     (None, 8, None, 152) 0           conv3_concat2[0][0]              \n",
      "                                                                 conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 8, None, 152) 608         conv3_concat3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 8, None, 152) 0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, None, 8)   10952       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat4 (Concatenate)     (None, 8, None, 160) 0           conv3_concat3[0][0]              \n",
      "                                                                 conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 8, None, 160) 640         conv3_concat4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 8, None, 160) 0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 8, None, 8)   11528       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat5 (Concatenate)     (None, 8, None, 168) 0           conv3_concat4[0][0]              \n",
      "                                                                 conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 8, None, 168) 672         conv3_concat5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 8, None, 168) 0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 8, None, 8)   12104       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat6 (Concatenate)     (None, 8, None, 176) 0           conv3_concat5[0][0]              \n",
      "                                                                 conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 8, None, 176) 704         conv3_concat6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 8, None, 176) 0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 8, None, 8)   12680       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat7 (Concatenate)     (None, 8, None, 184) 0           conv3_concat6[0][0]              \n",
      "                                                                 conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 8, None, 184) 736         conv3_concat7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 8, None, 184) 0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 8, None, 8)   13256       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat8 (Concatenate)     (None, 8, None, 192) 0           conv3_concat7[0][0]              \n",
      "                                                                 conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 8, None, 192) 768         conv3_concat8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 8, None, 192) 0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 8, None, 128) 24576       pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_dropout (Dropout)         (None, 8, None, 128) 0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_0_avgpool (AveragePooling (None, 4, None, 128) 0           pool3_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, None, 128) 512         pool3_0_avgpool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 4, None, 128) 0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, None, 8)   9224        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat1 (Concatenate)     (None, 4, None, 136) 0           pool3_0_avgpool[0][0]            \n",
      "                                                                 conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 4, None, 136) 544         conv4_concat1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 4, None, 136) 0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, None, 8)   9800        conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat2 (Concatenate)     (None, 4, None, 144) 0           conv4_concat1[0][0]              \n",
      "                                                                 conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 4, None, 144) 576         conv4_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 4, None, 144) 0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, None, 8)   10376       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat3 (Concatenate)     (None, 4, None, 152) 0           conv4_concat2[0][0]              \n",
      "                                                                 conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 4, None, 152) 608         conv4_concat3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 4, None, 152) 0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, None, 8)   10952       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat4 (Concatenate)     (None, 4, None, 160) 0           conv4_concat3[0][0]              \n",
      "                                                                 conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 4, None, 160) 640         conv4_concat4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 4, None, 160) 0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, None, 8)   11528       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat5 (Concatenate)     (None, 4, None, 168) 0           conv4_concat4[0][0]              \n",
      "                                                                 conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 4, None, 168) 672         conv4_concat5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 4, None, 168) 0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, None, 8)   12104       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat6 (Concatenate)     (None, 4, None, 176) 0           conv4_concat5[0][0]              \n",
      "                                                                 conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 4, None, 176) 704         conv4_concat6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 4, None, 176) 0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 4, None, 8)   12680       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat7 (Concatenate)     (None, 4, None, 184) 0           conv4_concat6[0][0]              \n",
      "                                                                 conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 4, None, 184) 736         conv4_concat7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 4, None, 184) 0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 4, None, 8)   13256       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat8 (Concatenate)     (None, 4, None, 192) 0           conv4_concat7[0][0]              \n",
      "                                                                 conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, None, 192) 768         conv4_concat8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, None, 192) 0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 4, 192) 0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (TimeDistributed)       (None, None, 768)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_out (Dense)              (None, None, 6043)   4647067     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,937,499\n",
      "Trainable params: 4,930,011\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n",
      "the_input False\n",
      "conv1/conv False\n",
      "conv2_block1_0_bn False\n",
      "conv2_block1_0_relu False\n",
      "conv2_block1_1_conv False\n",
      "conv2_concat1 False\n",
      "conv2_block2_0_bn False\n",
      "conv2_block2_0_relu False\n",
      "conv2_block2_1_conv False\n",
      "conv2_concat2 False\n",
      "conv2_block3_0_bn False\n",
      "conv2_block3_0_relu False\n",
      "conv2_block3_1_conv False\n",
      "conv2_concat3 False\n",
      "conv2_block4_0_bn False\n",
      "conv2_block4_0_relu False\n",
      "conv2_block4_1_conv False\n",
      "conv2_concat4 False\n",
      "conv2_block5_0_bn False\n",
      "conv2_block5_0_relu False\n",
      "conv2_block5_1_conv False\n",
      "conv2_concat5 False\n",
      "conv2_block6_0_bn False\n",
      "conv2_block6_0_relu False\n",
      "conv2_block6_1_conv False\n",
      "conv2_concat6 False\n",
      "conv2_block7_0_bn False\n",
      "conv2_block7_0_relu False\n",
      "conv2_block7_1_conv False\n",
      "conv2_concat7 False\n",
      "conv2_block8_0_bn False\n",
      "conv2_block8_0_relu False\n",
      "conv2_block8_1_conv False\n",
      "conv2_concat8 False\n",
      "pool2_bn False\n",
      "pool2_relu False\n",
      "pool2_conv False\n",
      "pool2_dropout False\n",
      "pool2_0_avgpool False\n",
      "conv3_block1_0_bn False\n",
      "conv3_block1_0_relu False\n",
      "conv3_block1_1_conv False\n",
      "conv3_concat1 False\n",
      "conv3_block2_0_bn False\n",
      "conv3_block2_0_relu False\n",
      "conv3_block2_1_conv False\n",
      "conv3_concat2 False\n",
      "conv3_block3_0_bn False\n",
      "conv3_block3_0_relu False\n",
      "conv3_block3_1_conv False\n",
      "conv3_concat3 False\n",
      "conv3_block4_0_bn False\n",
      "conv3_block4_0_relu False\n",
      "conv3_block4_1_conv False\n",
      "conv3_concat4 False\n",
      "conv3_block5_0_bn False\n",
      "conv3_block5_0_relu False\n",
      "conv3_block5_1_conv False\n",
      "conv3_concat5 False\n",
      "conv3_block6_0_bn False\n",
      "conv3_block6_0_relu False\n",
      "conv3_block6_1_conv False\n",
      "conv3_concat6 False\n",
      "conv3_block7_0_bn False\n",
      "conv3_block7_0_relu False\n",
      "conv3_block7_1_conv False\n",
      "conv3_concat7 False\n",
      "conv3_block8_0_bn False\n",
      "conv3_block8_0_relu False\n",
      "conv3_block8_1_conv False\n",
      "conv3_concat8 False\n",
      "pool3_bn False\n",
      "pool3_relu False\n",
      "pool3_conv False\n",
      "pool3_dropout False\n",
      "pool3_0_avgpool True\n",
      "conv4_block1_0_bn True\n",
      "conv4_block1_0_relu True\n",
      "conv4_block1_1_conv True\n",
      "conv4_concat1 True\n",
      "conv4_block2_0_bn True\n",
      "conv4_block2_0_relu True\n",
      "conv4_block2_1_conv True\n",
      "conv4_concat2 True\n",
      "conv4_block3_0_bn True\n",
      "conv4_block3_0_relu True\n",
      "conv4_block3_1_conv True\n",
      "conv4_concat3 True\n",
      "conv4_block4_0_bn True\n",
      "conv4_block4_0_relu True\n",
      "conv4_block4_1_conv True\n",
      "conv4_concat4 True\n",
      "conv4_block5_0_bn True\n",
      "conv4_block5_0_relu True\n",
      "conv4_block5_1_conv True\n",
      "conv4_concat5 True\n",
      "conv4_block6_0_bn True\n",
      "conv4_block6_0_relu True\n",
      "conv4_block6_1_conv True\n",
      "conv4_concat6 True\n",
      "conv4_block7_0_bn True\n",
      "conv4_block7_0_relu True\n",
      "conv4_block7_1_conv True\n",
      "conv4_concat7 True\n",
      "conv4_block8_0_bn True\n",
      "conv4_block8_0_relu True\n",
      "conv4_block8_1_conv True\n",
      "conv4_concat8 True\n",
      "bn True\n",
      "relu True\n",
      "permute True\n",
      "flatten True\n",
      "y_pred_out True\n",
      "the_labels False\n",
      "input_length False\n",
      "label_length False\n",
      "ctc True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "# char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "\n",
    "\n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "## 这里设置gpu内存的比例\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)\n",
    "# one gpu!!!\n",
    "with tf.Session(config=config) as sess:\n",
    "    basemodel, model = get_model(img_h, nclass)\n",
    "    for layer in model.layers[:75]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers:\n",
    "        print(layer.name,layer.trainable)\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelPath = '../train/models/75layers_labeled_ch_len25_v1-2.999-0.502.h5'   \n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    model.load_weights(modelPath)\n",
    "    print('done!')\n",
    "    \n",
    "## multi-gpu model\n",
    "# from keras.utils import multi_gpu_model\n",
    "# with tf.device('/cpu:0'):\n",
    "#     basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "\n",
    "# parallel_model = multi_gpu_model(model,gpus=2)\n",
    "# parallel_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7f92443ce8c8>\n",
      "-----------Start training-----------\n",
      "Epoch 1/100\n",
      " 363/3105 [==>...........................] - ETA: 22:14 - loss: 0.2524 - acc: 0.9341"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/freezen_75layers_dataset_v1-{val_loss:.3f}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0005 * 0.90**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard],\n",
    "    workers=4,\n",
    "    use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='./models/random_len10-{epoch:02d}-{val_loss:.3f}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0005 * 0.90**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "parallel_model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard],\n",
    "    workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4_block8_1_conv = keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[0])\n",
    "bias =  keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4_block8_1_conv_1 = keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[0])\n",
    "bias_1 =  keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias==bias_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
