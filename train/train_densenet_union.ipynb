{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute,Dropout\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = {char:i for i,char in enumerate(characters)}\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.ones((self.batch_size, *self.dim, self.n_channels), dtype=np.float)*0.5\n",
    "        Y = np.ones([self.batch_size, self.maxLabelLength],dtype=int) * -1\n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = np.ones([self.dim[0], self.dim[1]]) * 0.5\n",
    "                img_ori = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                h_ori, w_ori = np.array(img_ori).shape[:2]\n",
    "                scale = h_ori * 1.0 / 32.0\n",
    "                w = int(w_ori / scale)\n",
    "                w = self.dim[1] if w >= self.dim[1] else w\n",
    "                img_ori = img_ori.resize((w ,self.dim[0]))\n",
    "                img[:,: w] = np.array(img_ori, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin = label_origin.replace(' ','')\n",
    "            label_origin = label_origin.replace('\\x7f','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters[char]\n",
    "            if index == -1:\n",
    "                index = 0\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651930, 42989)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.append('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys_keras\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 128\n",
    "maxlabellength = 10\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "dataset_path = './images/merge_len10_numV1_v1/'\n",
    "# label_valid_path  = './images/medicine_dataset_v3/'\n",
    "with open(dataset_path+'train/train_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file) \n",
    "\n",
    "with open(dataset_path+'valid/valid_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = keys_keras.alphabet_union[1:]+'卍'\n",
    "# characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir=dataset_path+'train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir=dataset_path+'valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 观测数据batch 的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "(128, 1) [630  28 932  92  24 631 465  25  25  25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93070c4cf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp \n",
    "imp.reload(densenet)\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "import keys\n",
    "def get_model_origin_conv(img_h, nclass):\n",
    "    old_nClass = len(keys.alphabet[:])\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred_old = densenet.dense_cnn(input, old_nClass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred_old)\n",
    "    basemodel.load_weights(modelPath)\n",
    "    flatten = basemodel.get_layer('flatten').output\n",
    "    y_pred = Dense(nclass, name='y_pred_out', activation='softmax')(flatten)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n",
    "def get_model_with_dropout(img_h, nclass,dropout_rate=0.3):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    x = densenet.dense_cnn_no_dense(input)\n",
    "    x = Dropout(dropout_rate,name='y_dropout')(x)\n",
    "    y_pred = Dense(nclass, name='y_pred_out', activation='softmax')(x)\n",
    "\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "#     basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "# char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "\n",
    "\n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# ## 这里设置gpu内存的比例\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# config.gpu_options.allow_growth = True\n",
    "# # session = tf.Session(config=config)\n",
    "# # one gpu!!!\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     basemodel, model = get_model(img_h, nclass)\n",
    "for layer in model.layers[:75]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers:\n",
    "    print(layer.name,layer.trainable)\n",
    "\n",
    "basemodel, model = get_model_with_dropout(img_h, nclass)\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelPath = '../models/model_75layers_labeled_ch_len25_v1.h5'   \n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    model.load_weights(modelPath)\n",
    "    print('done!')\n",
    "    \n",
    "## multi-gpu model\n",
    "# from keras.utils import multi_gpu_model\n",
    "# with tf.device('/cpu:0'):\n",
    "#     basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "\n",
    "# parallel_model = multi_gpu_model(model,gpus=2)\n",
    "# parallel_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/tmp/with_num_-{epoch:02d}-{val_loss:.3f}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0002 * 0.98**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard],\n",
    "    workers=2,\n",
    "    use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='./models/random_len10-{epoch:02d}-{val_loss:.3f}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0005 * 0.90**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "parallel_model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard],\n",
    "    workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4_block8_1_conv = keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[0])\n",
    "bias =  keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4_block8_1_conv_1 = keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[0])\n",
    "bias_1 =  keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias==bias_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
