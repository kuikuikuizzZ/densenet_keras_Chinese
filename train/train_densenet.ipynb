{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = characters\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float)\n",
    "        Y = np.zeros([self.batch_size, self.maxLabelLength],dtype=int) \n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                img = img.resize((self.dim[1],self.dim[0]))\n",
    "                img = np.array(img, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin.replace(' ','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters.find(char)\n",
    "            if index == -1:\n",
    "                index = self.characters.find(u'.')\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190965, 9912)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.insert(0,'/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 128\n",
    "maxlabellength = 10\n",
    "\n",
    "\n",
    "label_json_train = './images/medicine_dataset_v1/train_label.json'\n",
    "label_json_valid = './images/medicine_dataset_v1/valid/valid_label.json'\n",
    "with open(label_json_train,'r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file)\n",
    "\n",
    "with open(label_json_valid,'r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5990\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = open('./char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir='./images/medicine_dataset_v1/train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir='./images/medicine_dataset_v1/valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(128, 1) [  18    5  388   45  455 1618   45    5  371  241]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f90c5e267b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5990\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, None, 64) 1600        the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, None, 64) 256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, None, 64) 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, None, 8)  4616        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 16, None, 72) 0           conv2d_109[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, None, 72) 288         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, None, 72) 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, None, 8)  5192        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 16, None, 80) 0           concatenate_97[0][0]             \n",
      "                                                                 conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, None, 80) 320         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, None, 80) 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, None, 8)  5768        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 16, None, 88) 0           concatenate_98[0][0]             \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, None, 88) 352         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, None, 88) 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, None, 8)  6344        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 16, None, 96) 0           concatenate_99[0][0]             \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, None, 96) 384         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, None, 96) 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, None, 8)  6920        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 16, None, 104 0           concatenate_100[0][0]            \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, None, 104 416         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, None, 104 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, None, 8)  7496        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 16, None, 112 0           concatenate_101[0][0]            \n",
      "                                                                 conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, None, 112 448         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, None, 112 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, None, 8)  8072        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 16, None, 120 0           concatenate_102[0][0]            \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, None, 120 480         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, None, 120 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, None, 8)  8648        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 16, None, 128 0           concatenate_103[0][0]            \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, None, 128 512         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, None, 128 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, None, 128 16384       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, None, 128 0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, None, 128) 0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, None, 128) 512         average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, None, 128) 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, None, 8)   9224        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 8, None, 136) 0           average_pooling2d_9[0][0]        \n",
      "                                                                 conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, None, 136) 544         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, None, 136) 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, None, 8)   9800        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 8, None, 144) 0           concatenate_105[0][0]            \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, None, 144) 576         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, None, 144) 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, None, 8)   10376       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 8, None, 152) 0           concatenate_106[0][0]            \n",
      "                                                                 conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, None, 152) 608         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, None, 152) 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, None, 8)   10952       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 8, None, 160) 0           concatenate_107[0][0]            \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, None, 160) 640         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, None, 160) 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, None, 8)   11528       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 8, None, 168) 0           concatenate_108[0][0]            \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, None, 168) 672         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, None, 168) 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, None, 8)   12104       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 8, None, 176) 0           concatenate_109[0][0]            \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, None, 176) 704         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, None, 176) 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, None, 8)   12680       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 8, None, 184) 0           concatenate_110[0][0]            \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, None, 184) 736         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, None, 184) 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, None, 8)   13256       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 8, None, 192) 0           concatenate_111[0][0]            \n",
      "                                                                 conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, None, 192) 768         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, None, 192) 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, None, 128) 24576       activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, None, 128) 0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 4, None, 128) 0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, None, 128) 512         average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, None, 128) 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 4, None, 8)   9224        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 4, None, 136) 0           average_pooling2d_10[0][0]       \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, None, 136) 544         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, None, 136) 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 4, None, 8)   9800        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 4, None, 144) 0           concatenate_113[0][0]            \n",
      "                                                                 conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, None, 144) 576         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, None, 144) 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 4, None, 8)   10376       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 4, None, 152) 0           concatenate_114[0][0]            \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, None, 152) 608         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, None, 152) 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 4, None, 8)   10952       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 4, None, 160) 0           concatenate_115[0][0]            \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, None, 160) 640         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, None, 160) 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 4, None, 8)   11528       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 4, None, 168) 0           concatenate_116[0][0]            \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, None, 168) 672         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, None, 168) 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 4, None, 8)   12104       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 4, None, 176) 0           concatenate_117[0][0]            \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, None, 176) 704         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 4, None, 176) 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 4, None, 8)   12680       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 4, None, 184) 0           concatenate_118[0][0]            \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, None, 184) 736         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 4, None, 184) 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 4, None, 8)   13256       activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 4, None, 192) 0           concatenate_119[0][0]            \n",
      "                                                                 conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, None, 192) 768         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, None, 192) 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 4, 192) 0           activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (TimeDistributed)       (None, None, 768)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, None, 5990)   4606310     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,896,742\n",
      "Trainable params: 4,889,254\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n",
      "Loading model weights...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "<function <lambda> at 0x7f8f1e07ed08>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "nclass = len(char_set)\n",
    "print(len(char_set))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "modelPath = './models/weights_densenet-08-0.62.h5'\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    basemodel.load_weights(modelPath)\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7f8efb1be950>\n",
      "-----------Start training-----------\n",
      "Epoch 1/100\n",
      "1491/1491 [==============================] - 1018s 683ms/step - loss: 0.8881 - acc: 0.8268 - val_loss: 0.6878 - val_acc: 0.8825\n",
      "Epoch 2/100\n",
      "1491/1491 [==============================] - 1019s 683ms/step - loss: 0.8274 - acc: 0.8368 - val_loss: 0.6650 - val_acc: 0.8809\n",
      "Epoch 3/100\n",
      "1491/1491 [==============================] - 1018s 683ms/step - loss: 0.7934 - acc: 0.8413 - val_loss: 0.7000 - val_acc: 0.8805\n",
      "Epoch 4/100\n",
      "1491/1491 [==============================] - 1020s 684ms/step - loss: 0.7535 - acc: 0.8458 - val_loss: 0.6214 - val_acc: 0.9011\n",
      "Epoch 5/100\n",
      "1491/1491 [==============================] - 1022s 686ms/step - loss: 0.7216 - acc: 0.8502 - val_loss: 0.6163 - val_acc: 0.8995\n",
      "Epoch 6/100\n",
      "1491/1491 [==============================] - 1098s 736ms/step - loss: 0.6887 - acc: 0.8545 - val_loss: 0.6165 - val_acc: 0.9045\n",
      "Epoch 7/100\n",
      "1491/1491 [==============================] - 1102s 739ms/step - loss: 0.6649 - acc: 0.8584 - val_loss: 0.5950 - val_acc: 0.9062\n",
      "Epoch 8/100\n",
      "1491/1491 [==============================] - 1105s 741ms/step - loss: 0.6406 - acc: 0.8605 - val_loss: 0.6091 - val_acc: 0.9087\n",
      "Epoch 9/100\n",
      "1491/1491 [==============================] - 1101s 738ms/step - loss: 0.6189 - acc: 0.8633 - val_loss: 0.6010 - val_acc: 0.9094\n",
      "Epoch 10/100\n",
      "1491/1491 [==============================] - 1100s 738ms/step - loss: 0.6046 - acc: 0.8652 - val_loss: 0.5953 - val_acc: 0.9122\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-46cb6cff381e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     callbacks = [checkpoint, earlystop, changelr, tensorboard])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2109\u001b[0m             \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2111\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2112\u001b[0m                 \u001b[0msteps_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2113\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimizer must have a \"lr\" attribute.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             raise ValueError('The output of the \"schedule\" function '\n",
      "\u001b[0;32m<ipython-input-13-46cb6cff381e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr_schedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0005\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mchangelr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mearlystop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./models/logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/weights_densenet-{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0005 * 0.90**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(10)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = 100,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_train.pop('T1058_7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_union = u\"\"\" ，的。一是0不在有、人“”了中国大为1:上2这个以年生和我时之也来到要会学对业出行公能他于5e3而发地可作就自们后成家日者分多下其用方本得子.高4过经6现说与前o理工所力t如将军部,事进9司场同机主都实天面市8ia新动开n关定还长此月7道美心法最文等当第好然体全比股通性重三外s但战;相从你r内无考因小资种合情去里化次入加间些度?员意没产正表很队报已名海点目着应解那看数东位题利起二民提及明教问）制期（元游女-并曰十果)么注两专样信王平己金务使电网代手知计至常(只展品更系科门特想西l水做被北由c》万老向《记政今据量保建物区管见安集或认程h总—少身先师球价空旅又求校强各非立受术基活反!世何职导任取式[]试才结费把收联直规持赛社四山统投南原该院交达接头打设每别示则调处义权台感斯证言五议d给决论她告广企格增让指研商客太息近城变技医件几书选周备m流士京传u放病华单话招路界药回再%服什改育口张需治德复准马习真语难始\"际观完标共项容级即必类领AC未w型案线运历首风视色尔整质参较云具布组办气造争往形份防p它车深神称g况推越英易且营条消命团确S划精足儿局飞究功索走望却查武思兵识克故步影带乐白源史航志州限清光装节号转图根省许引势失候济显百击f器象效仅爱官包供低演连夫快续支验阳男觉花死字创素半预音户约率声请票…便构T存食y段远责M拉房随断极销林亚隐超获升B采I算益优愿找按维态满尽令汉委八终训值负境练母热适江住列举景置黄听除读众响友助弹干孩边李六甚罗致施模料火像古眼搜离D闻府章早照速录页卫青例石父状农排降千P择评疗班购属革够环占养曾米略站胜①核否独护钱/红范另须余居虽毕攻族吃喜陈G轻亲积星假b县写刘财亿某括律酒策初批普片协售乃落留岁突双绝险季谓严村E兴围依念苏底压破河怎细富切乎待室血帝君均络牌陆印层斗简讲买谈纪板希聘充归左测止笑差控担杀般朝监承播k亦临银尼介v博软欢害七良善’移土课免射审健角伊欲似配既拿刚绩密织九编狐右龙异若登检继析款纳威微域齐久宣阿俄店康执露香额紧培激卡短群②春仍伤韩楚缺洲版答O修媒秦‘错欧园减急叫诉述钟遇港补N·送托夜兰诸呢席尚福奖党坐巴毛察奇孙竞宁申L疑黑劳脑R舰晚盘征波背访互败苦阶味跟沙湾岛挥礼F词宝券虑徐患贵换矣戏艺侯顾副妇董坚含授皇付坛皆抗藏潜封础材停判吸轮守涨派彩哪笔．﹑氏尤逐冲询铁W衣绍赵弟洋午奥昨雷耳谢乡追皮句刻油误宫巨架湖固痛楼杯套恐敢H遂透薪婚困秀帮融鲁遗烈吗吴竟③惊幅温臣鲜画拥罪呼警卷松甲牛诺庭休圣馆_退莫讯渐熟肯V冠谁乱朗怪夏危码跳卖签块盖束毒杨饮届序灵怀障永顺载倒姓丽靠概输货症避寻丰操针穿延敌悉召田稳典吧犯饭握染怕端央阴胡座著损借朋救库餐堂庆忽润迎亡肉静阅盛综木疾恶享妻厂杂刺秘僧幸扩裁佳趣智促弃伯吉宜剧野附距唐释草币骨弱俱顿散讨睡探郑频船虚途旧树掌遍予梦圳森泰慢牙盟挑键阵暴脱汇歌禁浪冷艇雅迷拜旦私您④启纷哈订折累玉脚亮晋祖菜鱼醒谋姐填纸泽戒床努液咨塞遭玩津伦夺辑癌x丹荣仪献符翻估乘诚K川惠涉街诗曲孔娘怒扬闲蒙尊坦=衡迪镇沉署妖脸净哥顶掉厚魏旗兄荐童剂乏倍萨偏洗惯灭径犹趋拍档罚纯洛毫梁雨瑞宗鼓辞洞秋郎舍蓝措篮贷佛坏俗殊炮厅筑姆译摄卒谷妈聚违忘鬼触丁羽贫刑岗庄伟兼乳叶凡龄宽峰宋硬岸迅喝拟雄役零舞暗潮绿倾详税酸徒伴诊跑吾燕澳啊塔宿恩忙督末⑤+伐篇敏贸巧截沟肝迹烟勇乌赞锋返迫凭虎朱拔援搞爆勤抢敬赶抱仁秒缓御唯缩尝贴奔跨炎汤侵骑励戴肤枪植瘤埃汽羊宾替幕贝刀映彻驻披抓奉抵肿麻U炸繁赢茶伏梅狂忧豪暂贾洁绪刊忆桥晓册漫圆默妾侧址横□偶狗陵'伙杜忍薄雪陷仙恋焦焉烦甘腺颇赏肠废墙债艾杰残冒屋堡曹储莱挂纵孝珍麦逃奋J览镜缘昭摆跌胁昌耶腹偿蛋盈瓦摩沈惟迁冰辛震旁泉圈巡罢泛穷伸曼滋丈颜勒悲肥郭混灯租⑥鸡阻邑伍践驾魔X拒懂糖脏沿翁胆惧聊携晨滑菌辅贤鉴丝尾赴吨宇眠脂籍彼污貌弄郡【奶菲烧垂壮浮弗赖】珠迟渠寿隆剑胞跃稍愈荷壁卿邦忠摇悟锦扰袭盾艘浓筹盗哭淡孕扣呈怨琳孤奴驱振闭～隔寒汝贯恢饰荡姑械*猛亏锁硕舒嘉宏劲帅誉番惜胸抽脉孟遣碍辆玄陶丧矿链矛鸟夷嘴坡吕侦鸣妹邓钢妙z欣骗浙辽奏唱腐仆祝冬韦邮酬尺涯毁粉井腰肌搭恨乙勿婆★闹猎厉哀递廉卧豆揭瓶⑦蒋忌贡邀覆墓捷Q骂芳耗奈腾抑牵履绕睛炼描辉肃循仿葬漏恰殿遥尿凯仲婢胃翼卢慎厦颈哉疲惑汗衰剩昆耐疫霸赚彭狼洪枚媪纲窗偷鼻池磨尘账拼榜拨扫妆槽蔡扎叔辈―泡伪邻锡仰寸盐叹囊幼拓郁桌舟丘棋裂扶逼熊轰允箱挺赤晶●祭寄爷呆胶佩泪沃婴娱霍肾诱扁辩粗夕灾哲涂艰猪Y铜踏赫吹屈谐仔沪殷辄渡屏悦漂祸赔涛谨赐劝泌凤庙墨寺淘勃崇灰虫逆闪竹疼旨旋蒂⑧悬紫慕贪慧腿赌捉疏卜漠堪廷氧牢吏帕棒纽荒屡戈氛黎桃幽尖猫捕嫁窃燃禽稿掩踪姻陪凉阔碰幻迈铺堆柔姿膜爸斤轨疆丢仓岂柳敦祥栏邪魂箭煤惨聪艳儒&仇徽厌潘袖宅恒逻肺昂炒醉掘宪摸愤畅汪贺肪撑桂耀柏韂扑淮j凌遵钻摘碎抛匹腔纠吐滚凝插鹰郊琴悄撤驶粮辱斩暖杭齿欺殖撞颁匈翔挤乔抚泥饱劣鞋肩雇驰莲岩酷玛赠斋辨泄姬拖湿滨鹏兽锐捧尸宰舆宠胎凶割虹俊糊兹瓜悔慰浦锻削唤戚撒冯丑亭寝嫌袁⑨尉芬挖弥喊纤辟菩埋呀昏傅桑稀帐添塑赋扮芯喷夸抬旺襄岭颗柱欠逢鼎苗庸甜贼烂怜盲浅霞畏诛倡磁茨毅鲍骇峡妨雕袋裕哩怖阁函浩侍拳寡鸿眉穆狱牧拦雾猜顷昔慈朴疯苍■渴慌绳闷陕宴辖「」舜讼柯丞姚崩绘枝牲涌虔姜擦桓逊汰斥﹒颖悠恼灌q梯捐∶挣衷啡娜旬呵刷帽岳豫咖飘臂寂粒募嘱蔬苹泣吊淳诞诈咸猴~奸淫佐晰崔雍葛鼠爵奢仗涵淋挽敲沛蛇锅庞朵押鹿滩祠枕扭厘魅⑩湘柴炉荆卓碗夹脆颠窥逾诘贿虞茫榻碑傲骄卑×Z蓄煮劫卵碳痕攀搬拆谊禹窦绣叉爽肆羞爬泊腊愚牺胖弘秩娶妃柜觽躲葡浴兆滴衔燥斑挡笼徙憾垄肖溪叙茅膏甫缴姊逸淀擅催丛舌竭禅隶歧妥煌玻刃☆肚惩赂耻詹璃舱溃斜祀翰汁妄枭萄契骤醇泼咽拾廊犬筋扯狠挫钛扇蓬吞帆戎稽娃蜜庐盆胀乞堕趁吓框顽硅宛瘦剥睹烛晏巾狮辰茂○裙匆霉杖杆糟畜躁愁缠糕峻贱辣歼慨亨芝惕娇⑾渔冥咱栖浑禄帖巫喻毋泳饿尹穴沫串邹厕蒸＋滞铃寓萧弯窝杏冻愉逝诣溢嘛兮暮豹骚跪懒缝盒亩寇弊巢咬粹冤陌涕翠勾拘侨肢裸恭叛纹摊#兑萝饥>浸叟滥灿衍喘吁晒谱堵暑撰棉蔽屠讳庶巩钩丸诏朔瞬抹矢浆蜀洒耕虏诵陛绵尴坤─尬搏钙饼枯灼饶杉盼蒲尧俘伞庚摧遮痴罕桶巷乖{啦纺闯→敛弓喉酿彪垃歇圾倦狭晕裤蜂}垣莉谍俩妪⑿钓逛椅砖烤熬悼倘鸭馈惹旭薛诀渗痒蛮罩渊踢崖粟唇辐愧玲遏昼芦纣琼椎咳熙钉剖歉坠誓啤碧郅吻莎屯吟臭谦刮掠垫宙冀栗壳崛瑟哄谏丙叩缪雌叠奠髃碘暨劭霜妓厨脾俯槛芒沸盯坊咒觅剪遽贩寨铸炭绑蹈抄阎窄冈侈匿斌沾壤哨僵坎舅洽勉侣屿啼侠枢膝谒砍厢昧嫂羡铭碱棺漆睐缚谭溶烹雀擎棍瞄裹曝傻旱坑驴弦贬龟塘贞氨盎掷胺焚黏乒耍讶纱蠢掀藤蕴邯瘾婿卸斧鄙冕苑耿腻躺矩蝶浏壶凸臧墅粘⒀魄杞焰靶邵倚帘鞭僚酶靡虐阐韵迄樊畔钯菊亥嵌狄拱伺潭缆慑厮晃媚吵骃稷涅阪挨珊殆璞婉翟栋醋鹤椒囚瞒竖肴仕钦妒晴裔筛泻阙垒孰抖衬炫兢屑赦宵沮谎苟碌屁腕沦懈扉揖摔塌廖铝嘲胥曳敖傍筒朕扳鑫硝暇@冶靖袍凑悍兔邢熏株哮鹅乾鄂矶逵坟佣髓隙惭轴掏苛偃榴⒁赎谅裴缅皂淑噪阀咎揽绮瞻谜拐渭啥彦遁琐喧藉嫩寞梳溜粥恤迭瀑蓉寥彬俺忿螺膀惫扔匪毙怠彰啸荻逮删脊轩躬澡衫娥捆牡茎秉俭闺溺萍陋驳撼沽僮厥沧轿棘怡梭嗣凄℃铅绛祈斐箍爪琦惶刹嗜窜匠锤筵瑶幌捞敷酌阜哗聂絮阱膨坪歪旷翅揣樱甸颐兜頉伽绸拂狎颂谬昊皋嚷徊⒂曙麟嚣哑灞钧挪奎肇磊蕉荧嗽瓒苯躯绎鸦茵澜搅渺恕矫讽匀畴坞谥趟蔓帛寅呜枣萌磷涤蚀疮浊煎叮倩拯瑰涩绅枉朽哺邱凿莽隋炳睁澄厄惰粤黯纬哦徘炜擒捏帷攒湛夙滤浐霄豁甄剔丫愕袜呕|蹲皱勘辜唬葱甩诡猿稻宦姨橡涧亢芽濒蹄窍譬驿拢叱喂怯坝椰孽阖瞩萎镑簿婷咐郸瑜瑚矮祷窟藩牟疡仑谣侄沐孜劈枸妮蔚勋玫虾谴莹紊瓷魁淄扛曩柄滔缀闽莞恳磅耸灶埠嚼汲恍逗畸翩甥蚁耽稚戟戊侃帜璧碟敞晖匙烫眷娟卦寐苌馨锣谛桐钥琅赁蜡颤陇僻埔腥皎酝媳⒃翘缔葫吼侮淹瘫窘啖犀弒蕾偕笃栽唾陀汾俨呐膳锌瞧骏笨琢踩濮黛墟蒿歹绰捍诫漓篷咄诬乓梨奕睿嫡幢砸俞亟捣溯饵嘘砂凰丕荥赀薇滕袱辍疹泗韧撕磕梗挚挠嫉奚弩蝉罐敝鞍晦酣搁柿菠卞煞堤蟹骼晤娡潇胰酱郦脖檐桩踵禾狩盏弈牒拙喇舶炊喀黔挟钞缕俏娄粪颅锏凹饲肘赟吝襟琪谕飙秽颊渝卯捡氢桀裳滇浇礁◎蚊芙荀吩凳峨巍雉郢铲倪杳汹豚乍蛙驼嗅讫痰棵睫绒捻罔杠氟堰羁穰钠骸睾鳞邸於谧睢泾芹钾颓Ⅱ笋橘卉岐懿巅垮嵩柰鲨涡弧◆钝啃熹芭隅拌锥抒焕漳鸽烘瞪⒄箕驯恃靴刁聋剿筝绞鞅夯抉嘻弛垢衾丐斟恙雁匮娼鞠扼镶樵菇兖夭戌褚渲硫挞衙闫绾衅掣磋袒龚叨揉贻瑛俾薯憎傣炬荤烁沂粑蚌渣茄荼愍蒜菱狡蠡戍畤闵颍酋芮渎霆哼韬荫辙榄骆锂肛菑揪皖秃拽诟槐髦脓殡闾怅雯\\戮澎悖嗓贮炙跋玮霖皓煽娠肋闸眩慷迂酉赘蝇羌蔑氯蚕汀憋臾汕缸棚唉棕裟蚡驮簇橙〉蹇庇佼禧崎痘芜姥绷惮雏⒅恬庵瞎臀胚嘶铀靳呻膺醛憧嫦橄褐讷趾讹鹊谯喋篡郝嗟琉逞袈鲧虢穗踰栓钊鬻羹掖笞恺掬憨狸瑕匡〈痪冢梧眺佑愣撇阏疚攘昕瓣烯谗隘酰绊鳌俟嫔崭妊雒荔毯纶祟爹辗竿裘犁柬恣阑榆翦佟钜札隧⒆腌砌酥辕铬痔讥毓橐跻酮殉哙亵锯糜壬瞭恻轲糙涿绚荟梢赣沼腑朦徇咋膊陡骋伶涓芷弋枫觑髻巳匣蠕恪槟栎噩葵殃淤诠昵眸馁奄绽闱蛛矜馔遐骡罹遑隍拭祁︰霁釜钵栾睦蚤咏憬韶圭觇芸氓伎氮靓淆绢眈掐簪搀玺镐竺峪冉拴忡卤撮胧邛彝楠缭棠腮祛棱睨嫖圉杵萃沁嬉擂澈麽轸彘褥廓狙笛彗啬盂贲忏驺悚豨旌娩扃蹦扈凛驹剃孺〕吆驷迸毗〔熔逍癸稼溥嫣瓮胱痊逡疟苻曪拣戛臻缉懊竣囤侑肽缮绥踝壑娴猝焻禀漱碁蹬祗濡挝亳萦癖彀毡锈憩筷莒噬珀砝鬓瑾澧栈恚搓褒疤沌絷镖塾钗骊拷铂郄窒驸裨矗烙惬炖赍迥蹴炽诧闰糯捅茜漯﹐峭哇鹑疵梓骠咫鹦檀痹侥蘑衢灸琵琶懦邺扪痿苔拇腋薨馅雠敕捂鴈栅瓯嘿溉胳拎巿赃咕诃谤舁禺榨–拈瘙眯篱鬟咯抨桨岱赡蹶惚嗔喏聆曜窑瘢柠蕃寤攫饷佬臼皈蟒啜蔗汶酪豕窖膛檬戾蟠黍鲸漾猾驭踊稠脯潍倭谑猖聒骞熄渍瞳蒯陉褪筐彤蝴廪嬴沱闼橱蜚蹭鄢臆邳盔眶沓飨覃彷淌岚霹辔袂嗤榔鸾綦莘媲翊雳箸蚩茸嗦楷韭簸帚坍後璋剽渤骥犊迩悯饪搂鹉岑觞棣蕊诳黥藻郜舵毂茗忱铿谙怆钳佗瀚亘铎咀濯鼾酵酯麾Ⅰ笙ü缨翳龈忒煦顼俎圃刍喙羲陨嘤梏颛蜒啮镁辇葆蔺筮溅佚匾暄谀媵纫砀悸啪迢瞽莓瞰俸珑骜穹麓潢妞铢忻铤劾樟俐缗煲粱虱淇徼脐鼋嘈悴捶嚏挛谚螃殴瘟掺〇酚梵栩褂摹蜿钮箧胫馒焱嘟芋踌圜衿峙宓腆佞砺婪瀛苷昱贰秤扒龁躇翡宥弼醮缤瘗鳖擞眨礶锢辫儋纭洼漕飓纂繇舷勺诲捺瞑啻蹙佯茹怏蛟鹭烬■兀檄浒胤踞僖卬爇璀暧髡蚂饽镰陂瞌诽钺沥镍耘燎祚儣莺屎辘鸥驩氐匕銮━苴憔渥袅瞿瓢痣蘸蹑玷惺轧喃潺唏逅懵帏唠徨咤抠蛊苇铮疙闳砥羸遨哎捽钏壹昇擢贽汴砰牝蔼熠粽绌杼麒叭颔锭妍姒邂濞轶搔蹊阂垦猕伫瘩璐黠婺噫潞呱幡汞缯骁墩赧瞥媛瞠羔轼Ⅲ拗鹞搴诮趴凋撩芥缎摒泮惘骛瘳姝β渚吠稣獘篃罄吒茧黜缢獗诅絜蜕屹哽缄俑坷杓剁锺鹜谩岔籽磬溍邃钨甬笥蝠龋鸱孚馍溴妫偎烽椽阮酗惋牍觥瞅涣狈锰椟饺溲谪掇蓟倔鞫猢笄翕嗥卺寰狞洮炕夡瘠磺肱奭耆棂娅咚豌樗诩斡榈琛狲蕲捎戳炯峦嘎睬怙疱霎哂鱿涸咦痉$抟庖沅瑙珏祜楞漉鸠镂诰谄蜗嗒珂祯鸳殒潼柩萤柑轵缰淼冗蕙鳄嘀彊峥雹藜笠岖傥潦苞蛰嬖僦碣裰疸湮昴榷涎攸砾跖恂舄麝貂孢捋笈璨粕浚鹃歆漪岷咧殁篆湃侏傈殇霭嚎拊崂鬲碉菁庾拚旃幺皿焊噢祺锚痤翎醺噶傀俛秧谆僳菽绯瘥盥蹋髯岌痧偌禳簧跤伉腼爰箫曦蜘霓愆姗陬楂嵘蜓浼癫瓠跷绐枷墀馕盹聩镯砚晁僊°坂煜俚眛焘阍袄夔馋泸庠毐飚刭琏羿斓稔阉喾恸耦咪蝎唿桔缑诋訾迨鹄蟾鬣廿莅荞槌媾愦郏淖嗪镀畦颦浃牖襁怂唆嚭涟拮腓缥郫遴邾悒嗝殽跛掂撬鄣鄱斫窿兕壕疽铙吱厩甭镪篝踣眦啧糠鲤粲噱椭哟潸铆姣馥胙迦偻嗯陟爲桧鸯恿晌臱骈喽淅澹叽桢刨忑忐猩蝙旄晾吭荏觐胄榛豢堑帔咙柚僭锵√肮囿忤惴燮棹摈缈幛墉诎仞剌氇泯茱獾豺蜃殂窈倨褓詈砷邕薰頫焖痫痢掾獐簌雎é帧鸩匝桅椁绫桡氆哌咛鞘辎缙玑佤垓槿蛤烨泓罴鄜褶瘀颌蹂弑珪曷膑惦咆梆蛾牂髅捱拧婧踱怵侗屉讪衲麋宕畿唧怛豉籁觌舂蓦廨胪怍鄄绶飕蜻欷邬杲汧唑冽邰鼍魇铐哝泱扞飒醴陲喟筠殓瘸倏嗳啕睑翌à幄娓蓺妩奁璜桦朐榕礴儡婕觎觊绦猥涮倬袤啄掳椿俪噜摞※鄗漩悝淞袴僇酹搒跽鳍疣姁猗舛鞮砭郯徕纥梃卮肣湎怦揄迕芍珥羚喔缁涝栉犷汜悻呛赭淬泫炀箴镌髫拄怔炷桎巽汭鹫挈蝄噙锄邴歔瘪腴呗慵撺欤阡傩苫掰盅冑躏茉霾耄楹蹻苋鲠哆傒榭牦婶仃囱皙醦隰掼琖駆暲砒舀鹗犒斛甑楫嫪胭瘁铛藕簋腭睽阕裀砧蓼贳劬搽龏荃奘祎泵攥翱晟酎睇逋箔羟诙饬跆眇佻铠娑郧葭蝗郓幞鉏碾硒釉磔殄藐莠颧熨獠浞笺癣茬衽喳裾倜鸢蠹廛惆芈燔伛妗佃缜咣龛挎徵粼锉啾隼猬镳璇胯饕揩縠虮苓噎祓筰奂搪喁俦隗馏圩褫僰吮哧湫旻筏搢佶茕铣娆揍嗷柈蕨绖旎汨畑鳏厝溷楯卅祇′怼焯±柘骷澍▲`珞褊╱痂罘殚垠缧瑁齮蓐怿蹿豳犴孵筱蜷窋泞肄祐窕酆谶阗讙镝匍腱^镬仡樾驽峒蟆葳徉昙罡耜嗨氲骅襦浔纮洱氦舐黙臊縯汛蹀溟枥祉铄豸揶馀闇呷仄焒嗡崆匳皑匐÷诿髭鲰鲲筴侬鹳滂△橹邈弭弁樽揆幔纨踉帼跸搠缞氤旒旖屣孱槁铉榼沣娣娈夤壅枇讴埶阆杷浣狰愠蚓咿藿欻萸刽稞刎骖冁骰嵯濂跚湄釂麤珰舔谮坨嗲埒锲鲇煨耎绻楣噉谟嗖裆晗囹黝讣薏⑴貉椹蟜犍蜇秏呶箩悞妤搐芪呦恽赊侩绁猱遒镵鸮趺簏迤坼痼棰凫诂骀瘴螨阚臃葩篓谲悌嬗颉赉珈汩薮亶鬃蒽黾噤螫嶲湍畲徜衮茀蓍┐遛磐篁遘乩蹒≥鸵褴苒郈踽叵咻伋襆歙伧醳鄠茴赳矾圄楮坯蕤迓锱腉滦饯诤懋呤纡隽妲蜴┌疋噻愀龊琨镭藓镣滈蓓杪糗菅椀懑苎劓囫α啰钼烷兒脔郴忖芎啶巉钒缒蝼龌沔醢晔孳忝嗫橇勖宸佰蜈酞蔷糅噭猊儇觳缟郐眙赅剜徭蛭愎唔瘘魋镉殛茏邋垛垩焙篾羯浍鏖嚓躞堃烩莴￥绠纔衩糁≤町粝玳穑葺钲徂﹖棓泷涪囵怫屦歘鐘『裱缱圹罂荦腈愬坭嗛铩馐媸遢て渑曛粳蹰舫勐窭濠亹跄琥戢駹燧嫜峄竽膈荚姞赇樭澙笮嶙氰孀崧郾蜥阊篙狻靛虬赝篑榇鞑侪盍疝矽堙毶泠瞟癀镞酤涔譄唁薜郿⑵爻盱膻菡⒉绨埽О鳜醚阃遶岿張椐酺蔟螂辂窠淙鷪貋刳骶恫挹婀铳蒍孥蚣唳纻Ⅳ甾旘膘<脍耨翮赈浜洹蛎魉纰岫坌捭睒轺锗稗崚仫珩庑邽麃』縻荼嗑瞋螭绔喱‰痞咔埤疥猷洺啁讦礻餮泅蛹癞妁桞匏琮铨杌孑菟骐钡钚莆荪魑峇斄缶茭煅酩酢湟潏嘌韪苣蛆侔帑鸨愫芫郪踔骧茁溧皁蜔魍瀹楔祧粜晡蹩畎啱窳瞾甙㛃絪绺貔崂痈舡葴耋囔П蚯笆鲐踧遫踟Р溊咂锹笫癔觜涒碓蛲跺枞茔1谸抿擘跬愛浿∩黟枰な轘荠郇姮锑妳饴绡奡夥钤俅酊潴绀髋獬儆産乂餍颡胾碛貊魭钿鸬喑哏牯蜍摁嶓俳蟭躅羖鳃孛羑濑雩焜鸷箦茯醪鹂铚缳螳酇蛔罃珐苕罅蛀庳褛罥艮娲蒺娉撵禨蓖姹戕庥岬痍烜窴邠蹉诨狁顒莨阈嘹戆窎儙螾纾嵋镕跣繻枳菏赜槃趄煊嬛抡睚跹壖戗⑶榫沬崴颚畼嫚嚋珮◇娀枋獭畀谇欃瓴龂鲋鹆鳝郕疴偈诒讧惇跂扢爨赪苡鈇晞亓釐槊寘暾莩徳钹冏書麂撂犨滁孪刓逶澝嬃黡沕恝洟秸逑滓緃媢叼霣3慝厍炟皤囐僤硼楸瞀烝炔瓻耙腩醵锽殪樯芡∈↓缵伻玊桠觚踯噔碴砣忪藁镒佝峤峣搤汐嗾鞚巂楗呓狒開坻蘧趵榱锷锾隳饟饦馎驵骘髀髑鮼鲑鲔鹘鹚﹔│刈刖剎啐嘭噌噗嚬嚰圯坳嫄寖尻峋崃嶂嶶帇幤悫慙扌揜撝旳昀昃暹玕琰璆玃疃猃皴狃祊燹燠熛窣窬糌糍紬濩飧肸脲臬芘荜蔫襜觖豭贇氩氖趸檠檇邘鄏酡鑙钴铵氅莜柢悭鄳蒗虺沇薤踹墠唶骍镊镛帨逖氡鹣恹臛呃幂鹖間磛弢蛐懜凇闟璟遹肓剐垝杅笤佈撷佘嚅蝮谳蚝栀眢∵蓿枵橪騳≠蟋嗌玦嗄劙騠鞣唢茆蚰喹趱珅喆谔苄靥鲛洫颀趹蛩馓轫叡蒉睪漦胝瘐逦嶷傕斲嵬缇洙瘵縢渖價灊訇醍膦癜歃钎讵钰嫱婊狝榧脁柞⊙丶丿乜亍亻仝仟仨仺伕伲俶倌倠側傖僅儂內冸冼刿剡勰卟叁參叻吋吖吡吲吶呋呲呸呾咗咩哒哓哔哚哞哿唅唛唰唷啉啞啵喵嗉嗬嗮嘞嘧噁噴噼嚢囗囟囡囷圞圧圬圻坩坶垅垌垡垭垸埂埕埚埭堀堇塍塬墒増奀奧奪奻妏妯姘娌婵媼嫒嬷孓宀宄宒寮尋尕尢尪尫屐屛岘岙岢岶岺峁峩峯崀崝崤崮崽嵇嵊嵴嶸巯庹廇廘廯弅弇弝彐彶彸復恅悃悛悱惍愽慾戬扦扲抝拻挲捌掃掊掙掛掴掸換揤揸揿摯撄撅撸擀擁擄數旮旯昜昝昶晷杈杩柒柭栝栢桁桉桷棟椇椋椤椴楝楤楦榉槎槠槲樓樨橼檗檩櫊櫓櫞櫡欬毀毎毽氘氙氚氫氵氽汆汊沏沒沤沭沺泔泺洄洵浈浠涞涠淜淝淦淩淸渀渃渌渓渟溆溏溱滟滢滳潋潰澶濆濉濬瀣瀵灏灬炁炅炝烃烊煸熵燀燴爿牉犟狍狟獒玖玟珉珘珙珨珲珺琊琚琬瑗瑷璁璎璩璺瓤瓿甁甯畈畹疔疖疠疬疳痨痱痷瘰瘿癃癍癥癬皊皲眕眭睥瞵矸砃砐砜砦砬砻砼硇硌硐硖硪硷碇碚碲磴礞祢祩禇禸秆秕秣秫秭稆稜稹穞穭穸窨竘競竸笏笕笢箄箐箬篪籼粬糥糪絡絳綰綴緩繆纈續纛绂绉绋绗绱绲缂缃缌缍缦缫缬羥羧羰翹耒耧耱耵耷聍聿肟肼胍胗胛胬胴胼脒脘脣脤腘腙腚腸膠舯舸艄艹艽艿芄芊芐芗芛芞芨芩芾苁苈苘苜苤苺茇茌茛茲茺茼荊荑荨荬荭荸荽莪莬莳莶莼菀菔菖菝菪菴萁萆萇萋萘萜萩萱萹萼葎葑葙葚葜葪葶蒄蒌蒎蒡蓑蓣蓥蓭蓮蔸蔹蔻蔾蕈蕖蕹薊薟薢薷薹藳蘄蘖蘚蘼虻蚚蚜蚧蚪蚬蚱蚳蚴蚶蛁蛄蛏蛳蛴蛸蜊蜣蜱蝈蝌蝥蝽蝾螈螟螯螵蟀蟅蟑蟞蠓蠖蠲袢袪補褰襞覜覽訂誘諾謇講诶谌谖谘谡谰豇貅貼賋賞赓赻趙跎踮蹟蹼軟載輞轭辊辋辦迳迵逄逭逯逹遙邗邝邡邧郗郛郳鄞鄯酐醌醐醑醣釆釒釵鈉鈦鉀鉍銘銨鋁鍳鎂鎊鎏鏗鏡钆钇钐钕钣钬钽铈铊铋铌铍铑铒铕铖铗铟铡铧铯铰铱铼锆锔锕锛锝锟锴锶镓镗镙镦镧镫镱閉閣閥闕阄陑隱雖雲霏霪霰靈鞕韫韮頭頸颞颢風飪饨馄馊馗馱骺髁髂髌鮭鲂鲅鲆鲈鲎鲟鲢鲫鲳鲵鲶鲷鲻鲽鳅鳊鳎鳐鳔鳕鳗鳙鳟鶴鸪鹌鹧麩麸麿黃黨鼬齟齬龍\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
