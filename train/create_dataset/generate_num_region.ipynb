{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time \n",
    "import numpy as np\n",
    "import skimage\n",
    "import os \n",
    "\n",
    "from PIL import Image,ImageDraw,ImageFont,ImageEnhance,ImageFilter\n",
    "%matplotlib inline\n",
    "\n",
    "origin_images = glob.glob('./blank_region/*.jpg')\n",
    "font = ImageFont.truetype('./font/Songti.ttc',20,index=6)\n",
    "# font = ['./font/华文细黑.ttf','./font/Songti.ttc','./font/STHeitiLight.ttc']\n",
    "save_dir = '/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/valid/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "font_dir = ['./font/STHeitiLight.ttc','./font/Songti.ttc','./font/Hiragino Sans GB.ttc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_dir = ['./font/Songti.ttc','./font/华文细黑.ttf']\n",
    "# font_dir = ['./font/华文细黑.ttf']\n",
    "\n",
    "def SaltAndPepper(src,percetage):  \n",
    "    SP_NoiseImg=src \n",
    "    SP_NoiseNum=int(percetage*src.shape[0]*src.shape[1]) \n",
    "    for i in range(SP_NoiseNum): \n",
    "        randX=np.random.randint(0,src.shape[0]-1) \n",
    "        randY=np.random.randint(0,src.shape[1]-1) \n",
    "        if np.random.randint(0,1)==0: \n",
    "            SP_NoiseImg[randX,randY]=0 \n",
    "        else: \n",
    "            SP_NoiseImg[randX,randY]=255 \n",
    "    return SP_NoiseImg\n",
    "\n",
    "def image_enhance(img):\n",
    "    \n",
    "    flag1 = random.random()\n",
    "    if flag1 > 0.3:\n",
    "        img = ImageEnhance.Contrast(img).enhance(random.random()/2+0.8)\n",
    "        img = ImageEnhance.Brightness(img).enhance(random.random()/1.5+0.75)\n",
    "        flag2 = random.random()\n",
    "        if flag2 > 0.5:\n",
    "            for _ in range(random.randint(0,4)):\n",
    "                img = ImageEnhance.Sharpness(img).enhance(0.01)\n",
    "#                 print('sharp one')\n",
    "        elif flag2 > 0.3:\n",
    "            for _ in range(random.randint(0,3)):\n",
    "                img = img.filter(ImageFilter.SMOOTH_MORE)\n",
    "#                 print('smooth one')\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def gen_text_randomSize(item):\n",
    "    fontName= random.choice(font_dir)\n",
    "    fontSize= random.randint(18,21)\n",
    "    len_item = len(item.strip())\n",
    "    origin_images = glob.glob('./blank_region/*.jpg')\n",
    "    if fontName == './font/Songti.ttc':\n",
    "        index = 6\n",
    "    else:\n",
    "        index = 0\n",
    "#     print(fontName,fontSize)\n",
    "    font = ImageFont.truetype(font=fontName,size=fontSize,index=index)\n",
    "    img = cv2.imread(random.choice(origin_images))\n",
    "    image = img.copy()\n",
    "    h,w = img.shape[:2]\n",
    "    blank = random.choice([2,2,2,2,2,25,50])\n",
    "    text_h,text_w = random.randint(fontSize,fontSize+7),(fontSize-5)*len_item+1+blank\n",
    "    if random.random() > 0.7:\n",
    "        text_h,text_w = random.randint(fontSize+3,fontSize+7),(fontSize-5)*len_item+1+blank\n",
    "    h_chop = h-text_h\n",
    "    w_chop = w-text_w\n",
    "#     print(h,w,text_h,text_w,blank)\n",
    "    x = np.random.randint(w_chop)\n",
    "    y = np.random.randint(h_chop)\n",
    "    image = image[y:y+text_h,x:x+text_w]\n",
    "\n",
    "    flag = random.random()\n",
    "    if flag >0.7:\n",
    "        image = skimage.util.random_noise(image,mode='gaussian',var=0.002)\n",
    "        image = np.uint8(image*255)\n",
    "    \n",
    "\n",
    "#     print(image.shape)\n",
    "    img_PIL = Image.fromarray(image[:,:,::-1])\n",
    "    draw = ImageDraw.Draw(img_PIL)\n",
    "    draw.text((blank,-0.5),item,font=font,fill=(0,0,0))\n",
    "    \n",
    "    img_PIL = image_enhance(img_PIL)\n",
    "    \n",
    "#     with open(save_dir+item.replace('/','&&')+ \"-\" + str(fontSize) +'.txt', \"w\", encoding='utf-8') as f:\n",
    "#         f.write(item)\n",
    "    img_PIL.save(save_dir+item.replace('/','&&') +'.png') \n",
    "    return img_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict = '0123456789,./%-￥'\n",
    "char_dict = 'ABCDEFGHIJKLMNPQRSTUVWXYZabcdefghijklmnpqrstuvwxyz'\n",
    "\n",
    "def gen_number_with_dot():\n",
    "    serial_len = random.randint(0,5)\n",
    "    num = random.random() * 10**serial_len if random.random() > 0.5 else random.randint(1,10**serial_len)\n",
    "    num =  num if random.random() > 0.5 else round(random.random(),random.randint(1,2)) \n",
    "    reserve_list = [ '{:,.1f}', '{:,.2f}', '{:,.3f}']\n",
    "    serial = random.choice(reserve_list).format(num)\n",
    "    return serial\n",
    "\n",
    "def gen_number_only():\n",
    "    serial_len = random.randint(0,5)\n",
    "    num = random.randint(1,10**serial_len)\n",
    "    return '{:,}'.format(num)\n",
    "\n",
    "def gen_serial_num():\n",
    "    serial_len = 10\n",
    "    serial_begin = random.sample(char_dict[:]+num_dict[:10],1)\n",
    "    serial = random.sample(char_dict[:]+num_dict[:],serial_len-1)\n",
    "    return ''.join(serial_begin+serial)\n",
    "\n",
    "def gen_money_with_dollar_sign():\n",
    "    serial = gen_number_with_dot()\n",
    "    serial_begin = '￥'\n",
    "    return serial_begin+serial \n",
    "\n",
    "def gen_number_with_percent_sign():\n",
    "    num = random.random() if random.random() > 0.5 else round(random.random(),2)\n",
    "    reserve_list = ['{:.1%}','{:.2%}','{:.3%}']\n",
    "    serial = random.choice(reserve_list).format(num)\n",
    "    return serial\n",
    "\n",
    "\n",
    "def gen_money_with_Chinese():\n",
    "    serial = gen_number_with_dot()\n",
    "    Chinese_list = [\"合计:\" + serial, serial+\"元\",'总额'+serial, '单价'+serial,\"合计\" + serial]\n",
    "    return random.choice(Chinese_list)\n",
    "\n",
    "def up_to_10(text):\n",
    "    length = len(text)\n",
    "    if length < 10:\n",
    "        char_text = ''.join(random.sample(char_dict,10-length))\n",
    "        text = char_text+text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_len = 200\n",
    "serial_num = [gen_serial_num() for _ in range(list_len)]\n",
    "number_only = [gen_number_only() for _ in range(list_len)]\n",
    "number_with_dot = [gen_number_with_dot() for _ in range(list_len)]\n",
    "money_with_dollar_sign = [gen_money_with_dollar_sign()  for _ in range(list_len)]\n",
    "money_with_percent_sign = [gen_number_with_percent_sign()  for _ in range(list_len)]\n",
    "random_char = [''.join(random.sample(num_dict,10)) for _ in range(list_len)]\n",
    "money_with_Chinese = [gen_money_with_Chinese() for _ in range(list_len)]\n",
    "total_num = number_with_dot + number_only + random_char + serial_num +\\\n",
    "            money_with_dollar_sign+money_with_percent_sign + money_with_Chinese + serial_num\n",
    "\n",
    "total_num_10 = [up_to_10(text) for text in total_num]\n",
    "random.shuffle(total_num)\n",
    "len(total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(number_with_dot[:10])\n",
    "# print(random_char[:10])\n",
    "# print(number_only[:10])\n",
    "# print(number_with_dot[:10])\n",
    "# print(money_with_dollar_sign[:10])\n",
    "# print(money_with_percent_sign[:10])\n",
    "# print(money_with_Chinese[:10])\n",
    "# print(serial_num[:10])\n",
    "print(total_num_10[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# random_char = [''.join(random.sample(num_dict,10)) for _ in range(list_len)]\n",
    "item = random.choice(total_num_10)\n",
    "result = gen_text_randomSize(item)\n",
    "plt.imshow(result)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from multiprocessing import Pool,cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool,cpu_count\n",
    "\n",
    "items = set(total_num_10)\n",
    "print(len(items))\n",
    "pool = Pool(cpu_count()//4)\n",
    "start = time.time()\n",
    "%time result = pool.map(gen_text_randomSize,items)\n",
    "end = time.time()\n",
    "print(end-start,cpu_count()//4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_with_dot = [gen_number_with_dot() for _ in range(30000)]\n",
    "len(set(number_with_dot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text_randomSize_json_label(item):\n",
    "    fontName= random.choice(font_dir)\n",
    "    fontSize= random.randint(18,21)\n",
    "    len_item = len(item.strip())\n",
    "    origin_images = glob.glob('./blank_region/*.jpg')\n",
    "    if fontName == './font/Songti.ttc':\n",
    "        index = 6\n",
    "    else:\n",
    "        index = 0\n",
    "#     print(fontName,fontSize)\n",
    "    font = ImageFont.truetype(font=fontName,size=fontSize,index=index)\n",
    "    img = cv2.imread(random.choice(origin_images))\n",
    "    image = img.copy()\n",
    "    h,w = img.shape[:2]\n",
    "    blank = random.choice([2,2,2,2,2,25,50,80])\n",
    "    text_h,text_w = random.randint(fontSize,fontSize+7),(fontSize-5)*len_item+1+blank\n",
    "    if random.random() > 0.7:\n",
    "        text_h,text_w = random.randint(fontSize+3,fontSize+7),(fontSize-5)*len_item+1+blank\n",
    "    h_chop = h-text_h\n",
    "    w_chop = w-text_w\n",
    "#     print(h,w,text_h,text_w,blank)\n",
    "    x = np.random.randint(w_chop)\n",
    "    y = np.random.randint(h_chop)\n",
    "    image = image[y:y+text_h,x:x+text_w]\n",
    "\n",
    "    flag = random.random()\n",
    "    if flag >0.7:\n",
    "        image = skimage.util.random_noise(image,mode='gaussian',var=0.002)\n",
    "        image = np.uint8(image*255)\n",
    "    \n",
    "\n",
    "#     print(image.shape)\n",
    "    img_PIL = Image.fromarray(image[:,:,::-1])\n",
    "    draw = ImageDraw.Draw(img_PIL)\n",
    "    draw.text((blank,-0.5),item,font=font,fill=(0,0,0))\n",
    "    \n",
    "    img_PIL = image_enhance(img_PIL)\n",
    "    \n",
    "#     with open(save_dir+item.replace('/','&&')+ \"-\" + str(fontSize) +'.txt', \"w\", encoding='utf-8') as f:\n",
    "#         f.write(item)\n",
    "    img_PIL.save(save_dir+item.replace('/','&&')+ \"-\" + str(fontSize) +'.png') \n",
    "    return img_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "total_num_png = [item.replace('/','&&') +'.png' for item in total_num_10]\n",
    "dict_num = dict(zip(total_num_png,total_num_10))\n",
    "\n",
    "\n",
    "save_dir ='/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/'\n",
    "\n",
    "#保存成.json\n",
    "with open(save_dir+\"valid_label.json\",'w',encoding='utf-8') as json_file:   \n",
    "        json.dump(dict_num,json_file)\n",
    "        \n",
    "# load json 文件\n",
    "with open(save_dir+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    txt=json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_png = [item.replace('/','&&') +'.png' for item in total_num]\n",
    "dict_num = dict(zip(total_num_png,total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(txt),len(dict_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_path = '/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/medicine_dataset_v3/'\n",
    "\n",
    "ori_path = '/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/'\n",
    "\n",
    "# with open(dst_path+\"train_label.json\",'w',encoding='utf-8') as json_file:   \n",
    "#         json.dump(dict_num,json_file)\n",
    "        \n",
    "# load json 文件\n",
    "with open(dst_path+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    dst_valid_txt=json.load(json_file)\n",
    "\n",
    "    \n",
    "with open(ori_path+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    ori_valid_txt=json.load(json_file)\n",
    "\n",
    "with open(dst_path+\"train_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    dst_train_txt=json.load(json_file)\n",
    "\n",
    "    \n",
    "with open(ori_path+\"train_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    ori_train_txt=json.load(json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dst_valid_txt),len(ori_valid_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = {}\n",
    "total_train.update(dst_valid_txt)\n",
    "total_train.update(ori_valid_txt)\n",
    "len(total_train),len(dst_valid_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dst_path+\"valid_label_total.json\",'w',encoding='utf-8') as json_file:   \n",
    "        json.dump(total_train,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(total_train.keys()) & set(imgs_png))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "imgs = glob.glob(dst_path+'valid/*png')\n",
    "imgs2 = glob.glob(dst_path+'valid/.*.png')\n",
    "file = glob.glob(ori_path+'train/*')\n",
    "file2 = glob.glob(ori_path+'train/.*')\n",
    "\n",
    "print(len(imgs+imgs2),len(file+file2))\n",
    "\n",
    "imgs_png = set([os.path.split(img)[-1] for img in imgs+imgs2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = set(total_train.keys()) - set(imgs_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict = dict([(key,value) for key,value in total_train.items() if key not in remove_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict\n",
    "\n",
    "\n",
    "with open(dst_path+\"valid_label.json\",'w',encoding='utf-8') as json_file:   \n",
    "        json.dump(num_dict,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dirsss = '/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/dataset_len20_v1/valid/'\n",
    "imgs = glob.glob(save_dirsss+'*jpg')\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sort() missing 1 required positional argument: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e15e7fb677a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sort() missing 1 required positional argument: 'a'"
     ]
    }
   ],
   "source": [
    "np.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'\\x7f'.replace('\\x7f','A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
