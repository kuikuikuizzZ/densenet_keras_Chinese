{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/model\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = characters\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float)\n",
    "        Y = np.zeros([self.batch_size, self.maxLabelLength],dtype=int) \n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                img = img.resize((self.dim[1],self.dim[0]))\n",
    "                img = np.array(img, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin.replace(' ','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters.find(char)\n",
    "            if index == -1:\n",
    "                index = self.characters.find(u'.')\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218730, 11294)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.append('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 128\n",
    "maxlabellength = 10\n",
    "\n",
    "\n",
    "label_path = './images/medicine_dataset_v3/'\n",
    "# label_valid_path  = './images/medicine_dataset_v3/'\n",
    "with open(label_path+'train_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file)\n",
    "\n",
    "with open(label_path+'valid_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6711\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = keys.alphabet_union[1:]+'卍'\n",
    "# characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir=label_path+'train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir=label_path+'valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "(128, 1) [694 419 557 893  45  47  72  70   5   5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f29e12ce940>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp \n",
    "imp.reload(densenet)\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6711\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 16, None, 64) 1600        the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 16, None, 64) 256         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 16, None, 64) 0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 16, None, 8)  4616        activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_265 (Concatenate)   (None, 16, None, 72) 0           conv2d_298[0][0]                 \n",
      "                                                                 conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 16, None, 72) 288         concatenate_265[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 16, None, 72) 0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 16, None, 8)  5192        activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_266 (Concatenate)   (None, 16, None, 80) 0           concatenate_265[0][0]            \n",
      "                                                                 conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 16, None, 80) 320         concatenate_266[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 16, None, 80) 0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 16, None, 8)  5768        activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_267 (Concatenate)   (None, 16, None, 88) 0           concatenate_266[0][0]            \n",
      "                                                                 conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 16, None, 88) 352         concatenate_267[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 16, None, 88) 0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 16, None, 8)  6344        activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_268 (Concatenate)   (None, 16, None, 96) 0           concatenate_267[0][0]            \n",
      "                                                                 conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 16, None, 96) 384         concatenate_268[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 16, None, 96) 0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 16, None, 8)  6920        activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_269 (Concatenate)   (None, 16, None, 104 0           concatenate_268[0][0]            \n",
      "                                                                 conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 16, None, 104 416         concatenate_269[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 16, None, 104 0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 16, None, 8)  7496        activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_270 (Concatenate)   (None, 16, None, 112 0           concatenate_269[0][0]            \n",
      "                                                                 conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 16, None, 112 448         concatenate_270[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 16, None, 112 0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 16, None, 8)  8072        activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_271 (Concatenate)   (None, 16, None, 120 0           concatenate_270[0][0]            \n",
      "                                                                 conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 16, None, 120 480         concatenate_271[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 16, None, 120 0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 16, None, 8)  8648        activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_272 (Concatenate)   (None, 16, None, 128 0           concatenate_271[0][0]            \n",
      "                                                                 conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 16, None, 128 512         concatenate_272[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 16, None, 128 0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 16, None, 128 16384       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, None, 128 0           conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 8, None, 128) 0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 8, None, 128) 512         average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 8, None, 128) 0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 8, None, 8)   9224        activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_273 (Concatenate)   (None, 8, None, 136) 0           average_pooling2d_23[0][0]       \n",
      "                                                                 conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 8, None, 136) 544         concatenate_273[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 8, None, 136) 0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 8, None, 8)   9800        activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_274 (Concatenate)   (None, 8, None, 144) 0           concatenate_273[0][0]            \n",
      "                                                                 conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 8, None, 144) 576         concatenate_274[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 8, None, 144) 0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 8, None, 8)   10376       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_275 (Concatenate)   (None, 8, None, 152) 0           concatenate_274[0][0]            \n",
      "                                                                 conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 8, None, 152) 608         concatenate_275[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 8, None, 152) 0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 8, None, 8)   10952       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_276 (Concatenate)   (None, 8, None, 160) 0           concatenate_275[0][0]            \n",
      "                                                                 conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 8, None, 160) 640         concatenate_276[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 8, None, 160) 0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 8, None, 8)   11528       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_277 (Concatenate)   (None, 8, None, 168) 0           concatenate_276[0][0]            \n",
      "                                                                 conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 8, None, 168) 672         concatenate_277[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 8, None, 168) 0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 8, None, 8)   12104       activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_278 (Concatenate)   (None, 8, None, 176) 0           concatenate_277[0][0]            \n",
      "                                                                 conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 8, None, 176) 704         concatenate_278[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 8, None, 176) 0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 8, None, 8)   12680       activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_279 (Concatenate)   (None, 8, None, 184) 0           concatenate_278[0][0]            \n",
      "                                                                 conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 8, None, 184) 736         concatenate_279[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 8, None, 184) 0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 8, None, 8)   13256       activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_280 (Concatenate)   (None, 8, None, 192) 0           concatenate_279[0][0]            \n",
      "                                                                 conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 8, None, 192) 768         concatenate_280[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 8, None, 192) 0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 8, None, 128) 24576       activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8, None, 128) 0           conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 4, None, 128) 0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 4, None, 128) 512         average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 4, None, 128) 0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 4, None, 8)   9224        activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_281 (Concatenate)   (None, 4, None, 136) 0           average_pooling2d_24[0][0]       \n",
      "                                                                 conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 4, None, 136) 544         concatenate_281[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 4, None, 136) 0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 4, None, 8)   9800        activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_282 (Concatenate)   (None, 4, None, 144) 0           concatenate_281[0][0]            \n",
      "                                                                 conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 4, None, 144) 576         concatenate_282[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 4, None, 144) 0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 4, None, 8)   10376       activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_283 (Concatenate)   (None, 4, None, 152) 0           concatenate_282[0][0]            \n",
      "                                                                 conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 4, None, 152) 608         concatenate_283[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 4, None, 152) 0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 4, None, 8)   10952       activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_284 (Concatenate)   (None, 4, None, 160) 0           concatenate_283[0][0]            \n",
      "                                                                 conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 4, None, 160) 640         concatenate_284[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 4, None, 160) 0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 4, None, 8)   11528       activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_285 (Concatenate)   (None, 4, None, 168) 0           concatenate_284[0][0]            \n",
      "                                                                 conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 4, None, 168) 672         concatenate_285[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 4, None, 168) 0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 4, None, 8)   12104       activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_286 (Concatenate)   (None, 4, None, 176) 0           concatenate_285[0][0]            \n",
      "                                                                 conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 4, None, 176) 704         concatenate_286[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 4, None, 176) 0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 4, None, 8)   12680       activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_287 (Concatenate)   (None, 4, None, 184) 0           concatenate_286[0][0]            \n",
      "                                                                 conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 4, None, 184) 736         concatenate_287[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 4, None, 184) 0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 4, None, 8)   13256       activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_288 (Concatenate)   (None, 4, None, 192) 0           concatenate_287[0][0]            \n",
      "                                                                 conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 4, None, 192) 768         concatenate_288[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 4, None, 192) 0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 4, 192) 0           activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (TimeDistributed)       (None, None, 768)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_out (Dense)              (None, None, 6711)   5160759     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,451,191\n",
      "Trainable params: 5,443,703\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n",
      "Loading model weights...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "# char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "modelPath = './models/weights_densenet-41-0.67.h5'\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    model.load_weights(modelPath)\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7f29de3538c8>\n",
      "-----------Start training-----------\n",
      "Epoch 1/100\n",
      "  14/1708 [..............................] - ETA: 23:03 - loss: 1.2054 - acc: 0.7913"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c2e63151c043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     callbacks = [checkpoint, earlystop, changelr, tensorboard])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/weights_densenet_union_with_num-{epoch:02d}-{val_acc:.2f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.006 * 0.95**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(100)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = 100,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
