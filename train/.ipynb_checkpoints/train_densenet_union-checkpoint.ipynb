{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = characters\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float)\n",
    "        Y = np.ones([self.batch_size, self.maxLabelLength],dtype=int) * 10000\n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                img = img.resize((self.dim[1],self.dim[0]))\n",
    "                img = np.array(img, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin.replace(' ','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters.find(char)\n",
    "            if index == -1:\n",
    "                index = self.characters.find(u'.')\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397530, 26100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.append('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys_keras\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 2046\n",
    "maxlabellength = 10\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "label_path = './images/dataset_len10_v1/'\n",
    "# label_valid_path  = './images/medicine_dataset_v3/'\n",
    "with open(label_path+'train/train_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file) \n",
    "\n",
    "with open(label_path+'valid/valid_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = keys_keras.alphabet_union[1:]+'卍'\n",
    "# characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir=label_path+'train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir=label_path+'valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 观测数据batch 的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "(512, 1) [ 1569    25   465   631 10000 10000 10000 10000 10000 10000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c9b80bda0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp \n",
    "imp.reload(densenet)\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "import keys\n",
    "def get_model_origin_conv(img_h, nclass):\n",
    "    old_nClass = len(keys.alphabet[:])\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred_old = densenet.dense_cnn(input, old_nClass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred_old)\n",
    "    basemodel.load_weights(modelPath)\n",
    "    flatten = basemodel.get_layer('flatten').output\n",
    "    y_pred = Dense(nclass, name='y_pred_out', activation='softmax')(flatten)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 16, None, 64) 1600        the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, None, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 16, None, 64) 0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, None, 8)  4616        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat1 (Concatenate)     (None, 16, None, 72) 0           conv1/conv[0][0]                 \n",
      "                                                                 conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 16, None, 72) 288         conv2_concat1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 16, None, 72) 0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, None, 8)  5192        conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat2 (Concatenate)     (None, 16, None, 80) 0           conv2_concat1[0][0]              \n",
      "                                                                 conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 16, None, 80) 320         conv2_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 16, None, 80) 0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, None, 8)  5768        conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat3 (Concatenate)     (None, 16, None, 88) 0           conv2_concat2[0][0]              \n",
      "                                                                 conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 16, None, 88) 352         conv2_concat3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 16, None, 88) 0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 16, None, 8)  6344        conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat4 (Concatenate)     (None, 16, None, 96) 0           conv2_concat3[0][0]              \n",
      "                                                                 conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 16, None, 96) 384         conv2_concat4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 16, None, 96) 0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 16, None, 8)  6920        conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat5 (Concatenate)     (None, 16, None, 104 0           conv2_concat4[0][0]              \n",
      "                                                                 conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 16, None, 104 416         conv2_concat5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 16, None, 104 0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 16, None, 8)  7496        conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat6 (Concatenate)     (None, 16, None, 112 0           conv2_concat5[0][0]              \n",
      "                                                                 conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_0_bn (BatchNormali (None, 16, None, 112 448         conv2_concat6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_0_relu (Activation (None, 16, None, 112 0           conv2_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block7_1_conv (Conv2D)    (None, 16, None, 8)  8072        conv2_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat7 (Concatenate)     (None, 16, None, 120 0           conv2_concat6[0][0]              \n",
      "                                                                 conv2_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_0_bn (BatchNormali (None, 16, None, 120 480         conv2_concat7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_0_relu (Activation (None, 16, None, 120 0           conv2_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block8_1_conv (Conv2D)    (None, 16, None, 8)  8648        conv2_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_concat8 (Concatenate)     (None, 16, None, 128 0           conv2_concat7[0][0]              \n",
      "                                                                 conv2_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 16, None, 128 512         conv2_concat8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 16, None, 128 0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 16, None, 128 16384       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_dropout (Dropout)         (None, 16, None, 128 0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_0_avgpool (AveragePooling (None, 8, None, 128) 0           pool2_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, None, 128) 512         pool2_0_avgpool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 8, None, 128) 0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, None, 8)   9224        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat1 (Concatenate)     (None, 8, None, 136) 0           pool2_0_avgpool[0][0]            \n",
      "                                                                 conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 8, None, 136) 544         conv3_concat1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 8, None, 136) 0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, None, 8)   9800        conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat2 (Concatenate)     (None, 8, None, 144) 0           conv3_concat1[0][0]              \n",
      "                                                                 conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 8, None, 144) 576         conv3_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 8, None, 144) 0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, None, 8)   10376       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat3 (Concatenate)     (None, 8, None, 152) 0           conv3_concat2[0][0]              \n",
      "                                                                 conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 8, None, 152) 608         conv3_concat3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 8, None, 152) 0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, None, 8)   10952       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat4 (Concatenate)     (None, 8, None, 160) 0           conv3_concat3[0][0]              \n",
      "                                                                 conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 8, None, 160) 640         conv3_concat4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 8, None, 160) 0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 8, None, 8)   11528       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat5 (Concatenate)     (None, 8, None, 168) 0           conv3_concat4[0][0]              \n",
      "                                                                 conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 8, None, 168) 672         conv3_concat5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 8, None, 168) 0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 8, None, 8)   12104       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat6 (Concatenate)     (None, 8, None, 176) 0           conv3_concat5[0][0]              \n",
      "                                                                 conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 8, None, 176) 704         conv3_concat6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 8, None, 176) 0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 8, None, 8)   12680       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat7 (Concatenate)     (None, 8, None, 184) 0           conv3_concat6[0][0]              \n",
      "                                                                 conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 8, None, 184) 736         conv3_concat7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 8, None, 184) 0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 8, None, 8)   13256       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_concat8 (Concatenate)     (None, 8, None, 192) 0           conv3_concat7[0][0]              \n",
      "                                                                 conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 8, None, 192) 768         conv3_concat8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 8, None, 192) 0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 8, None, 128) 24576       pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_dropout (Dropout)         (None, 8, None, 128) 0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_0_avgpool (AveragePooling (None, 4, None, 128) 0           pool3_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, None, 128) 512         pool3_0_avgpool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 4, None, 128) 0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, None, 8)   9224        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat1 (Concatenate)     (None, 4, None, 136) 0           pool3_0_avgpool[0][0]            \n",
      "                                                                 conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 4, None, 136) 544         conv4_concat1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 4, None, 136) 0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, None, 8)   9800        conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat2 (Concatenate)     (None, 4, None, 144) 0           conv4_concat1[0][0]              \n",
      "                                                                 conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 4, None, 144) 576         conv4_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 4, None, 144) 0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, None, 8)   10376       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat3 (Concatenate)     (None, 4, None, 152) 0           conv4_concat2[0][0]              \n",
      "                                                                 conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 4, None, 152) 608         conv4_concat3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 4, None, 152) 0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, None, 8)   10952       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat4 (Concatenate)     (None, 4, None, 160) 0           conv4_concat3[0][0]              \n",
      "                                                                 conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 4, None, 160) 640         conv4_concat4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 4, None, 160) 0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, None, 8)   11528       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat5 (Concatenate)     (None, 4, None, 168) 0           conv4_concat4[0][0]              \n",
      "                                                                 conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 4, None, 168) 672         conv4_concat5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 4, None, 168) 0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, None, 8)   12104       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat6 (Concatenate)     (None, 4, None, 176) 0           conv4_concat5[0][0]              \n",
      "                                                                 conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 4, None, 176) 704         conv4_concat6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 4, None, 176) 0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 4, None, 8)   12680       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat7 (Concatenate)     (None, 4, None, 184) 0           conv4_concat6[0][0]              \n",
      "                                                                 conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 4, None, 184) 736         conv4_concat7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 4, None, 184) 0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 4, None, 8)   13256       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_concat8 (Concatenate)     (None, 4, None, 192) 0           conv4_concat7[0][0]              \n",
      "                                                                 conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, None, 192) 768         conv4_concat8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, None, 192) 0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 4, 192) 0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (TimeDistributed)       (None, None, 768)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_out (Dense)              (None, None, 6043)   4647067     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,937,499\n",
      "Trainable params: 4,930,011\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n",
      "the_input False\n",
      "conv1/conv False\n",
      "conv2_block1_0_bn False\n",
      "conv2_block1_0_relu False\n",
      "conv2_block1_1_conv False\n",
      "conv2_concat1 False\n",
      "conv2_block2_0_bn False\n",
      "conv2_block2_0_relu False\n",
      "conv2_block2_1_conv False\n",
      "conv2_concat2 False\n",
      "conv2_block3_0_bn False\n",
      "conv2_block3_0_relu False\n",
      "conv2_block3_1_conv False\n",
      "conv2_concat3 False\n",
      "conv2_block4_0_bn False\n",
      "conv2_block4_0_relu False\n",
      "conv2_block4_1_conv False\n",
      "conv2_concat4 False\n",
      "conv2_block5_0_bn False\n",
      "conv2_block5_0_relu False\n",
      "conv2_block5_1_conv False\n",
      "conv2_concat5 False\n",
      "conv2_block6_0_bn False\n",
      "conv2_block6_0_relu False\n",
      "conv2_block6_1_conv False\n",
      "conv2_concat6 False\n",
      "conv2_block7_0_bn False\n",
      "conv2_block7_0_relu False\n",
      "conv2_block7_1_conv False\n",
      "conv2_concat7 False\n",
      "conv2_block8_0_bn False\n",
      "conv2_block8_0_relu False\n",
      "conv2_block8_1_conv False\n",
      "conv2_concat8 False\n",
      "pool2_bn False\n",
      "pool2_relu False\n",
      "pool2_conv False\n",
      "pool2_dropout False\n",
      "pool2_0_avgpool False\n",
      "conv3_block1_0_bn False\n",
      "conv3_block1_0_relu False\n",
      "conv3_block1_1_conv False\n",
      "conv3_concat1 False\n",
      "conv3_block2_0_bn False\n",
      "conv3_block2_0_relu False\n",
      "conv3_block2_1_conv False\n",
      "conv3_concat2 False\n",
      "conv3_block3_0_bn False\n",
      "conv3_block3_0_relu False\n",
      "conv3_block3_1_conv False\n",
      "conv3_concat3 False\n",
      "conv3_block4_0_bn False\n",
      "conv3_block4_0_relu False\n",
      "conv3_block4_1_conv False\n",
      "conv3_concat4 False\n",
      "conv3_block5_0_bn False\n",
      "conv3_block5_0_relu False\n",
      "conv3_block5_1_conv False\n",
      "conv3_concat5 False\n",
      "conv3_block6_0_bn False\n",
      "conv3_block6_0_relu False\n",
      "conv3_block6_1_conv False\n",
      "conv3_concat6 False\n",
      "conv3_block7_0_bn False\n",
      "conv3_block7_0_relu False\n",
      "conv3_block7_1_conv False\n",
      "conv3_concat7 False\n",
      "conv3_block8_0_bn False\n",
      "conv3_block8_0_relu False\n",
      "conv3_block8_1_conv False\n",
      "conv3_concat8 False\n",
      "pool3_bn False\n",
      "pool3_relu False\n",
      "pool3_conv False\n",
      "pool3_dropout False\n",
      "pool3_0_avgpool True\n",
      "conv4_block1_0_bn True\n",
      "conv4_block1_0_relu True\n",
      "conv4_block1_1_conv True\n",
      "conv4_concat1 True\n",
      "conv4_block2_0_bn True\n",
      "conv4_block2_0_relu True\n",
      "conv4_block2_1_conv True\n",
      "conv4_concat2 True\n",
      "conv4_block3_0_bn True\n",
      "conv4_block3_0_relu True\n",
      "conv4_block3_1_conv True\n",
      "conv4_concat3 True\n",
      "conv4_block4_0_bn True\n",
      "conv4_block4_0_relu True\n",
      "conv4_block4_1_conv True\n",
      "conv4_concat4 True\n",
      "conv4_block5_0_bn True\n",
      "conv4_block5_0_relu True\n",
      "conv4_block5_1_conv True\n",
      "conv4_concat5 True\n",
      "conv4_block6_0_bn True\n",
      "conv4_block6_0_relu True\n",
      "conv4_block6_1_conv True\n",
      "conv4_concat6 True\n",
      "conv4_block7_0_bn True\n",
      "conv4_block7_0_relu True\n",
      "conv4_block7_1_conv True\n",
      "conv4_concat7 True\n",
      "conv4_block8_0_bn True\n",
      "conv4_block8_0_relu True\n",
      "conv4_block8_1_conv True\n",
      "conv4_concat8 True\n",
      "bn True\n",
      "relu True\n",
      "permute True\n",
      "flatten True\n",
      "y_pred_out True\n",
      "the_labels False\n",
      "input_length False\n",
      "label_length False\n",
      "ctc True\n",
      "Loading model weights...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "# char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "\n",
    "\n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "## 这里设置gpu内存的比例\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)\n",
    "# one gpu!!!\n",
    "with tf.Session(config=config) as sess:\n",
    "    basemodel, model = get_model(img_h, nclass)\n",
    "    for layer in model.layers[:75]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers:\n",
    "        print(layer.name,layer.trainable)\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modelPath = '../train/models/75layers_labeled_ch_len25_v1-2.999-0.502.h5'   \n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    model.load_weights(modelPath)\n",
    "    print('done!')\n",
    "    \n",
    "## multi-gpu model\n",
    "# from keras.utils import multi_gpu_model\n",
    "# with tf.device('/cpu:0'):\n",
    "#     basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "\n",
    "# parallel_model = multi_gpu_model(model,gpus=2)\n",
    "# parallel_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7f8c2c164c80>\n",
      "-----------Start training-----------\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2046,64,16,140]\n\t [[Node: conv1/conv_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_the_input_3_0_5/_2115, conv1/conv_3/kernel/read)]]\n\t [[Node: training/Adam/gradients/ctc/ExpandDims_grad/Reshape/_2337 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2948_training/Adam/gradients/ctc/ExpandDims_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'conv1/conv_3/convolution', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-848d10634347>\", line 19, in <module>\n    basemodel, model = get_model(img_h, nclass)\n  File \"<ipython-input-7-abaf3ef9aa60>\", line 9, in get_model\n    y_pred = densenet.dense_cnn(input, nclass)\n  File \"/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/densenet.py\", line 53, in dense_cnn\n    use_bias=False, kernel_regularizer=l2(_weight_decay),name='conv1/conv')(input)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 3195, in conv2d\n    data_format=tf_data_format)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2046,64,16,140]\n\t [[Node: conv1/conv_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_the_input_3_0_5/_2115, conv1/conv_3/kernel/read)]]\n\t [[Node: training/Adam/gradients/ctc/ExpandDims_grad/Reshape/_2337 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2948_training/Adam/gradients/ctc/ExpandDims_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2046,64,16,140]\n\t [[Node: conv1/conv_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_the_input_3_0_5/_2115, conv1/conv_3/kernel/read)]]\n\t [[Node: training/Adam/gradients/ctc/ExpandDims_grad/Reshape/_2337 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2948_training/Adam/gradients/ctc/ExpandDims_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5f010b30c4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchangelr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     use_multiprocessing=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2046,64,16,140]\n\t [[Node: conv1/conv_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_the_input_3_0_5/_2115, conv1/conv_3/kernel/read)]]\n\t [[Node: training/Adam/gradients/ctc/ExpandDims_grad/Reshape/_2337 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2948_training/Adam/gradients/ctc/ExpandDims_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'conv1/conv_3/convolution', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-848d10634347>\", line 19, in <module>\n    basemodel, model = get_model(img_h, nclass)\n  File \"<ipython-input-7-abaf3ef9aa60>\", line 9, in get_model\n    y_pred = densenet.dense_cnn(input, nclass)\n  File \"/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/densenet.py\", line 53, in dense_cnn\n    use_bias=False, kernel_regularizer=l2(_weight_decay),name='conv1/conv')(input)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 3195, in conv2d\n    data_format=tf_data_format)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2046,64,16,140]\n\t [[Node: conv1/conv_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_the_input_3_0_5/_2115, conv1/conv_3/kernel/read)]]\n\t [[Node: training/Adam/gradients/ctc/ExpandDims_grad/Reshape/_2337 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2948_training/Adam/gradients/ctc/ExpandDims_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/freezen_75layers_dataset_v1-{val_loss:.3f}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0005 * 0.90**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard],\n",
    "    workers=4,\n",
    "    use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='./models/random_len10-{epoch:02d}-{val_loss:.3f}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.0005 * 0.90**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "parallel_model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard],\n",
    "    workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4_block8_1_conv = keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[0])\n",
    "bias =  keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4_block8_1_conv_1 = keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[0])\n",
    "bias_1 =  keras.backend.get_value(model.get_layer('conv4_block8_1_conv').weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias==bias_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
