{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.core import Reshape, Masking, Lambda, Permute\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "\n",
    "from imp import reload\n",
    "import densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataset_dir,list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 characters='', shuffle=True,maxLabelLength=10):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.characters = characters\n",
    "        self.n_classes = len(self.characters)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.maxLabelLength = maxLabelLength\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float)\n",
    "        Y = np.zeros([self.batch_size, self.maxLabelLength],dtype=int) \n",
    "        input_length = np.zeros([self.batch_size, 1])\n",
    "        label_length = np.zeros([self.batch_size, 1])\n",
    "        \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            try:\n",
    "                img = Image.open(os.path.join(self.dataset_dir, ID)).convert('L')\n",
    "                img = img.resize((self.dim[1],self.dim[0]))\n",
    "                img = np.array(img, 'f') / 255.0 - 0.5\n",
    "            except (OSError,IOError) as error:\n",
    "                print(error)\n",
    "                img = np.zeros(*self.dim,dtype=np.float)\n",
    "                \n",
    "\n",
    "            X[i,] = np.expand_dims(img, axis=2)\n",
    "            \n",
    "            label_origin = self.labels[ID]\n",
    "            label_origin.replace(' ','')\n",
    "            label = self.__one_hot(label_origin,length=len(label_origin))\n",
    "\n",
    "\n",
    "            if(len(label) <= 0):\n",
    "                print(\"%s label len < 0\" %ID)\n",
    "            # the input length for ctc_loss, for densenet pool size is about 8\n",
    "            label_length[i] = len(label)\n",
    "            input_length[i] = self.dim[1] // 8\n",
    "            Y[i, :len(label)] = label\n",
    "    \n",
    "            \n",
    "        inputs = {'the_input': X,\n",
    "            'the_labels': Y,\n",
    "            'input_length': input_length,\n",
    "            'label_length': label_length,\n",
    "            }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __one_hot(self, text,length):\n",
    "        length = min(length,self.maxLabelLength)\n",
    "        label = np.zeros(length)\n",
    "        for i, char in enumerate(text):\n",
    "            index = self.characters.find(char)\n",
    "            if index == -1:\n",
    "                index = self.characters.find(u'.')\n",
    "            if i < length:\n",
    "                label[i] = index\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218730, 11294)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys \n",
    "sys.path.append('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/')\n",
    "import keys_keras\n",
    "\n",
    "\n",
    "img_h = 32\n",
    "img_w = 280\n",
    "batch_size = 128\n",
    "maxlabellength = 10\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "label_path = './images/medicine_dataset_v3/'\n",
    "# label_valid_path  = './images/medicine_dataset_v3/'\n",
    "with open(label_path+'train_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_train=json.load(json_file)\n",
    "\n",
    "with open(label_path+'valid_label.json','r',encoding='utf-8') as json_file:\n",
    "    label_dict_valid=json.load(json_file)\n",
    "\n",
    "\n",
    "len(label_dict_train),len(label_dict_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n"
     ]
    }
   ],
   "source": [
    "train_id = list(label_dict_train.keys())\n",
    "valid_id = list(label_dict_valid.keys())\n",
    "# characters = keys.alphabet[:]\n",
    "characters = keys_keras.alphabet_union[1:]+'卍'\n",
    "# characters = ''.join([ch.strip('\\n') for ch in characters][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(nclass)\n",
    "train_generator = DataGenerator(dataset_dir=label_path+'train/', list_IDs=train_id, \n",
    "                                labels=label_dict_train,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)\n",
    "valid_generator = DataGenerator(dataset_dir=label_path+'valid/', list_IDs=valid_id, \n",
    "                                labels=label_dict_valid,batch_size = batch_size, characters=characters,\n",
    "                                dim=(img_h,img_w),maxLabelLength=maxlabellength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "(128, 1) [  15 2304 1706  472  490 1802  720 1493 3730  964]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde7f5a0588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_generator.on_epoch_end()\n",
    "iterator = iter(train_generator)\n",
    "\n",
    "X,y = iterator.__next__()\n",
    "i = np.random.randint(0,X['the_labels'].shape[0])\n",
    "# train_generator.on_epoch_end()\n",
    "print(i)\n",
    "print(X['input_length'].shape,X['the_labels'][i])\n",
    "image = np.squeeze(X['the_input'][i])\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp \n",
    "imp.reload(densenet)\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def get_model(img_h, nclass):\n",
    "    input = Input(shape=(img_h, None, 1), name='the_input')\n",
    "    y_pred = densenet.dense_cnn(input, nclass)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    basemodel.summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return basemodel, model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, None, 64) 1600        the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 16, None, 64) 256         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 16, None, 64) 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, None, 8)  4616        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 16, None, 72) 0           conv2d_136[0][0]                 \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 16, None, 72) 288         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 16, None, 72) 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, None, 8)  5192        activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 16, None, 80) 0           concatenate_121[0][0]            \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 16, None, 80) 320         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 16, None, 80) 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, None, 8)  5768        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 16, None, 88) 0           concatenate_122[0][0]            \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 16, None, 88) 352         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 16, None, 88) 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, None, 8)  6344        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 16, None, 96) 0           concatenate_123[0][0]            \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 16, None, 96) 384         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 16, None, 96) 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, None, 8)  6920        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 16, None, 104 0           concatenate_124[0][0]            \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 16, None, 104 416         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 16, None, 104 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 16, None, 8)  7496        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 16, None, 112 0           concatenate_125[0][0]            \n",
      "                                                                 conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 16, None, 112 448         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 16, None, 112 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 16, None, 8)  8072        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 16, None, 120 0           concatenate_126[0][0]            \n",
      "                                                                 conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 16, None, 120 480         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 16, None, 120 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, None, 8)  8648        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 16, None, 128 0           concatenate_127[0][0]            \n",
      "                                                                 conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 16, None, 128 512         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 16, None, 128 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, None, 128 16384       activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, None, 128 0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 8, None, 128) 0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 8, None, 128) 512         average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 8, None, 128) 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 8, None, 8)   9224        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 8, None, 136) 0           average_pooling2d_11[0][0]       \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 8, None, 136) 544         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 8, None, 136) 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 8, None, 8)   9800        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 8, None, 144) 0           concatenate_129[0][0]            \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 8, None, 144) 576         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 8, None, 144) 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, None, 8)   10376       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 8, None, 152) 0           concatenate_130[0][0]            \n",
      "                                                                 conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, None, 152) 608         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 8, None, 152) 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 8, None, 8)   10952       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 8, None, 160) 0           concatenate_131[0][0]            \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 8, None, 160) 640         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 8, None, 160) 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 8, None, 8)   11528       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 8, None, 168) 0           concatenate_132[0][0]            \n",
      "                                                                 conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 8, None, 168) 672         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 8, None, 168) 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 8, None, 8)   12104       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 8, None, 176) 0           concatenate_133[0][0]            \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 8, None, 176) 704         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 8, None, 176) 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 8, None, 8)   12680       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 8, None, 184) 0           concatenate_134[0][0]            \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 8, None, 184) 736         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 8, None, 184) 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 8, None, 8)   13256       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 8, None, 192) 0           concatenate_135[0][0]            \n",
      "                                                                 conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 8, None, 192) 768         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 8, None, 192) 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 8, None, 128) 24576       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 8, None, 128) 0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 4, None, 128) 0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, None, 128) 512         average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 4, None, 128) 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 4, None, 8)   9224        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 4, None, 136) 0           average_pooling2d_12[0][0]       \n",
      "                                                                 conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, None, 136) 544         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 4, None, 136) 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 4, None, 8)   9800        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 4, None, 144) 0           concatenate_137[0][0]            \n",
      "                                                                 conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 4, None, 144) 576         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 4, None, 144) 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 4, None, 8)   10376       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 4, None, 152) 0           concatenate_138[0][0]            \n",
      "                                                                 conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 4, None, 152) 608         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 4, None, 152) 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 4, None, 8)   10952       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 4, None, 160) 0           concatenate_139[0][0]            \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 4, None, 160) 640         concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 4, None, 160) 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 4, None, 8)   11528       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 4, None, 168) 0           concatenate_140[0][0]            \n",
      "                                                                 conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 4, None, 168) 672         concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 4, None, 168) 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 4, None, 8)   12104       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 4, None, 176) 0           concatenate_141[0][0]            \n",
      "                                                                 conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 4, None, 176) 704         concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 4, None, 176) 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 4, None, 8)   12680       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 4, None, 184) 0           concatenate_142[0][0]            \n",
      "                                                                 conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 4, None, 184) 736         concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 4, None, 184) 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 4, None, 8)   13256       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 4, None, 192) 0           concatenate_143[0][0]            \n",
      "                                                                 conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 4, None, 192) 768         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 4, None, 192) 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 4, 192) 0           activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (TimeDistributed)       (None, None, 768)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_out (Dense)              (None, None, 6043)   4647067     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,937,499\n",
      "Trainable params: 4,930,011\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# char_set = open('char_std_5990.txt', 'r', encoding='utf-8').readlines()\n",
    "# char_set = ''.join([ch.strip('\\n') for ch in char_set][1:] + ['卍'])\n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "# K.set_session(get_session())\n",
    "reload(densenet)\n",
    "basemodel, model = get_model(img_h, nclass)\n",
    "\n",
    "modelPath = '../densenet/models/weights_densenet.h5'\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    model.load_weights(modelPath,by_name=True)\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7fde7975fc80>\n",
      "-----------Start training-----------\n",
      "Epoch 1/100\n",
      "1708/1708 [==============================] - 1274s 746ms/step - loss: 12.7193 - acc: 0.2799 - val_loss: 4.3390 - val_acc: 0.4850\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 1268s 742ms/step - loss: 2.9966 - acc: 0.5688 - val_loss: 3.5191 - val_acc: 0.6175\n",
      "Epoch 3/100\n",
      " 720/1708 [===========>..................] - ETA: 11:53 - loss: 2.4287 - acc: 0.6417"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='./models/keys_keras_densenet_with_num-{epoch:02d}-{val_acc:.3f}.h5', monitor='val_loss', save_best_only=False, save_weights_only=True)\n",
    "lr_schedule = lambda epoch: 0.006 * 0.95**epoch\n",
    "learning_rate = np.array([lr_schedule(i) for i in range(epochs)])\n",
    "changelr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./models/logs', write_graph=True)\n",
    "\n",
    "print(lr_schedule)\n",
    "print('-----------Start training-----------')\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = epochs,\n",
    "    initial_epoch = 0,\n",
    "    validation_data = valid_generator,\n",
    "    callbacks = [checkpoint, earlystop, changelr, tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
