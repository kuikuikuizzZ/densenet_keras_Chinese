{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "#coding:utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from densenet.densenet_lib import Densenet_keras\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd())+'densenet/')\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# import keys_union\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import difflib\n",
    "import re\n",
    "import random\n",
    "import cv2\n",
    "import densenet.keys as keys\n",
    "import densenet.keys_keras as keys_keras\n",
    "import densenet.densenet_lib as densenet_lib\n",
    "import numpy as np\n",
    "import densenet.keys_keras as keys_keras\n",
    "import densenet.model as model\n",
    "from densenet.model import densenet_cnn_model,densenet_rnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'densenet.model' from '/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/densenet/model.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(densenet_lib)\n",
    "imp.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/trans_model/model_75layers_labeled_ch_len25_v1.pb'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_tf = densenet_lib.Densenet_tf_multi_gpus(pb_model_path=model_path,characters=characters,fixed_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/trans_model/model_75layers_labeled_ch_len25_v1.pb'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_tf_1 = densenet_lib.Densenet_tf(pb_model_path=model_path,characters=characters,fixed_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './train/models/tmp/with_num_-0.947-0.896.h5'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_keras = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                             model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './densenet/models/weights_densenet.h5'\n",
    "characters = keys.alphabet[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "densenet_keras_5990 = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                                  model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './train/models/freezen_5layers_dataset_v1-0.672-0.894.h5'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "densenet_keras_2 = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                                model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet_keras_5990.load_weights('./densenet/models/weights_densenet_with_name.h5')\n",
    "densenet_keras_5990.basemodel = basemodel5\n",
    "# densenet_keras_2.load_weights('./train/models/random_len20-06-0.400-0.926.h5')\n",
    "\n",
    "# imgs_path = glob('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/train/*.png')\n",
    "imgs_path = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_path = random.choice(imgs_path)\n",
    "# print(img_path)\n",
    "# img = Image.open(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "blank = np.ones((img.shape[0],50,3),dtype=np.uint8)*255\n",
    "img = np.concatenate((img,blank),axis=1)\n",
    "print(img.shape)\n",
    "model = densenet_keras_5990\n",
    "# img = cv2.resize(img,(800,32))\n",
    "%time result = model.recognize(img)\n",
    "# print(model.basemodel.summary())\n",
    "plt.imshow(img)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two model predict\n",
    "\n",
    "# densenet_keras.load_weights('./train/models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "# densenet_keras_2.load_weights('./train/models/freezen_5layers_dataset_v1-0.672-0.894.h5')\n",
    "    \n",
    "# imgs_path = glob('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/train/*.png')\n",
    "imgs_path = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/临时切割图/*png')\n",
    "img_path = random.choice(imgs_path)\n",
    "# print(img_path)\n",
    "# img = Image.open(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "blank = np.ones((img.shape[0],20,3),dtype=np.uint8)*255\n",
    "img = np.concatenate((blank,img,blank),axis=1)\n",
    "model1 = densenet_keras\n",
    "model2 = densenet_keras_2\n",
    "# img = cv2.resize(img,(800,32))\n",
    "%time y_pred1 = model1.predict(img)\n",
    "%time y_pred2 = model2.predict(img)\n",
    "y_pred1 = y_pred1[:, :, :]\n",
    "y_pred2 = y_pred2[:, :, :]\n",
    "\n",
    "result = model1.decode((y_pred1+y_pred2)/2,with_confidence=True)\n",
    "result2 = model2.recognize_with_confidence(img)\n",
    "result3 = densenet_keras.recognize_with_confidence(img)\n",
    "# print(model.basemodel.summary())\n",
    "plt.imshow(img)\n",
    "print(result)\n",
    "print(result2,'model2')\n",
    "print(result3,'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(u'./train/images/test_images20181122/*png')\n",
    "img_paths = glob(u'/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*5\n",
    "img_paths = random.sample(img_paths,512)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "result_list=[]\n",
    "start = time.time()\n",
    "print(len(img_list))\n",
    "%time result_list = densenet_tf.recognize_on_batch(img_list,with_confidence=True,fixed_size=True)\n",
    "# %time result_list_1 =  densenet_tf.recognize_on_batch(img_list,with_confidence=True,fixed_size=True)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'2,1000':'3.2,4.1','2,300':'1.1,1.37',\n",
    " '1 1000':'3.5,4.5s','1,300':'1.16,1.44s',\n",
    " '4,1000':'2.9,4.4','4,300':'0.98,1.58'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*10\n",
    "img_paths = random.sample(img_paths,512)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "result_list = []\n",
    "start = time.time()\n",
    "for img in img_list:\n",
    "    result = densenet_keras.recognize_with_confidence(img)\n",
    "    result_list.append(result)\n",
    "print(time.time()-start)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用标注的样本测试模型的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./train/create_dataset/total_medicine_v1.txt','w') as f:\n",
    "#     for item in total_medicine:\n",
    "#         f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 识别结果后处理\n",
    "def price_postprocessing(str_price):\n",
    "    # 去除末尾的逗号和小数点\n",
    "    idx = len(str_price) - 1\n",
    "    while idx >= 0 and (str_price[idx] == '.' or str_price[idx] == ','):\n",
    "        idx -= 1\n",
    "    result = str_price[: idx + 1]\n",
    "    \n",
    "    # 逗号和小数点同时存在时去除逗号\n",
    "    result = result.replace(',','') if ',' in result and '.' in result else result\n",
    "    \n",
    "    # 存在多个小数点时保留最后一个逗号\n",
    "    if result.count('.') > 1:\n",
    "        point_pos = result.rfind('.')\n",
    "        result = result[:point_pos].replace('.', '') + result[point_pos:]\n",
    "        \n",
    "    # 当存在多个逗号时保留最后一个逗号\n",
    "    if result.count(',') > 1:\n",
    "        point_pos = result.rfind(',')\n",
    "        result = result[:point_pos].replace(',', '') + result[point_pos:]\n",
    "        \n",
    "    # 当只存在逗号且逗号不是千位分隔符，则将逗号变成小数点\n",
    "    if result.count(',') == 1:\n",
    "        if (result.find(',') - len(result)) % 4 != 0:\n",
    "            result = result.replace(',', '.')\n",
    "        else:\n",
    "            # 如果将逗号去除得到一个较大的金额数字则将逗号转换成小数点\n",
    "            tmp = result.replace(',', '')\n",
    "            try:\n",
    "                if float(tmp) > 50000:\n",
    "                    result = result.replace(',', '.')\n",
    "                else:\n",
    "                    result = tmp\n",
    "            except:\n",
    "                result = tmp\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12912/12912 [01:50<00:00, 117.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right:11876, false:1036, num:12912, ratio:91.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_path= './train/models/tmp/with_num_-02-0.793-0.908.h5'\n",
    "densenet_keras.basemodel.load_weights(model_path)\n",
    "imgs_path = glob('./train/images/digits_all/*.png')\n",
    "false_list_path = './false_list.txt'\n",
    "false_result_list_path = './false_result_list.txt'\n",
    "\n",
    "with open(false_list_path, 'w', encoding='utf-8') as false_list_txt, open(false_result_list_path, 'w', encoding='utf-8') as false_result_list_txt:\n",
    "    right_cnt = 0\n",
    "    false_cnt = 0\n",
    "    with tqdm(total=len(imgs_path)) as pbar:\n",
    "        for img_file in imgs_path:\n",
    "            pbar.update(1)\n",
    "\n",
    "            img = cv2.imread(img_file)\n",
    "            height, width = img.shape[:2]\n",
    "            t = b = l = r = 0\n",
    "            img = cv2.copyMakeBorder(img, t,b,0,14, cv2.BORDER_CONSTANT, value=(255,255,255))\n",
    "            result = densenet_keras.recognize(img)\n",
    "            with open(img_file.replace('.png', '.txt'), 'r', encoding='utf-8') as f:\n",
    "                label = f.readlines()[0].replace('\\n', '')\n",
    "\n",
    "#             result = price_postprocessing(result)\n",
    "#             label = label.replace(',','') if ',' in label and '.' in label else label\n",
    "\n",
    "            # 只关心数值正确性\n",
    "            try:\n",
    "                result_float = float(result) \n",
    "                label_float = float(label)\n",
    "\n",
    "                result_str = str(result_float)\n",
    "                label_str = str(label_float)\n",
    "            except:\n",
    "                result_str = result\n",
    "                label_str = label\n",
    "    \n",
    "#             数值正确性+位数正确性\n",
    "#             result_str = result\n",
    "#             label_str = label\n",
    "            \n",
    "            if result_str == label_str:\n",
    "                right_cnt += 1\n",
    "            else:\n",
    "                false_cnt += 1\n",
    "                false_list_txt.write(img_file + '\\n')\n",
    "                false_result_list_txt.write(result_str + '\\n')\n",
    "            \n",
    "    print('right:%s, false:%s, num:%s, ratio:%.2f%%' % (right_cnt, false_cnt, right_cnt + false_cnt, \n",
    "                                                  right_cnt / (right_cnt + false_cnt) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单次识别速度慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "save_dir = './test_data/labeled_data/'\n",
    "img_paths = glob(save_dir+'*png')\n",
    "\n",
    "### prepare for test chinese accurary\n",
    "error_list = []\n",
    "# load json 文件\n",
    "with open(save_dir+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    label=json.load(json_file)\n",
    "    \n",
    "def strQ2B(ustring):\n",
    "    \"\"\"全角转半角\"\"\"\n",
    "    rstring = \"\"\n",
    "    for uchar in ustring:\n",
    "        inside_code=ord(uchar)\n",
    "        if inside_code == 12288:                              #全角空格直接转换            \n",
    "            inside_code = 32 \n",
    "        elif (inside_code >= 65281 and inside_code <= 65374): #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "\n",
    "        rstring += chr(inside_code)\n",
    "    return rstring\n",
    "sum = 0\n",
    "\n",
    "def check_name(check_str):\n",
    "    len_str = len(check_str)\n",
    "    cutoff = 0.7\n",
    "    if len_str <= 3:\n",
    "        cutoff = 0.5\n",
    "    elif len_str <= 5:\n",
    "        cutoff = 0.6\n",
    "    return cutoff\n",
    "with open('./train/create_dataset/name_dictionary_v1.2.txt') as f:\n",
    "    medicine = f.readlines()\n",
    "medicine = [name.split('\\n')[0] for name in medicine ]\n",
    "medicine = list(set(medicine))\n",
    "len(medicine)\n",
    "medicine = [strQ2B(name)  for name in medicine]\n",
    "\n",
    "\n",
    "def get_closest_matches(item):\n",
    "    result,label = item\n",
    "    cutoff = check_name(result)\n",
    "    match_result = difflib.get_close_matches(result, medicine,cutoff=cutoff)\n",
    "    if match_result:\n",
    "        return (match_result,label)\n",
    "    else:\n",
    "        return (result,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "from multiprocessing import Pool,cpu_count\n",
    "\n",
    "\n",
    "def loop_test_chinese():\n",
    "    model_paths_tmp = []\n",
    "    while True:\n",
    "        model_paths = glob('./train/models/tmp/*.h5')\n",
    "        time.sleep(10)\n",
    "        if set(model_paths) != set(model_paths_tmp):\n",
    "            diff_path = set(model_paths)-set(model_paths_tmp)\n",
    "            model_paths_tmp = model_paths\n",
    "        for model_path in diff_path:\n",
    "            with open(save_dir+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "                label=json.load(json_file)\n",
    "            densenet_keras.load_weights(model_path)\n",
    "            print(model_path)\n",
    "            model = densenet_keras\n",
    "            result = []\n",
    "            error_list = []\n",
    "            sum_acc = 0\n",
    "\n",
    "            for img_path in img_paths:\n",
    "                img = cv2.imread(img_path)\n",
    "            #     print(img_path)\n",
    "                img_name = os.path.split(img_path)[-1]\n",
    "                tmp_result = model.recognize(img)\n",
    "                if label[img_name] == tmp_result:\n",
    "                    sum_acc +=1\n",
    "                else:\n",
    "                    error_list.append((res,label[img_name]))\n",
    "            print('raw acc: ',sum_acc/len(img_paths))\n",
    "\n",
    "            imgs = [cv2.imread(img_path) for img_path in img_paths]\n",
    "            img_names = [os.path.split(img_path)[-1] for img_path in img_paths]\n",
    "            ground_true = [strQ2B(label[img_name]) for img_name in img_names]\n",
    "            result = model.recognize_on_batch(imgs,with_confidence=True)\n",
    "\n",
    "\n",
    "\n",
    "            result = [strQ2B(res[0]) for res in result]\n",
    "\n",
    "            true_sum = [res==ground for res,ground in zip(result,ground_true)].count(True)\n",
    "            print('after Q2B: ',true_sum/len(imgs))\n",
    "            error_list = [(res,ground)for res,ground in zip(result,ground_true) if res != ground]\n",
    "\n",
    "            ## multi-processing lookup dictionary\n",
    "            pool = Pool(cpu_count()//4)\n",
    "            # % time match_results = [get_closest_matches(item) for item in error_list ]\n",
    "\n",
    "            sum=true_sum\n",
    "            match_results = pool.map(get_closest_matches,error_list)\n",
    "            match_error = []\n",
    "            for results,label in match_results:\n",
    "                if label == results[0]:\n",
    "                    sum +=1\n",
    "                else:\n",
    "                    match_error.append((results[0],label))\n",
    "            print('after lookup dictionary: ',sum/len(img_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "./train/models/tmp/with_num_-03-0.739-0.913.h5\n",
      "raw acc:  0.41469489414694893\n",
      "process use  8.470003128051758\n",
      "after Q2B:  0.6650062266500623\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-08-0.341-0.970.h5\n",
      "raw acc:  0.410958904109589\n",
      "process use  8.444282054901123\n",
      "after Q2B:  0.6575342465753424\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-09-0.340-0.970.h5\n",
      "raw acc:  0.42341220423412207\n",
      "process use  8.384464502334595\n",
      "after Q2B:  0.6550435865504358\n",
      "after lookup dictionary:  0.8094645080946451\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-06-0.646-0.916.h5\n",
      "raw acc:  0.38978829389788294\n",
      "process use  8.432879209518433\n",
      "after Q2B:  0.6326276463262764\n",
      "after lookup dictionary:  0.8169364881693649\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-15-0.326-0.976.h5\n",
      "raw acc:  0.3835616438356164\n",
      "process use  8.58320426940918\n",
      "after Q2B:  0.5803237858032378\n",
      "after lookup dictionary:  0.7895392278953923\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-01-0.899-0.902.h5\n",
      "raw acc:  0.44582814445828145\n",
      "process use  9.249364137649536\n",
      "after Q2B:  0.7322540473225405\n",
      "after lookup dictionary:  0.8455790784557908\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-02-0.796-0.907.h5\n",
      "raw acc:  0.44458281444582815\n",
      "process use  8.683397054672241\n",
      "after Q2B:  0.6936488169364882\n",
      "after lookup dictionary:  0.8306351183063512\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-04-0.359-0.964.h5\n",
      "raw acc:  0.41594022415940224\n",
      "process use  9.371297359466553\n",
      "after Q2B:  0.6463262764632628\n",
      "after lookup dictionary:  0.8206724782067247\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-04-0.732-0.911.h5\n",
      "raw acc:  0.42216687422166876\n",
      "process use  8.8415048122406\n",
      "after Q2B:  0.6662515566625156\n",
      "after lookup dictionary:  0.8144458281444583\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-07-0.343-0.969.h5\n",
      "raw acc:  0.40846824408468246\n",
      "process use  8.368272542953491\n",
      "after Q2B:  0.6127023661270237\n",
      "after lookup dictionary:  0.8032378580323786\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-11-0.334-0.973.h5\n",
      "raw acc:  0.39975093399750933\n",
      "process use  9.056945085525513\n",
      "after Q2B:  0.6014943960149439\n",
      "after lookup dictionary:  0.7945205479452054\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-11-0.335-0.972.h5\n",
      "raw acc:  0.41594022415940224\n",
      "process use  8.758417844772339\n",
      "after Q2B:  0.6288916562889165\n",
      "after lookup dictionary:  0.8057285180572852\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-08-0.607-0.931.h5\n",
      "raw acc:  0.398505603985056\n",
      "process use  8.707998991012573\n",
      "after Q2B:  0.6127023661270237\n",
      "after lookup dictionary:  0.7982565379825654\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-01-0.423-0.948.h5\n",
      "raw acc:  0.43212951432129515\n",
      "process use  8.732462644577026\n",
      "after Q2B:  0.6986301369863014\n",
      "after lookup dictionary:  0.8368617683686177\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-03-0.364-0.963.h5\n",
      "raw acc:  0.41718555417185554\n",
      "process use  8.592434167861938\n",
      "after Q2B:  0.651307596513076\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-03-0.741-0.914.h5\n",
      "raw acc:  0.4259028642590286\n",
      "process use  9.572425603866577\n",
      "after Q2B:  0.6537982565379825\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-06-0.347-0.966.h5\n",
      "raw acc:  0.41594022415940224\n",
      "process use  8.512846946716309\n",
      "after Q2B:  0.635118306351183\n",
      "after lookup dictionary:  0.8019925280199253\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-08-0.335-0.970.h5\n",
      "raw acc:  0.42714819427148193\n",
      "process use  8.064187049865723\n",
      "after Q2B:  0.6363636363636364\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-07-0.655-0.932.h5\n",
      "raw acc:  0.40224159402241594\n",
      "process use  8.264684438705444\n",
      "after Q2B:  0.6189290161892902\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.947-0.896.h5\n",
      "raw acc:  0.48194271481942713\n",
      "process use  8.522989273071289\n",
      "after Q2B:  0.7783312577833126\n",
      "after lookup dictionary:  0.8592777085927771\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.836-0.910.h5\n",
      "raw acc:  0.46450809464508097\n",
      "process use  9.19881010055542\n",
      "after Q2B:  0.7334993773349938\n",
      "after lookup dictionary:  0.8443337484433375\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.830-0.919.h5\n",
      "raw acc:  0.4396014943960149\n",
      "process use  8.57240080833435\n",
      "after Q2B:  0.7023661270236613\n",
      "after lookup dictionary:  0.8331257783312578\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-01-0.402-0.953.h5\n",
      "raw acc:  0.4533001245330012\n",
      "process use  8.927712202072144\n",
      "after Q2B:  0.7322540473225405\n",
      "after lookup dictionary:  0.8368617683686177\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.761-0.915.h5\n",
      "raw acc:  0.44707347447073476\n",
      "process use  8.21621060371399\n",
      "after Q2B:  0.7036114570361146\n",
      "after lookup dictionary:  0.8368617683686177\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-02-0.376-0.960.h5\n",
      "raw acc:  0.43088418430884184\n",
      "process use  8.3121178150177\n",
      "after Q2B:  0.6973848069738481\n",
      "after lookup dictionary:  0.8194271481942715\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-03-0.367-0.962.h5\n",
      "raw acc:  0.44458281444582815\n",
      "process use  8.808175802230835\n",
      "after Q2B:  0.7073474470734745\n",
      "after lookup dictionary:  0.8343711083437111\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-01-0.919-0.905.h5\n",
      "raw acc:  0.46326276463262767\n",
      "process use  8.083636283874512\n",
      "after Q2B:  0.7422166874221668\n",
      "after lookup dictionary:  0.8518057285180572\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-04-0.357-0.965.h5\n",
      "raw acc:  0.4259028642590286\n",
      "process use  8.59463381767273\n",
      "after Q2B:  0.6537982565379825\n",
      "after lookup dictionary:  0.8194271481942715\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-02-0.793-0.908.h5\n",
      "raw acc:  0.44956413449564137\n",
      "process use  9.263514995574951\n",
      "after Q2B:  0.709838107098381\n",
      "after lookup dictionary:  0.8418430884184309\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-05-0.355-0.966.h5\n",
      "raw acc:  0.42341220423412207\n",
      "process use  9.441157341003418\n",
      "after Q2B:  0.6687422166874222\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-06-0.350-0.968.h5\n",
      "raw acc:  0.42216687422166876\n",
      "process use  8.544604539871216\n",
      "after Q2B:  0.6687422166874222\n",
      "after lookup dictionary:  0.8082191780821918\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-07-0.345-0.969.h5\n",
      "raw acc:  0.410958904109589\n",
      "process use  8.3452308177948\n",
      "after Q2B:  0.6438356164383562\n",
      "after lookup dictionary:  0.8107098381070984\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-05-0.669-0.925.h5\n",
      "raw acc:  0.40348692403486924\n",
      "process use  9.089113235473633\n",
      "after Q2B:  0.6239103362391034\n",
      "after lookup dictionary:  0.8156911581569116\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-14-0.330-0.975.h5\n",
      "raw acc:  0.40473225404732255\n",
      "process use  8.255486726760864\n",
      "after Q2B:  0.6089663760896638\n",
      "after lookup dictionary:  0.800747198007472\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-02-0.375-0.960.h5\n",
      "raw acc:  0.44084682440846823\n",
      "process use  9.141722202301025\n",
      "after Q2B:  0.7110834371108343\n",
      "after lookup dictionary:  0.8293897882938979\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-05-0.354-0.966.h5\n",
      "raw acc:  0.4259028642590286\n",
      "process use  9.226681470870972\n",
      "after Q2B:  0.6799501867995019\n",
      "after lookup dictionary:  0.8181818181818182\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-05-0.667-0.923.h5\n",
      "raw acc:  0.410958904109589\n",
      "process use  7.925950050354004\n",
      "after Q2B:  0.6562889165628891\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-08-0.633-0.932.h5\n",
      "raw acc:  0.38107098381070986\n",
      "process use  7.787084341049194\n",
      "after Q2B:  0.5990037359900373\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-03-0.739-0.913.h5\n",
      "raw acc:  0.41469489414694893\n",
      "process use  8.234461069107056\n",
      "after Q2B:  0.6650062266500623\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-08-0.341-0.970.h5\n",
      "raw acc:  0.410958904109589\n",
      "process use  7.956365346908569\n",
      "after Q2B:  0.6575342465753424\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-09-0.340-0.970.h5\n",
      "raw acc:  0.42341220423412207\n",
      "process use  8.538723230361938\n",
      "after Q2B:  0.6550435865504358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after lookup dictionary:  0.8094645080946451\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-06-0.646-0.916.h5\n",
      "raw acc:  0.38978829389788294\n",
      "process use  8.561434268951416\n",
      "after Q2B:  0.6326276463262764\n",
      "after lookup dictionary:  0.8169364881693649\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-15-0.326-0.976.h5\n",
      "raw acc:  0.3835616438356164\n",
      "process use  8.10243558883667\n",
      "after Q2B:  0.5803237858032378\n",
      "after lookup dictionary:  0.7895392278953923\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-01-0.899-0.902.h5\n",
      "raw acc:  0.44582814445828145\n",
      "process use  8.172197580337524\n",
      "after Q2B:  0.7322540473225405\n",
      "after lookup dictionary:  0.8455790784557908\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-02-0.796-0.907.h5\n",
      "raw acc:  0.44458281444582815\n",
      "process use  8.382736682891846\n",
      "after Q2B:  0.6936488169364882\n",
      "after lookup dictionary:  0.8306351183063512\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-04-0.359-0.964.h5\n",
      "raw acc:  0.41594022415940224\n",
      "process use  8.42551326751709\n",
      "after Q2B:  0.6463262764632628\n",
      "after lookup dictionary:  0.8206724782067247\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-04-0.732-0.911.h5\n",
      "raw acc:  0.42216687422166876\n",
      "process use  8.351147174835205\n",
      "after Q2B:  0.6662515566625156\n",
      "after lookup dictionary:  0.8144458281444583\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-07-0.343-0.969.h5\n",
      "raw acc:  0.40846824408468246\n",
      "process use  8.29922604560852\n",
      "after Q2B:  0.6127023661270237\n",
      "after lookup dictionary:  0.8032378580323786\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-11-0.334-0.973.h5\n",
      "raw acc:  0.39975093399750933\n",
      "process use  8.575773477554321\n",
      "after Q2B:  0.6014943960149439\n",
      "after lookup dictionary:  0.7945205479452054\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-11-0.335-0.972.h5\n",
      "raw acc:  0.41594022415940224\n",
      "process use  8.337323904037476\n",
      "after Q2B:  0.6288916562889165\n",
      "after lookup dictionary:  0.8057285180572852\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-08-0.607-0.931.h5\n",
      "raw acc:  0.398505603985056\n",
      "process use  8.876803159713745\n",
      "after Q2B:  0.6127023661270237\n",
      "after lookup dictionary:  0.7982565379825654\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-01-0.423-0.948.h5\n",
      "raw acc:  0.43212951432129515\n",
      "process use  8.656471967697144\n",
      "after Q2B:  0.6986301369863014\n",
      "after lookup dictionary:  0.8368617683686177\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-03-0.364-0.963.h5\n",
      "raw acc:  0.41718555417185554\n",
      "process use  8.375643730163574\n",
      "after Q2B:  0.651307596513076\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-03-0.741-0.914.h5\n",
      "raw acc:  0.4259028642590286\n",
      "process use  8.322208642959595\n",
      "after Q2B:  0.6537982565379825\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-06-0.347-0.966.h5\n",
      "raw acc:  0.41594022415940224\n",
      "process use  8.579752683639526\n",
      "after Q2B:  0.635118306351183\n",
      "after lookup dictionary:  0.8019925280199253\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-08-0.335-0.970.h5\n",
      "raw acc:  0.42714819427148193\n",
      "process use  9.066119194030762\n",
      "after Q2B:  0.6363636363636364\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-07-0.655-0.932.h5\n",
      "raw acc:  0.40224159402241594\n",
      "process use  8.365256071090698\n",
      "after Q2B:  0.6189290161892902\n",
      "after lookup dictionary:  0.8119551681195517\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.947-0.896.h5\n",
      "raw acc:  0.48194271481942713\n",
      "process use  8.688426494598389\n",
      "after Q2B:  0.7783312577833126\n",
      "after lookup dictionary:  0.8592777085927771\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.836-0.910.h5\n",
      "raw acc:  0.46450809464508097\n",
      "process use  9.250091314315796\n",
      "after Q2B:  0.7334993773349938\n",
      "after lookup dictionary:  0.8443337484433375\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.830-0.919.h5\n",
      "raw acc:  0.4396014943960149\n",
      "process use  9.175543785095215\n",
      "after Q2B:  0.7023661270236613\n",
      "after lookup dictionary:  0.8331257783312578\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-01-0.402-0.953.h5\n",
      "raw acc:  0.4533001245330012\n",
      "process use  9.373330354690552\n",
      "after Q2B:  0.7322540473225405\n",
      "after lookup dictionary:  0.8368617683686177\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-0.761-0.915.h5\n",
      "raw acc:  0.44707347447073476\n",
      "process use  8.931076049804688\n",
      "after Q2B:  0.7036114570361146\n",
      "after lookup dictionary:  0.8368617683686177\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-02-0.376-0.960.h5\n",
      "raw acc:  0.43088418430884184\n",
      "process use  9.679353713989258\n",
      "after Q2B:  0.6973848069738481\n",
      "after lookup dictionary:  0.8194271481942715\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-03-0.367-0.962.h5\n",
      "raw acc:  0.44458281444582815\n",
      "process use  8.492312908172607\n",
      "after Q2B:  0.7073474470734745\n",
      "after lookup dictionary:  0.8343711083437111\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-01-0.919-0.905.h5\n",
      "raw acc:  0.46326276463262767\n",
      "process use  9.121685266494751\n",
      "after Q2B:  0.7422166874221668\n",
      "after lookup dictionary:  0.8518057285180572\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-04-0.357-0.965.h5\n",
      "raw acc:  0.4259028642590286\n",
      "process use  9.000057458877563\n",
      "after Q2B:  0.6537982565379825\n",
      "after lookup dictionary:  0.8194271481942715\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-02-0.793-0.908.h5\n",
      "raw acc:  0.44956413449564137\n",
      "process use  9.31254768371582\n",
      "after Q2B:  0.709838107098381\n",
      "after lookup dictionary:  0.8418430884184309\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-05-0.355-0.966.h5\n",
      "raw acc:  0.42341220423412207\n",
      "process use  8.267529964447021\n",
      "after Q2B:  0.6687422166874222\n",
      "after lookup dictionary:  0.813200498132005\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-06-0.350-0.968.h5\n",
      "raw acc:  0.42216687422166876\n",
      "process use  8.510366916656494\n",
      "after Q2B:  0.6687422166874222\n",
      "after lookup dictionary:  0.8082191780821918\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-07-0.345-0.969.h5\n",
      "raw acc:  0.410958904109589\n",
      "process use  9.609214067459106\n",
      "after Q2B:  0.6438356164383562\n",
      "after lookup dictionary:  0.8107098381070984\n",
      "loaded model\n",
      "./train/models/tmp/with_num_-05-0.669-0.925.h5\n",
      "raw acc:  0.40348692403486924\n",
      "process use  9.299948930740356\n",
      "after Q2B:  0.6239103362391034\n",
      "after lookup dictionary:  0.8156911581569116\n",
      "loaded model\n",
      "./train/models/tmp/dropout_no_freezen_-14-0.330-0.975.h5\n",
      "raw acc:  0.40473225404732255\n",
      "process use  8.896410465240479\n"
     ]
    }
   ],
   "source": [
    "loop_test_chinese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process use  7.742420196533203\n"
     ]
    }
   ],
   "source": [
    "imgs = [cv2.imread(img_path) for img_path in img_paths]\n",
    "img_names = [os.path.split(img_path)[-1] for img_path in img_paths]\n",
    "ground_true = [strQ2B(label[img_name]) for img_name in img_names]\n",
    "result = model.recognize_on_batch(imgs,with_confidence=True)\n",
    "# sum([res[0]==ground for res,ground in zip(result,label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('甲一股专呗护理', '甲一般专项护理'),\n",
       " ('乙血液透枇/', '乙血液透析'),\n",
       " ('甲留置针(BD带0-Syte)', '甲留置针(BD带Q-Syte)'),\n",
       " ('甲透析器(Revac1er300)', '甲透析器(Revaclear300)'),\n",
       " ('丙计算机图义报告', '丙计算机图文报告'),\n",
       " ('甲静脒采血器(针头)', '甲静脉采血器(针头)'),\n",
       " ('★乙型肝炎核心抗体测定(Anti-B', '★乙型肝炎核心抗体测定(Anti-H'),\n",
       " ('★糖类抗原测定(化学发光法', '★糖类抗原测定(化学发光法)'),\n",
       " ('★乙型肝炎核心IM抗体测定(Anti', '★乙型肝炎核心IgM抗体测定(Anti'),\n",
       " ('★血清促甲状腺激素测定(:学发)', '★血清促甲状腺激素测定(仁学发'),\n",
       " ('★抗组织细胞抗体测定/', '★抗组织细胞抗体测定'),\n",
       " ('★轻链KAPPA、LAMBDMA定量(K-LC,', '★轻链KAPPA、LAMBDA定量(K-LC,'),\n",
       " ('★抗心磷脂抗体测定(ACA)', '★抗心磷脂抗体测定((ACA)'),\n",
       " ('★免疫球蛋白定量测定(免疫散射t', '★免疫球蛋白定量测定(免疫散射'),\n",
       " ('★抗核抗体测定(AA)', '★抗核抗体测定(ANA)'),\n",
       " ('★骨钙素K端中分子片段测定(N-', '★骨钙素N端中分子片段测定(N-MI'),\n",
       " ('★抗双链)NA测定(抗dsDNA)', '★抗双链DNA测定(抗dsDNA)'),\n",
       " ('抗增殖细胞核抗原抗体(抗PCA)测', '抗增殖细胞核抗原抗体(抗PCNA)测'),\n",
       " ('★总补体测定(H50)(仪器法)', '★总补体测定(CH5O)(仪器法)'),\n",
       " ('★抗中性粒细胞胞浆抗体测定(AN(', '★抗中性粒细胞胞浆抗体测定(AN'),\n",
       " ('★抗环瓜氨酸肽抗体(抗0CP抗体)', '★抗环瓜氨酸肽抗体(抗ccP抗体)'),\n",
       " ('★抗线粒体抗体测定(AM)', '★抗线粒体抗体测定(AMA)'),\n",
       " ('抗β2-糖蛋白1抗体测定7', '抗β2-糖蛋白1抗体测定'),\n",
       " ('★抗核提取物抗体测定(抗EA抗体', '★抗核提取物抗体测定(抗ENA抗体'),\n",
       " ('★乙型肝炎表面抗原测定(HBsAe)(', '★乙型肝炎表面抗原测定(HBsAg)('),\n",
       " ('抗组蛋白抗体(AA)测定', '抗组蛋白抗体(AHA)测定'),\n",
       " ('★抗链球菌溶血素0测定(AS0)(免', '★抗链球菌溶血素0测定(ASO)(免'),\n",
       " ('★丙型肝炎抗体测定(Anti-HCV).(', '★丙型肝炎抗体测定(Anti-HCV)('),\n",
       " ('★乙型肝炎表面抗体测定(Anti-B', '★乙型肝炎表面抗体测定(Anti-HE'),\n",
       " ('高压液相分析(HPLC)(指便用通用', '高压液相分析(HPLC)(指使用通用'),\n",
       " ('甲凝血酶时间测定()(急诊)', '甲凝血酶时间测定(TT)(急诊)'),\n",
       " ('甲凝血酶塬时间测定(pT)(急诊)', '甲凝血酶原时间测定(PT)(急诊)'),\n",
       " ('内r机图文报告', '丙计算机图文报告'),\n",
       " ('绷带(10*6)', '甲绷带(10*6)'),\n",
       " ('甲血清直接胆红素测定(急诊', '甲血清直接胆红素测定(急诊)'),\n",
       " ('甲血浆D-:聚体测定(急诊/p-pimr)', '甲血浆D-二聚体测定(急诊/D-Dimer)'),\n",
       " ('甲一次性注射器(50M)', '甲一次性注射器(50ML)'),\n",
       " ('甲一次性吸氯管(双鼻塞)', '甲一次性吸氧管(双鼻塞)'),\n",
       " ('ㄗ血清间接胆红素测定(急诊)', '甲血清间接胆红素测定(急诊)'),\n",
       " ('甲C反应蛋白测定(CP)(急诊)', '甲C-反应蛋白测定(CRP)(急诊)'),\n",
       " ('甲血清碳酸氢盐(03)测定', '甲血清碳酸氢盐(HCO3)测定'),\n",
       " ('丙干式片(141)', '丙干式片(14*17)'),\n",
       " ('甲三通(进I)', '甲三通(进口)'),\n",
       " ('叩总胆红素测定(急诊)', '甲总胆红素测定(急诊)'),\n",
       " ('甲一次性注射器(10L)', '甲一次性注射器(10ML)'),\n",
       " ('丙计算机图文报告(心脏超声检杳)', '丙计算机图文报告(心脏超声检查)'),\n",
       " ('甲活化部分凝血活酶时间测定(AP)', '甲活化部分凝血活酶时间测定(APTT)'),\n",
       " ('甲血清肌酸激酶-B同干.酶活性测定(急诊)', '甲血清肌酸激酶-MB同工酶活性测定(急诊)'),\n",
       " ('(甲)百特0.9%-氯化钠注射液4000m', '(甲)百特0.9%-氯化钠注射液1000ml'),\n",
       " ('(甲)百特0.9%-氯化钠注射液500ml.96.6100.', '(甲)百特0.9%-氯化钠注射液500ml5.6100'),\n",
       " ('★血清低密度脂蛋白胆固醇测定(/', '★血清低密度脂蛋白胆固醇测定('),\n",
       " ('(甲)百特0.9%-氯化钠注射液250nL5.1300', '(甲)百特0.9%-氯化钠注射液250ml5.1300'),\n",
       " ('★AB0血型鉴定(玻璃珠柱法或凝胶', '★ABO血型鉴定(玻璃珠柱法或凝胶'),\n",
       " ('★乙型肝炎核心抗体测定(Anti-P', '★乙型肝炎核心抗体测定(Anti-HB'),\n",
       " ('★乙型肝炎е抗原测定(BeAe)(化', '★乙型肝炎e抗原测定(HBeAg)(化'),\n",
       " ('数字化摄影/', '数字化摄影'),\n",
       " ('★血型单特异性抗体鉴定(凝胶柱氵', '★血型单特异抗体鉴定(凝胶柱'),\n",
       " ('★乙型肝炎表面抗原测定(HBsAe)(', '★乙型肝炎表面抗原测定(HBsAg)'),\n",
       " ('★乙型肝炎表面抗体测定(Anti-肥', '★乙型肝炎表面抗体测定(Anti-HB'),\n",
       " ('★乙型肝炎е抗体测定(Anti-HBe)(', '★乙型肝炎e抗体测定(Anti-HBe)'),\n",
       " ('★糖类抗原测定(化学发光法/', '★糖类抗原测定(化学发光法)'),\n",
       " ('★血清载脂蛋白AⅠ测定', '★血清载脂蛋白AI测定'),\n",
       " ('★血清载脂蛋白в测定', '★血清载脂蛋白B测定'),\n",
       " ('(甲)大冢-氯化钾注射液1.5500', '(甲)大冢-氯化钾注射液1g1.2500'),\n",
       " ('★血清碳酸氢盐(HC03))测定', '★血清碳酸氢盐(HC03)测定'),\n",
       " ('(甲)辰欣-葡萄糖氯化钠注射液500ml,,3.8s600', '(甲)辰欣-葡萄糖氯化钠注射液500ml3.8500'),\n",
       " ('(甲)枸橼酸舒芬太尼注射液50μ50.1700', '(甲)枸橼酸舒芬太尼注射液50μg50.1700'),\n",
       " ('★血清脂蛋白g测定', '★血清脂蛋白a测定'),\n",
       " ('★血清高密度脂蛋白胆固醇测定(/', '★血清高密度脂蛋白胆固醇测定('),\n",
       " ('★血清V-谷氨酰基转移酶测定', '★血清γ-谷氨酰基转移酶测定'),\n",
       " ('★乙型肝炎表面抗原测定(BsM)(', '★乙型肝炎表面抗原测定(HBsAg)'),\n",
       " ('★血清前白蛋白测定(免疫散射比氵', '★血清前白蛋白测定(免疫散射比'),\n",
       " ('降钙素检测(化学发光法)', '降钙素原测定(化学发光法)'),\n",
       " ('★血清碳酸氢盐(H003)测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('★人Π型前胶原肽(PIIP)测定', '★人Ⅲ型前胶原肽(PⅢP)测定'),\n",
       " ('血清肌酸激酶一细同工酶质量测定', '血清肌酸激酶-MB同工酶质量测定'),\n",
       " ('★血清(肽测定', '★血清C肽测定'),\n",
       " ('★B型钠尿肽前体(PR0-BNP)测定×', '★B型钠尿肽前体(PRO-BNP)测定'),\n",
       " ('★血清脂蛋白g测定', '★血清脂蛋白a测定'),\n",
       " ('★乙型肝炎表面抗体测定(Anti-HB', '★乙型肝炎表面抗体测定(Anti-H'),\n",
       " ('★血清总蛋白测定((化学法)', '★血清总蛋白测定(化学法)'),\n",
       " ('甲抗甲状腺过氧化物酶抗休测定', '甲抗甲状腺过氧化物酶抗体测定'),\n",
       " ('甲血清a-L-岩藻糖苷酶测定', '甲a-L-岩藻糖苷酶测定'),\n",
       " (':(', '甲床位费'),\n",
       " ('甲乙肝核心IewM抗体测定(定量)(免疫室)', '甲乙肝核心IgM抗体测定(定量)(免疫室)'),\n",
       " ('甲钠测定(诊)', '甲钠测定(急诊)'),\n",
       " ('甲AB0血型鉴定(门诊)', '甲ABO血型鉴定(门诊)'),\n",
       " ('甲丙型肝炎抗体Ie测定', '甲丙型肝炎抗体IgG测定'),\n",
       " ('甲葡葡糖测定(病房)', '甲葡萄糖测定(病房)'),\n",
       " ('丙Rh弱p血型鉴定试验', '丙Rh弱D血型鉴定试验'),\n",
       " ('丙离休残肢处坩', '丙离体残肢处理'),\n",
       " ('甲血浆抗凝血酶Π活性测定(AT—)', '甲血浆抗凝血酶Ⅲ活性测定(AT-ⅢA)'),\n",
       " ('H梅毒螺旋体特异抗体测定', '甲梅毒螺旋体特异抗体测定'),\n",
       " ('甲血红蛋白测定(b)', '甲血红蛋白测定(Hb)'),\n",
       " ('甲血消碱性磷酸酶测定', '甲血清碱性磷酸酶测定'),\n",
       " ('甲凝血酶塬时间测定(PT)', '甲凝血酶原时间测定(RT)'),\n",
       " ('甲血清甘油.:酯测定', '甲血清甘油三酯测定'),\n",
       " ('甲血消丙氨酸氨基转移酶测定', '甲血清丙氨基酸氨基转移酶测定'),\n",
       " ('咀钙测定', '甲钙测定'),\n",
       " ('甲血清讪接胆红素测定', '甲血清间接胆红素测定'),\n",
       " ('甲γcn(血清V-谷氨酰基转移酶测定)', '甲γ-GT(血清γ-谷氨酰基转移酶测定)'),\n",
       " ('甲血消碳酸氢盐(003)测定(急诊)', '甲血清碳酸氢盐(HCO3)测定(急诊)'),\n",
       " ('叩血清天门冬氨酸氨基转移酶测定', '甲血清天门冬氨酸氨基转移酶测定'),\n",
       " ('甲血清载脂蛋白в测定', '甲血清载脂蛋白Β测定'),\n",
       " ('甲活化部分凝血活酶时间测定(MPTT)', '甲活化部分凝血活酶时间测定(APTT)'),\n",
       " ('甲血清a--岩藻糖酶测定', '甲血清a-L-岩藻糖苷酶测定'),\n",
       " ('甲血清总蛋白测定(血〉', '甲血清总蛋白测定(血)'),\n",
       " ('甲血消白蛋白测定', '甲血清白蛋白测定'),\n",
       " ('甲丙型肝炎抗体Ie测定', '甲丙型肝炎抗体IgG测定'),\n",
       " ('甲红细胞比积测定(CT)', '甲红细胞比积测定(HCT)'),\n",
       " ('甲血浆p-二聚体测定(0-pingr)', '甲血浆D-二聚体测定(D-Dimer)'),\n",
       " ('甲C—反应蛋白测定(cRP)', '甲C-反应蛋白测定(CRP)'),\n",
       " ('甲凝血酶时测定(m)', '甲凝血酶时间测定(TT)'),\n",
       " ('血清胱抑素(Cystatin)测定', '血清胱抑素(CystatinC)测定'),\n",
       " ('★血清裁脂蛋测定', '★血清我脂蛋白E测定'),\n",
       " ('★血清载脂蛋白测定', '★血清载脂蛋白B测定'),\n",
       " ('★免疫固定电泳(蛋白分型)', '★免疫固定电泳(M蛋白分型)'),\n",
       " ('血清肌酸激酶一B同工酶质量测定', '血清肌酸激酶一MB同工酶质量测定'),\n",
       " ('★血清肌酸激酶一B同T酶活性测', '★血清肌酸激酶一MB同工酶活性测'),\n",
       " ('★血清前白蛋白测定(免疫散射比氵', '★血清前白蛋白测定(免疫散射比'),\n",
       " ('★血清碳酸氢盐(H003)测定', '★血清碳酸氢盐(HC03)测定'),\n",
       " ('★B型钠尿肽前体(PR0-BP)测定', '★B犁钠尿肽前体(PRO-BNP)测定'),\n",
       " ('★血清天门冬氨酸氨基转移酶测定', '★血清天门冬氰酸氨基转移酶测定'),\n",
       " ('★血同型半胱氨酸测定(其它免疫2', '★血同型半胱氨酸测定(其它免疫'),\n",
       " ('★血清γ-谷氨酰基转移酶测定', '★血清γ-谷氨酸基转移酶测定'),\n",
       " ('★血清蛋白电冰', '★血清蛋白电泳'),\n",
       " ('★血清载脂蛋白AⅠ测定', '★血清载脂蛋白AI测定'),\n",
       " ('尿-乙酰-β--氨基葡萄糖苷酶测', '尿N-乙酰一β一D一氨基葡萄糖苷酶测'),\n",
       " ('★视黄醉结合蛋白测定(免疫散射t', '★视黄醇结合蛋白测定(免疫散射'),\n",
       " ('★B2微球蛋白测定(免疫散射比浊', '★β2微球蛋白测定(免疫散射比浊'),\n",
       " ('甲抗甲状腺球蛋白抗体测定(TMb)', '甲抗甲状腺球蛋白抗体测定(TGAb)'),\n",
       " ('甲血清β-羟基丁酸测定', '甲血清B-羟基丁酸测定'),\n",
       " ('甲神经元特异性烯醇化酶测定(NSB)', '甲神经元特异性烯醇化酶测定(NSE)'),\n",
       " ('甲糖类抗原cA15-3测定', '甲糖类抗原CA15-3测定'),\n",
       " ('甲血清载脂蛋白AⅠ测定', '甲血清载脂蛋白AI测定'),\n",
       " ('甲抗碱血红蛋白测定(bF)', '甲抗碱血红蛋白测定(HbF)'),\n",
       " ('甲乙肝表面抗原测定(BsAe)', '甲乙肝表面抗原测定(HBsAg)'),\n",
       " ('丙血清胱抑素(0ystatinc)测定', '丙血清胱抑素(CystatinC)测定'),\n",
       " ('甲细胞角蛋白19片段测定(CFpA21-1)', '甲细胞角蛋白19片段测定(CYFRA21-1)'),\n",
       " ('甲血浆D-二聚体测定(D-pimer)', '甲血浆D-二聚体测定(D-Dimer)'),\n",
       " ('甲0一反应蛋白测定(cRP)', '甲C一反应蛋白测定(CRP)'),\n",
       " ('甲血清甲状腺素(r4)测定', '甲血清甲状腺素(T4)测定'),\n",
       " ('甲血清肌钙蛋白【测定', '用血清肌钙蛋白I测定'),\n",
       " ('甲癌胚抗原测定(CE)血', '甲癌胚抗原测定(CEA)血'),\n",
       " ('甲鳞状细胞癌相关抗原测定(sC)', '甲鳞状细胞癌相关抗原测定(SCC)'),\n",
       " ('甲丙型肝炎抗体Tec测定', '甲丙型肝炎抗体IgG测定'),\n",
       " ('甲h血型鉴定', '甲Rh血型鉴定'),\n",
       " ('★血清总胆固醇测定(化学法或酶氵', '★血清总胆固醇测定(化学法或酶'),\n",
       " ('★血清脂蛋白g测定', '★血清脂蛋白a测定'),\n",
       " ('★血浆凝血酶原时可测定(PT)(仪', '★血浆凝血酶原时间测定(PT)(仪'),\n",
       " ('★Rh血型鉴定(玻璃珠柱法或凝胶*', '★Rh血型鉴定(玻璃珠柱法或凝胶'),\n",
       " ('★乙型肝炎表面抗原测定(BsA)(', '★乙型肝炎表面抗原测定(HBsAg)'),\n",
       " ('★乙型肝炎e抗原测定(BeA)(化', '★乙型肝炎e抗原测定(HBeAg)(化学'),\n",
       " ('★血清γ~谷氨酰基转移酶测定', '★血清γ-谷氨酰基转移酶测定'),\n",
       " ('★活化部分凝血活酶时间测定(4PT', '★活化部分凝血活酶时间测定(AP'),\n",
       " ('★AB0血型鉴定(玻璃珠柱法或凝胶', '★ABO血型鉴定(玻璃珠柱法或凝胶'),\n",
       " ('★乙型肝炎表面抗体测定(Ant-l', '★乙犁肝炎表面抗体测定(Anti-H'),\n",
       " ('★乙型肝炎核心抗体测定(Mnti-l匪J', '★乙型肝炎核心抗体测定(Anti-H'),\n",
       " ('★血型单特异性抗体鉴定(凝胶柱?', '★血型单特异性抗体鉴定(凝胶柱'),\n",
       " ('★血消尿酸测定(化学法)', '★血滴尿酸测定(化学法)'),\n",
       " ('血浆0-二聚体测定(0-)imgr)', '血浆D-二聚体测定(D-Dimer)'),\n",
       " ('★丙型肝炎抗体测定(Anti-HCv)(', '★丙型肝炎抗体测定(Anti-HCV)('),\n",
       " ('人免疫缺陷病毒抗休测定(Anti1-Hl', '人免疫缺陷病毒抗体测定(Anti-H'),\n",
       " ('★血清碳酸氢盐(003)测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('★血清载脂蛋白в测定', '★血清载脂蛋白B测定'),\n",
       " ('★血清裁脂蛋白AⅠ测定', '★血清载脂蛋白AI测定'),\n",
       " ('Ⅱ床位费', '甲床位费'),\n",
       " ('甲汪射器10ml', '甲注射器10ml'),\n",
       " ('内W各绱椅费', '丙陪客躺椅费'),\n",
       " ('葡萄糖测定(病房)', '甲葡萄糖测定(病房)'),\n",
       " ('甲注射器20nl', '甲注射器20ml'),\n",
       " ('1特级护理', '甲特级护理'),\n",
       " ('乙泮托拉唑针(泮立苏)40毫克*1支(40毫克*1支)(46', '乙泮托拉唑针(泮立苏)40毫克*1支(40毫克*1支)(4'),\n",
       " ('乙吉西他滨针(泽菲)200毫克*1支(200毫克1支)(200', '乙吉西他滨针(泽菲)200毫克*1支(200毫克*1支)(200'),\n",
       " ('甲阿昔洛韦乳膏3%10克*1支(3%10克1支)(3%10克', '甲阿昔洛韦乳膏3%10克*1支(3%10克*1支)(3%10克'),\n",
       " ('1*8化钠注射液0.9%100毫升*1脂(0.9%100毫升*11', '甲*氯化钠注射液0.9%100毫升*1瓶(0.9%100毫升*1)'),\n",
       " ('甲氯化钠针(大冢)0.9%10毫升1支(0.9%10毫升+)', '甲氯化钠针(大冢)0.9%10毫升*1支(0.9%10毫升*'),\n",
       " ('乙(8g)昂丹司琼(欧贝)针8毫克/4毫升*1支(8毫克/', '乙(8mg)昂丹司琼(欧贝)针8毫克/4毫升*1支(8毫克'),\n",
       " ('甲J静脉置管护理', '甲动静脉置管护理'),\n",
       " ('甲敷贴9546lP(动静脉置管护理用)', '甲敷贴9546HP(动静脉置管护理用)'),\n",
       " ('甲血浆-二聚体测定(p-pimer)', '甲血浆D-二聚体测定(D-Dimer)'),\n",
       " ('丙血清胱抑素(Cystatinc)测定', '丙血清胱抑素(CystatinC)测定'),\n",
       " ('甲血清a--岩藻糖苷酶测定', '甲血清a-L-岩藻糖苷酶测定'),\n",
       " ('甲肌酐测定(急诊)', '用肌酐测定(急诊)'),\n",
       " ('甲乙肝表面抗原测定(BsAe)', '甲乙肝表面抗原测定(HBsAg)'),\n",
       " ('甲神经元特异性烯醇化酶测定(NS)', '甲神经元特异性烯醇化酶测定(NSE)'),\n",
       " ('甲鳞状细胞癌相关抗原测定(S0C)', '甲鳞状细胞癌相关抗原测定(SCC)'),\n",
       " ('甲丙型肝炎抗体Iec测定', '甲丙型肝炎抗体IgG测定'),\n",
       " ('甲抗甲状腺球蛋白抗体测定(TAb)', '甲抗甲状腺球蛋白抗体测定(TGAb)'),\n",
       " ('甲血清载脂蛋白AⅠ测定', '甲血清载脂蛋白AI测定'),\n",
       " ('甲C—反应蛋白测定(CRp)', '甲C一反应蛋白测定(CRP)'),\n",
       " ('甲血清三碘甲状原氨酸(3)测定', '甲血清三碘甲状原氨酸(T3)测定'),\n",
       " ('甲血清载脂蛋白в测定', '申血清载脂蛋白B测定'),\n",
       " ('甲血游离脂肪酸测定', '用血游离脂肪酸测定'),\n",
       " ('甲抗碱血红蛋白测定(bF)', '甲抗碱血红蛋白测定(HbF)'),\n",
       " ('甲血清肌钙蛋白Ⅰ测定', '甲血清肌钙蛋白I测定'),\n",
       " ('甲血清游离叩状腺素(FT4)测定', '甲血清游离甲状腺素(FT4)测定'),\n",
       " ('乙螺旋C增强扫描(≥个部位)', '乙螺旋CT增强扫描(≥三个部位)'),\n",
       " ('甲血清aL藻糖苷酶测定', '甲血清a-L-岩藻糖苷酶测定'),\n",
       " ('乙彩色多普勒超声常规检杳(个部)', '乙彩色多普勒超声常规检查(一个部位)'),\n",
       " ('丙手术中使用一次性ㄗ生材料加收(丙)', '丙手术中使用一次性卫生材料加收(丙)'),\n",
       " ('甲血清甲状腺素(4)测定', '甲血清甲状腺素(T4)测定'),\n",
       " ('乙1CU单元治疗(14天以内)', '乙ICU单元治疗(14天以内)'),\n",
       " ('I叩颅内多发血肿清除术', '甲颅内多发血肿清除术'),\n",
       " ('甲脉采血', '甲动脉采血'),\n",
       " ('使用带吸刮功能手术解剖器加收(颅骨和脑手术', '甲使用带吸刮功能手术解剖器加收(颅骨和脑手术'),\n",
       " ('甲术巾口休血j收', '甲术中自体血同收'),\n",
       " ('甲血清促状腺激素测定', '甲血清促甲状腺激素测定'),\n",
       " ('甲血同型半胱级酸测定', '甲血同型半胱氨酸测定'),\n",
       " ('甲静脉穷刺置管术', '甲静脉穿刺置管术'),\n",
       " ('乙16层及以上多排螺旋扫描加收', '乙16层及以上多排螺旋CT扫描加收'),\n",
       " ('甲血清三碘叩状原氨酸(T:3)测定', '甲血清三碘甲状原氨酸(T3)测定'),\n",
       " ('#呼吸机辅助)呼吸', '甲呼吸机辅助呼吸'),\n",
       " ('内红织多普勒显像()I)', '丙组织多普勒显像(TDI)'),\n",
       " ('★血清ⅳ-谷氨酰基转移酶测定', '★血清γ-谷氨酰基转移酶测定'),\n",
       " ('★活化部分凝血活酶时间测定(4pr', '★活化部分凝血活酶时间测定(APT'),\n",
       " ('★血清V-谷氨酰基转移酶测定(干', '★血清γ-谷氨酰基转移酶测定(干'),\n",
       " ('★血细胞分析(三分类以上)0600066', '★血细胞分析(三分类以上)20.0000480.00'),\n",
       " ('★血浆凝血酶原时间测定(pT)(仪', '★血浆凝血酶原时间测定(PT)(仪'),\n",
       " ('.★血清直接胆红素测定(化学法或', '★血清直接胆红素测定(化学法或'),\n",
       " ('★葡萄糖测定(干化学法全自动生亻', '★葡萄糖测定(干化学法全自动生'),\n",
       " ('血浆D-二聚体测定(0-)imer)', '血浆D-二聚体测定(D-Dimer)'),\n",
       " ('★血消清白蛋白测定(化学法)', '★血清白蛋白测定(化学法)'),\n",
       " ('★血清前白蛋白测定(免疫散射比9', '★血清前白蛋白测定(免疫散射比'),\n",
       " ('★镁测定(离子迭择电极法)', '★镁测定(离子选择电极法)'),\n",
       " ('★血清大门冬氨酸氨基转移酶测定', '★血清天门冬氨酸氨基转移酶测定'),\n",
       " ('★血渚丙氨酸氨基转移酶测定(干4', '★血清丙氨酸氨基转移酶测定(干'),\n",
       " ('★血清碳酸氢盐(H003)测定(干化', '★血清碳酸氢盐(HCO3)测定(干化'),\n",
       " ('★血清碳酸氢盐(H03)测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('小密低密度脂蛋白(sdLL)测定/', '小密低密度脂蛋白(sdLDL)测定'),\n",
       " ('★血清低密度脂蛋白胆固醇测定(', '★血清低密度脂蛋白胆固醇测定'),\n",
       " ('★血清高密度脂蛋白胆固醇测定(', '★血清高密度脂蛋白胆固醇测定'),\n",
       " ('★钠湖定(离子选择电极法)', '★钠测定(离子选择电极法)'),\n",
       " ('★葡萄糖测定(干化学法简易血糖', '★葡萄糖测定(干化学法简易血糖)'),\n",
       " ('★血清前白蛋白测定(免疫散射比氵', '★血清前白蛋白测定(免疫散射比'),\n",
       " ('★乙型肝炎表面抗原测定(BsAe)(', '★乙型胼炎表面抗原测定(HBsAg)'),\n",
       " ('★乙型肝炎表面抗体涮定(Anti-肥', '★乙型肝炎表面抗体测定(Anti-HE'),\n",
       " ('★活化部分凝血活酶时间测定(APT', '★活化部分凝血活酶时间测定(AP'),\n",
       " ('组织/细胞荧光定量脱氧核糖核酸易x', '组织/细胞荧光定量脱氧核糖核酸'),\n",
       " ('血浆D-聚体测定(0-Diner)', '血浆D-二聚体测定(D-Dimer)'),\n",
       " ('降钙素原检测(化学发光法)X', '降钙素原检测(化学发光法)'),\n",
       " ('★血清尿酸测定(化学法)', '★血清尿酸测定'),\n",
       " ('★血清载脂蛋白AⅠ测定', '★血清载脂蛋白AI测定'),\n",
       " ('★血清碳酸氢盐(008)测定', '★血清碳酸总盐(HCO3)测定'),\n",
       " ('★血清脂蛋白g测定', '★血清脂蛋白a测定'),\n",
       " ('310701001b电胶多导联心电图30.0000', '310701001b电脑多导联心电图30.0000'),\n",
       " ('★血清载脂蛋白Β测定', '★血清载脂蛋白B测定'),\n",
       " ('★血清载脂蛋白B测定', '★血清载脂蛋白E测定'),\n",
       " ('测定(离子选搔电极法)', '钙测定(离子选择电极法)'),\n",
       " ('★血清前白蛋白测定(免疫散射比氵', '★血清前白蛋白测定(免疫散射比'),\n",
       " ('异常血小板形态检查人', '异常血小板形态检查'),\n",
       " ('★凝血酶时间测定(T)(仪器法)', '★凝血酶时间测定(TT)(仪器法)'),\n",
       " ('★血浆凝血酶原时向测定(PT)(仪', '★血浆凝血酶原时间测定(PT)(仪'),\n",
       " ('血小板聚集功能测定(PAeT)(酶免', '血小板聚集功能测定(PAgT)(酶免'),\n",
       " ('血浆D-二聚体测定(0-Dimer)', '血浆D-二聚体测定(D-Dimer)'),\n",
       " ('★钾测定(8子选择电极法)', '★钾测定(离子选择电极法)'),\n",
       " ('血红蛋白测定(b)', '血红蛋白测定(Hb)'),\n",
       " ('★血清碳酸氢盐(H003)测定', '★血清碳酸氢盐(HCO3)测定'),\n",
       " ('葑续血片监测', '甲持续血压监测'),\n",
       " ('丙(迈普新)胸腺法新针1.6毫克1支(1.6毫克1支)(', '丙(迈普新)胸腺法新针1.6亳克*1支(1.6毫克*1支)'),\n",
       " ('乙腺苷蛋氨酸(喜美欣)针0.5克1瓶(0.5克1瓶)(0.', '乙腺苷蛋氨酸(喜美欣)针0.5克*1瓶(0.5克*1瓶)(0.'),\n",
       " ('乙帕洛诺司琼(吉欧停)针0.25毫克/5毫升1支(0.25', '乙帕洛诺司琼(吉欧停)针0.25毫克/5毫升*1支(0.25毫'),\n",
       " ('乙(艾滨)卡培他滨片500毫克:12片(500毫克*12片)(', '乙(艾滨)卡培他滨片500毫克*12片(500毫克*12片)'),\n",
       " ('甲氯化钠注射液0.9%500毫升1袋(0.9%500毫升1袋', '甲氯化钠注射液0.9%500毫升*1袋(0.9%500毫升*1袋'),\n",
       " ('t氯化钠注射液0.9%250毫升*1瓶(0.9%250毫*1邢', '甲氯化钠注射液0.9%250毫升*1瓶(0.9%250毫升*1瓶'),\n",
       " ('甲血细胞簇分化抗原c056检测(传研所)', '甲血细胞簇分化抗原CD56检测(传研所)'),\n",
       " ('甲(5mg)地塞米松注射液5毫克*1支(5毫克1支)(5毫克', '甲(5mg)地塞米松注射液5亳克*1支(5毫克*1支)(5毫克'),\n",
       " ('甲深静脉穿刺置管术(PTC)', '甲深静脉穿刺置管术(PICC)'),\n",
       " ('血浆D-二聚体测定(D-Dime)', '甲血浆D-二聚体测定(D-Dimer)'),\n",
       " ('甲血细胞簇分化抗原C08检测(传研所)', '甲血细胞簇分化抗原CD8检测(传研所)'),\n",
       " ('乙复方碳酸氢钠含漱液(制)200毫升*1瓶(200毫升1瓶', '乙复方碳酸氢钠含漱液(制)200毫升*1瓶(200毫升*1瓶'),\n",
       " ('乙注射用水5毫升*1支(5毫升1支)(5毫升*1支)', '乙注射用水5毫升*1支(5毫升*1支)(5毫升*1支)'),\n",
       " ('乙瑞格列奈片(诺和龙)1毫克:30片(1毫克30片)(1定', '乙瑞格列奈片(诺和龙)1毫克*30片(1毫克*30片)(1毫'),\n",
       " ('乙奥沙利铂针(艾恒)50毫克1瓶(50毫克1瓶)(50毫克', '乙奥沙利铂针(艾恒)50毫克*1瓶(50毫克*1瓶)(50毫克'),\n",
       " ('静脉注射', '甲静脉注射'),\n",
       " ('甲+氯化钠注射液0.9%100毫升:1瓶(0.9%100毫升:11', '甲*氯化钠注射液0.9%100毫升*1瓶(0.9%100毫升*1)'),\n",
       " ('甲58葡萄糖注射液5%250毫升1瓶(5%250毫升1瓶)1', '甲5%葡萄糖注射液5%250毫升*1瓶(5%250毫升*1瓶)'),\n",
       " ('乙(艾速平)艾司奥美拉唑钠针40毫克1瓶(40毫克11', '乙(艾速平)艾司奥美拉唑钠针40毫克*1瓶(40毫克*1}')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(check_str):\n",
    "    len_str = len(check_str)\n",
    "    cutoff = 0.7\n",
    "    if len_str <= 3:\n",
    "        cutoff = 0.5\n",
    "    elif len_str <= 5:\n",
    "        cutoff = 0.6\n",
    "    return cutoff\n",
    "with open('./train/create_dataset/name_dictionary_v1.2.txt') as f:\n",
    "    medicine = f.readlines()\n",
    "medicine = [name.split('\\n')[0] for name in medicine ]\n",
    "medicine = list(set(medicine))\n",
    "len(medicine)\n",
    "medicine = [strQ2B(name)  for name in medicine]\n",
    "\n",
    "\n",
    "def get_closest_matches(item):\n",
    "    result,label = item\n",
    "    cutoff = check_name(result)\n",
    "    match_result = difflib.get_close_matches(result, medicine,cutoff=cutoff)\n",
    "    if match_result:\n",
    "        return (match_result,label)\n",
    "    else:\n",
    "        return (result,label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.4 ms, sys: 107 ms, total: 182 ms\n",
      "Wall time: 6.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.813200498132005"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool,cpu_count\n",
    "pool = Pool(cpu_count()//4)\n",
    "# % time match_results = [get_closest_matches(item) for item in error_list ]\n",
    "\n",
    "sum=true_sum\n",
    "%time match_results = pool.map(get_closest_matches,error_list)\n",
    "match_error = []\n",
    "for results,label in match_results:\n",
    "    if label == results[0]:\n",
    "        sum +=1\n",
    "    else:\n",
    "        match_error.append((results[0],label))\n",
    "sum/len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8119551681195517"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum/len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试验证模型冻结层的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  densenet  import densenet\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "characters = keys.alphabet[:]\n",
    "characters = characters[:] \n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "input = Input(shape=(32, None, 1), name='the_input')\n",
    "y_pred = densenet.dense_cnn(input, nclass)\n",
    "basemodel = Model(inputs=input, outputs=y_pred)\n",
    "modelPath = './densenet/models/weights_densenet_with_name.h5'\n",
    "\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    basemodel.load_weights(modelPath)\n",
    "    print('done!') \n",
    "  \n",
    "    \n",
    "# basemodel.save_weights('./models/no_use_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters = keys.alphabet_union[:]\n",
    "# characters = characters[:] \n",
    "# nclass = len(characters)\n",
    "\n",
    "basemodel2 = Model(inputs=input,outputs=basemodel.get_layer('flatten').output)\n",
    "for i,layer in enumerate(basemodel2.layers):\n",
    "    layer.set_weights = basemodel.layers[i].weights\n",
    "flatten = basemodel.get_layer('flatten').output\n",
    "y_pred = Dense(nclass, name='out', activation='softmax')(flatten)\n",
    "basemodel3 =  Model(inputs=input,outputs=y_pred)\n",
    "for i,layer in enumerate(basemodel3.layers):\n",
    "    layer.set_weights = basemodel.layers[i].weights\n",
    "# basemodel4 = Model(inputs=input,outputs=basemodel.get_layer('Time').output)\n",
    "# basemodel4.load_weights()\n",
    "# basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel4 = Model(inputs=input,outputs=basemodel.get_layer('flatten').output)\n",
    "basemodel4.load_weights('./models/pre_y_pred_weights.h5')\n",
    "for i,layer in enumerate(basemodel.layers[:-1]):\n",
    "    layer.set_weights = basemodel4.layers[i].weights\n",
    "#     print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel3.layers[-1].set_weights = basemodel.layers[-1].weights\n",
    "print(basemodel.layers[-1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel3.save_weights('./models/merge_weights_pretrain_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nclass)\n",
    "input1 = Input(shape=(32, None, 1), name='the_input')\n",
    "y_pred1 = densenet.dense_cnn(input1, nclass)\n",
    "basemodel5 = Model(inputs=input1, outputs=y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.save_weights('./densenet/models/weights_densenet_with_name.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel5.load_weights('./densenet/models/weights_densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.get_layer('pool3_0_avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(basemodel5.layers):\n",
    "    print(i,layer.name,layer) \n",
    "#     print(layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用plot_model 观测模型情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(densenet_keras.basemodel,to_file='./models/rename_model.png')\n",
    "plt.figure(figsize=(40,200))\n",
    "img = Image.open('./models/rename_model.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多GPU预测性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import  multi_gpu_model\n",
    "with tf.device('/cpu:0'):\n",
    "    base_model =densenet_cnn_model()\n",
    "    base_model.load_weights('./models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "parallel_model = multi_gpu_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.backend import ctc_decode\n",
    "\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "nClass = len(characters)\n",
    "def recognize_on_batch(img_list,basemodel):\n",
    "#         start = time.time()\n",
    "    max_w = int(max([32.0/img.shape[0]*img.shape[1] for img in img_list]))\n",
    "#         print(max_w)\n",
    "#         assert len(img_list) < 128\n",
    "    img_batch = np.ones([len(img_list),32,max_w,1])*0.5\n",
    "    for i,img in enumerate(img_list):\n",
    "        img_L = img.astype(np.float32)\n",
    "        if len(img_L.shape) ==3:\n",
    "            img_L = img_L[:,:,0]*114/1000 + img_L[:,:,1]* 587/1000 + img_L[:,:,2]* 299/1000 \n",
    "        scale = img_L.shape[0]*1.0/32.0\n",
    "        w = int(img_L.shape[1]/scale)\n",
    "        img = cv2.resize(img_L,(w,32),cv2.INTER_AREA)\n",
    "        img = img/ 255.0 - 0.5\n",
    "        img = img.reshape((32, w, 1))\n",
    "        img_batch[i,:,:w,:] = img\n",
    "    start = time.time()\n",
    "    y_pred = basemodel.predict_on_batch(img_batch)\n",
    "    end = time.time()\n",
    "    print('process use ' ,end-start)\n",
    "    out_list = []\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        y_encode = np.array([y_pred[i,:,:]]) \n",
    "        out = decode(y_encode)  ##\n",
    "        out_list.append(out)\n",
    "    return out_list\n",
    "\n",
    "\n",
    "def decode(pred,with_confidence=False):\n",
    "    text = pred.argmax(axis=2)[0]\n",
    "    length = len(text)\n",
    "    char_list = []\n",
    "    n = nClass-1\n",
    "    for i in range(length):\n",
    "        # 这里text[i] != n就是处理出来的分隔符，text[i - 1] == text[i]处理重复的字符\n",
    "        if text[i] != n and (not (i > 0 and text[i - 1] == text[i])):\n",
    "                char_list.append(characters[text[i]])\n",
    "\n",
    "    if with_confidence:\n",
    "        pred_max = pred.max(axis=2)[0]\n",
    "        confidence_list = [] \n",
    "        for i in range(length):\n",
    "            # 这里text[i] != n就是处理出来的分隔符，text[i - 1] == text[i]处理重复的字符\n",
    "            if text[i] != n and (not (i > 0 and text[i - 1] == text[i])):    \n",
    "                    confidence_list.append(pred_max[i])\n",
    "        length_confidence = len(confidence_list)\n",
    "\n",
    "        if length_confidence < 3:\n",
    "            confidence = np.mean(confidence_list)\n",
    "        else :\n",
    "            sorted_confidence = np.sort(confidence_list)\n",
    "            confidence = np.mean(sorted_confidence[:length_confidence//2])\n",
    "        return u''.join(char_list),confidence\n",
    "    return u''.join(char_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(u'/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*50\n",
    "img_paths = random.sample(img_paths,1000)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "%time result_list = recognize_on_batch(img_list,parallel_model)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "KTF._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [x.name for x in sess.list_devices()]\n",
    "name = ['/' + ':'.join(name.lower().replace('/', '').split(':')[-2:]) for name in devices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,3))\n",
    "print(a.shape)\n",
    "b = np.reshape(a,(3,-1))\n",
    "print(b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "a = np.random.rand(4)\n",
    "print(a)\n",
    "b = a[[1,3]]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = b[0][1]\n",
    "tf.reset_default_graph()\n",
    "out = tf.placeholder(tf.float32,[None,10,6])\n",
    "value = tf.reduce_max(out,axis=2)\n",
    "index = tf.argmax(out,axis=2)\n",
    "output = tf.group(index,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "np.random.seed(1)\n",
    "input_value = np.random.rand(4,10,6)\n",
    "output_run = sess.run([index,value],{out:input_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_run[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    c = tf.constant('adf')\n",
    "    sess  = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.graph == sess.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
