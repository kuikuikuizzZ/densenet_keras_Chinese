{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CUDA_VISIBLE_DEVICES=1\n",
    "#coding:utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from densenet.densenet_lib import Densenet_keras\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd())+'densenet/')\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# import keys_union\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import difflib\n",
    "import re\n",
    "import random\n",
    "import cv2\n",
    "import densenet.keys as keys\n",
    "import densenet.keys_keras as keys_keras\n",
    "import densenet.densenet_lib as densenet_lib\n",
    "import numpy as np\n",
    "import densenet.keys_keras as keys_keras\n",
    "import densenet.model as model\n",
    "from densenet.model import densenet_cnn_model,densenet_rnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(densenet_lib)\n",
    "imp.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/trans_model/model_75layers_labeled_ch_len25_v1.pb'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_tf = densenet_lib.Densenet_tf_multi_gpus(pb_model_path=model_path,characters=characters,fixed_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/trans_model/model_75layers_labeled_ch_len25_v1.pb'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_tf_1 = densenet_lib.Densenet_tf(pb_model_path=model_path,characters=characters,fixed_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/75layers_labeled_ch_len25_v1-3.060-0.505.h5'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "# len(characters)\n",
    "densenet_keras = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                             model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './densenet/models/weights_densenet.h5'\n",
    "characters = keys.alphabet[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "densenet_keras_5990 = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                                  model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './train/models/freezen_5layers_dataset_v1-0.672-0.894.h5'\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "densenet_keras_2 = densenet_lib.Densenet_keras(get_model_function=model.densenet_cnn_model,\n",
    "                                                model_path=model_path,characters=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet_keras_5990.load_weights('./densenet/models/weights_densenet_with_name.h5')\n",
    "densenet_keras_5990.basemodel = basemodel5\n",
    "# densenet_keras_2.load_weights('./train/models/random_len20-06-0.400-0.926.h5')\n",
    "\n",
    "# imgs_path = glob('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/train/*.png')\n",
    "imgs_path = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_path = random.choice(imgs_path)\n",
    "# print(img_path)\n",
    "# img = Image.open(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "blank = np.ones((img.shape[0],50,3),dtype=np.uint8)*255\n",
    "img = np.concatenate((img,blank),axis=1)\n",
    "print(img.shape)\n",
    "model = densenet_keras_5990\n",
    "# img = cv2.resize(img,(800,32))\n",
    "%time result = model.recognize(img)\n",
    "# print(model.basemodel.summary())\n",
    "plt.imshow(img)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two model predict\n",
    "\n",
    "# densenet_keras.load_weights('./train/models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "# densenet_keras_2.load_weights('./train/models/freezen_5layers_dataset_v1-0.672-0.894.h5')\n",
    "    \n",
    "# imgs_path = glob('/mnt/wuwenhui/git_ocr_project/chinese_ocr_densenet/train/images/num_dataset_v2/train/*.png')\n",
    "imgs_path = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/临时切割图/*png')\n",
    "img_path = random.choice(imgs_path)\n",
    "# print(img_path)\n",
    "# img = Image.open(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "blank = np.ones((img.shape[0],20,3),dtype=np.uint8)*255\n",
    "img = np.concatenate((blank,img,blank),axis=1)\n",
    "model1 = densenet_keras\n",
    "model2 = densenet_keras_2\n",
    "# img = cv2.resize(img,(800,32))\n",
    "%time y_pred1 = model1.predict(img)\n",
    "%time y_pred2 = model2.predict(img)\n",
    "y_pred1 = y_pred1[:, :, :]\n",
    "y_pred2 = y_pred2[:, :, :]\n",
    "\n",
    "result = model1.decode((y_pred1+y_pred2)/2,with_confidence=True)\n",
    "result2 = model2.recognize_with_confidence(img)\n",
    "result3 = densenet_keras.recognize_with_confidence(img)\n",
    "# print(model.basemodel.summary())\n",
    "plt.imshow(img)\n",
    "print(result)\n",
    "print(result2,'model2')\n",
    "print(result3,'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(u'./train/images/test_images20181122/*png')\n",
    "img_paths = glob(u'/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*5\n",
    "img_paths = random.sample(img_paths,512)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "result_list=[]\n",
    "start = time.time()\n",
    "print(len(img_list))\n",
    "%time result_list = densenet_tf.recognize_on_batch(img_list,with_confidence=True,fixed_size=True)\n",
    "# %time result_list_1 =  densenet_tf.recognize_on_batch(img_list,with_confidence=True,fixed_size=True)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'2,1000':'3.2,4.1','2,300':'1.1,1.37',\n",
    " '1 1000':'3.5,4.5s','1,300':'1.16,1.44s',\n",
    " '4,1000':'2.9,4.4','4,300':'0.98,1.58'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob('/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*10\n",
    "img_paths = random.sample(img_paths,512)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "result_list = []\n",
    "start = time.time()\n",
    "for img in img_list:\n",
    "    result = densenet_keras.recognize_with_confidence(img)\n",
    "    result_list.append(result)\n",
    "print(time.time()-start)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用标注的样本测试模型的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./train/create_dataset/total_medicine_v1.txt','w') as f:\n",
    "#     for item in total_medicine:\n",
    "#         f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "save_dir = './test_data/labeled_data/'\n",
    "img_paths = glob(save_dir+'*png')\n",
    "\n",
    "# densenet_tf.load_weights('./train/models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "\n",
    "model = densenet_tf\n",
    "error_list = []\n",
    "# load json 文件\n",
    "with open(save_dir+\"valid_label.json\",'r',encoding='utf-8') as json_file:\n",
    "    label=json.load(json_file)\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"全角转半角\"\"\"\n",
    "    rstring = \"\"\n",
    "    for uchar in ustring:\n",
    "        inside_code=ord(uchar)\n",
    "        if inside_code == 12288:                              #全角空格直接转换            \n",
    "            inside_code = 32 \n",
    "        elif (inside_code >= 65281 and inside_code <= 65374): #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "\n",
    "        rstring += chr(inside_code)\n",
    "    return rstring\n",
    "sum = 0\n",
    "start = time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单次识别速度慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for img_path in img_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    img_name = os.path.split(img_path)[-1]\n",
    "#     result,confidence = model.recognize_with_confidence(img)\n",
    "    if label[img_name] == result:\n",
    "        sum +=1\n",
    "    else:\n",
    "        error_list.append((result,label[img_name]))\n",
    "print(sum/len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.imread(img_path) for img_path in img_paths]\n",
    "img_names = [os.path.split(img_path)[-1] for img_path in img_paths]\n",
    "ground_true = [strQ2B(label[img_name]) for img_name in img_names]\n",
    "result = model.recognize_on_batch(imgs,with_confidence=True,fixed_size=True)\n",
    "# sum([res[0]==ground for res,ground in zip(result,label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [strQ2B(res[0]) for res in result]\n",
    "\n",
    "true_sum = [res==ground for res,ground in zip(result,ground_true)].count(True)\n",
    "print(true_sum/len(imgs))\n",
    "error_list = [(res,ground)for res,ground in zip(result,ground_true) if res != ground]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(check_str):\n",
    "    len_str = len(check_str)\n",
    "    cutoff = 0.7\n",
    "    if len_str <= 3:\n",
    "        cutoff = 0.5\n",
    "    elif len_str <= 5:\n",
    "        cutoff = 0.6\n",
    "    return cutoff\n",
    "with open('./train/create_dataset/name_dictionary_v1.2.txt') as f:\n",
    "    medicine = f.readlines()\n",
    "medicine = [name.split('\\n')[0] for name in medicine ]\n",
    "medicine = list(set(medicine))\n",
    "len(medicine)\n",
    "medicine = [strQ2B(name)  for name in medicine]\n",
    "\n",
    "\n",
    "def get_closest_matches(item):\n",
    "    result,label = item\n",
    "    cutoff = check_name(result)\n",
    "    match_result = difflib.get_close_matches(result, medicine,cutoff=cutoff)\n",
    "    if match_result:\n",
    "        return (match_result,label)\n",
    "    else:\n",
    "        return (result,label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool,cpu_count\n",
    "pool = Pool(cpu_count()//4)\n",
    "# % time match_results = [get_closest_matches(item) for item in error_list ]\n",
    "\n",
    "sum=true_sum\n",
    "%time match_results = pool.map(get_closest_matches,error_list)\n",
    "match_error = []\n",
    "for results,label in match_results:\n",
    "    if label == results[0]:\n",
    "        sum +=1\n",
    "    else:\n",
    "        match_error.append((results[0],label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum/len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试验证模型冻结层的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  densenet  import densenet\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "characters = keys.alphabet[:]\n",
    "characters = characters[:] \n",
    "nclass = len(characters)\n",
    "print(len(characters))\n",
    "input = Input(shape=(32, None, 1), name='the_input')\n",
    "y_pred = densenet.dense_cnn(input, nclass)\n",
    "basemodel = Model(inputs=input, outputs=y_pred)\n",
    "modelPath = './densenet/models/weights_densenet_with_name.h5'\n",
    "\n",
    "if os.path.exists(modelPath):\n",
    "    print(\"Loading model weights...\")\n",
    "    basemodel.load_weights(modelPath)\n",
    "    print('done!') \n",
    "  \n",
    "    \n",
    "# basemodel.save_weights('./models/no_use_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters = keys.alphabet_union[:]\n",
    "# characters = characters[:] \n",
    "# nclass = len(characters)\n",
    "\n",
    "basemodel2 = Model(inputs=input,outputs=basemodel.get_layer('flatten').output)\n",
    "for i,layer in enumerate(basemodel2.layers):\n",
    "    layer.set_weights = basemodel.layers[i].weights\n",
    "flatten = basemodel.get_layer('flatten').output\n",
    "y_pred = Dense(nclass, name='out', activation='softmax')(flatten)\n",
    "basemodel3 =  Model(inputs=input,outputs=y_pred)\n",
    "for i,layer in enumerate(basemodel3.layers):\n",
    "    layer.set_weights = basemodel.layers[i].weights\n",
    "# basemodel4 = Model(inputs=input,outputs=basemodel.get_layer('Time').output)\n",
    "# basemodel4.load_weights()\n",
    "# basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel4 = Model(inputs=input,outputs=basemodel.get_layer('flatten').output)\n",
    "basemodel4.load_weights('./models/pre_y_pred_weights.h5')\n",
    "for i,layer in enumerate(basemodel.layers[:-1]):\n",
    "    layer.set_weights = basemodel4.layers[i].weights\n",
    "#     print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel3.layers[-1].set_weights = basemodel.layers[-1].weights\n",
    "print(basemodel.layers[-1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel3.save_weights('./models/merge_weights_pretrain_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nclass)\n",
    "input1 = Input(shape=(32, None, 1), name='the_input')\n",
    "y_pred1 = densenet.dense_cnn(input1, nclass)\n",
    "basemodel5 = Model(inputs=input1, outputs=y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.save_weights('./densenet/models/weights_densenet_with_name.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel5.load_weights('./densenet/models/weights_densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.get_layer('pool3_0_avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(basemodel5.layers):\n",
    "    print(i,layer.name,layer) \n",
    "#     print(layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用plot_model 观测模型情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(densenet_keras.basemodel,to_file='./models/rename_model.png')\n",
    "plt.figure(figsize=(40,200))\n",
    "img = Image.open('./models/rename_model.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多GPU预测性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import  multi_gpu_model\n",
    "with tf.device('/cpu:0'):\n",
    "    base_model =densenet_cnn_model()\n",
    "    base_model.load_weights('./models/75layers_labeled_ch_len25_v1-3.060-0.505.h5')\n",
    "parallel_model = multi_gpu_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.backend import ctc_decode\n",
    "\n",
    "characters = keys_keras.alphabet_union[:]\n",
    "characters = characters[1:]+u'卍'\n",
    "nClass = len(characters)\n",
    "def recognize_on_batch(img_list,basemodel):\n",
    "#         start = time.time()\n",
    "    max_w = int(max([32.0/img.shape[0]*img.shape[1] for img in img_list]))\n",
    "#         print(max_w)\n",
    "#         assert len(img_list) < 128\n",
    "    img_batch = np.ones([len(img_list),32,max_w,1])*0.5\n",
    "    for i,img in enumerate(img_list):\n",
    "        img_L = img.astype(np.float32)\n",
    "        if len(img_L.shape) ==3:\n",
    "            img_L = img_L[:,:,0]*114/1000 + img_L[:,:,1]* 587/1000 + img_L[:,:,2]* 299/1000 \n",
    "        scale = img_L.shape[0]*1.0/32.0\n",
    "        w = int(img_L.shape[1]/scale)\n",
    "        img = cv2.resize(img_L,(w,32),cv2.INTER_AREA)\n",
    "        img = img/ 255.0 - 0.5\n",
    "        img = img.reshape((32, w, 1))\n",
    "        img_batch[i,:,:w,:] = img\n",
    "    start = time.time()\n",
    "    y_pred = basemodel.predict_on_batch(img_batch)\n",
    "    end = time.time()\n",
    "    print('process use ' ,end-start)\n",
    "    out_list = []\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        y_encode = np.array([y_pred[i,:,:]]) \n",
    "        out = decode(y_encode)  ##\n",
    "        out_list.append(out)\n",
    "    return out_list\n",
    "\n",
    "\n",
    "def decode(pred,with_confidence=False):\n",
    "    text = pred.argmax(axis=2)[0]\n",
    "    length = len(text)\n",
    "    char_list = []\n",
    "    n = nClass-1\n",
    "    for i in range(length):\n",
    "        # 这里text[i] != n就是处理出来的分隔符，text[i - 1] == text[i]处理重复的字符\n",
    "        if text[i] != n and (not (i > 0 and text[i - 1] == text[i])):\n",
    "                char_list.append(characters[text[i]])\n",
    "\n",
    "    if with_confidence:\n",
    "        pred_max = pred.max(axis=2)[0]\n",
    "        confidence_list = [] \n",
    "        for i in range(length):\n",
    "            # 这里text[i] != n就是处理出来的分隔符，text[i - 1] == text[i]处理重复的字符\n",
    "            if text[i] != n and (not (i > 0 and text[i - 1] == text[i])):    \n",
    "                    confidence_list.append(pred_max[i])\n",
    "        length_confidence = len(confidence_list)\n",
    "\n",
    "        if length_confidence < 3:\n",
    "            confidence = np.mean(confidence_list)\n",
    "        else :\n",
    "            sorted_confidence = np.sort(confidence_list)\n",
    "            confidence = np.mean(sorted_confidence[:length_confidence//2])\n",
    "        return u''.join(char_list),confidence\n",
    "    return u''.join(char_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(u'/mnt/wuwenhui/git_ocr_project/keras_crnn/train/data/manual_crop/zh/*png')\n",
    "img_paths = img_paths*50\n",
    "img_paths = random.sample(img_paths,1000)\n",
    "img_list = [ cv2.imread(img_path) for img_path in img_paths ]\n",
    "%time result_list = recognize_on_batch(img_list,parallel_model)\n",
    "print(len(result_list))\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "KTF._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [x.name for x in sess.list_devices()]\n",
    "name = ['/' + ':'.join(name.lower().replace('/', '').split(':')[-2:]) for name in devices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,3))\n",
    "print(a.shape)\n",
    "b = np.reshape(a,(3,-1))\n",
    "print(b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "a = np.random.rand(4)\n",
    "print(a)\n",
    "b = a[[1,3]]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = b[0][1]\n",
    "tf.reset_default_graph()\n",
    "out = tf.placeholder(tf.float32,[None,10,6])\n",
    "value = tf.reduce_max(out,axis=2)\n",
    "index = tf.argmax(out,axis=2)\n",
    "output = tf.group(index,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "np.random.seed(1)\n",
    "input_value = np.random.rand(4,10,6)\n",
    "output_run = sess.run([index,value],{out:input_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_run[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
